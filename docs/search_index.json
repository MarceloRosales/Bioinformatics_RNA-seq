[["index.html", "Bioinformatics_RNA-seq Chapter 1 Introduction to RNA sequencing (RNA_seq) 1.1 Downloading and setting up conda environments. 1.2 Install Miniconda, or Anaconda. 1.3 Alignment Procedures and files.", " Bioinformatics_RNA-seq J. Marcelo Rosales R. Created: 2021-08-10; Update: 2021-09-28 Chapter 1 Introduction to RNA sequencing (RNA_seq) An over simplification of the Process. Holds 4 main sections. Sample and sample analysis. Samples are taken, prepared and send to a company for analysis. (Illumina !?). Raw data (FASTQ) - Expression quantification. Differential expression analysis. Pathway and Enrichment analysis. Each of these sections are subdivided in other steps. Download or acquire the files 2021/07/02 Copy Trial data from: MK/土橋 to folder HD-PCFSU3-A/Experiments Data/Genewiz : The Report file is here. The Summary file is here. Raw Data open &quot;Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/03_GeneExpression&quot; Report file open &quot;/Volumes/HD-PCFSU3-A/Experiments%20Data/Genewiz/60-499583816_60-501009934/60-499583816_60-501009934_GENEWIZ_RNASeq_Report.html&quot; Summary report file open &quot;/Volumes/HD-PCFSU3-A/Experiments%20Data/Genewiz/60-499583816_60-501009934/60-499583816_60-501009934_GENEWIZ_QC_Report.html&quot; To open folder in Finder with r code, is similar to terminal commands.: open . # To open the current working folder within Finder open ~ # To open the Home folder open / # To open the Root directory open Desktop/ open Music/ open /Library/ open /path/to/Directory/ # If folder have spaces, replace with %20% or other similar, or use &quot;&quot;. open &quot;/path/to/Directory/&quot; You can also launch (and update) applications from the Terminal without using Finder. For example, to open Safari, type: (But seem like it only works in terminal and can not do it with r/rstudio) 1.1 Downloading and setting up conda environments. Benefit: You can install all your tools in “Conda” and export as yml and you can share that environment or create a new one base on it, and by doing so, you can have all those tools automatically installed. 1.2 Install Miniconda, or Anaconda. Choose Anaconda if you: - Are new to conda or Python - Like the convenience of having Python and over 1500 scientific packages automatically installed at once - Have the time and disk space (a few minutes and 3 GB), and/or - Don’t want to install each of the packages you want to use individually. Choose Miniconda if you: - Do not mind installing each of the packages you want to use individually. - Do not have time or disk space to install over 1500 packages at once, and/or - Just want fast access to Python and the conda commands, and wish to sort out the other programs later. Mind that Windows and Mac installation and procedures are different. Does Windows need Linux to be intalled? Yes, a version of Linux kernell for window is available for download. Install Anaconda or Miniconda. brew install --cask anaconda brew install --cask miniconda # To check the version of conda installed. conda --version Quick video tutorial on how to use conda. * (Master) Conda environment. * Set up a data Science environment with Conda-Forge. To create an environment. The easy way: Open the anaconda app &gt; Environment &gt; New &gt; Name… Ok To access environment and open in terminal: anaconda app &gt; Environment &gt; Select environment &gt; rna-seq_test ^ &gt; »Open in Terminal. 1.2.1 Conda terminal commands. Conda cheat sheet In Terminal # To open conda app open /Applications/Anaconda-Navigator.app # Or, if any of the container folders have a space character. open &quot;/Applications/Anaconda-Navigator.app&quot; # To open (activate) conda environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3/envs/rna-seq_test # To see all the environment created. conda env list # To create a new environment called &quot;rna-seq_test&quot; in conda in terminal: conda create --rna-seq_test # To activate environment. conda activate rna-seq_test # To see if we activated the environment and where (path) we are. echo $path # To exit the environment and return to base/root. Check with echo $path. conda deactivate # To see packages installed in env.: conda config --show channels # List all packages and versions installed in active environment conda list # To see the url location of packages (repository): conda info # To add packages to the environment. (only to this environment: --env). conda config --env --add channels conda-forge conda config --env --add channels bioconda # If a package is repeated in the environment, Conda will always install the package of higher version. If you dont want that, and specifically need a version originally configured at creation of the environment.. type: conda config --env --set channel_priority strict. # To install fastqc conda install fastqc #To make and export a list of the required environment/ conda list --export &gt; requirements.txt #To make and export an yml file to share with others. conda env export &gt; rna-seq_test.yml conda env export --file rna-seq_test.yml # To quickly check the yml file. less rna-seq_test.yml #To see the content of a .yml file. head rna-seq_test.yml #To clear the terminal screen. clear # To run a Jupyter Notebook. jupyter notebook # To Keep Anaconda updated. conda update conda # Delete an environment and everything in it called rna-seq_test. conda env remove --rna-seq_test # To Uninstall Anaconda. # [Uninstall page]() 1.2.2 Anaconda/Miniconda install Summary of Steps. Install anaconda/miniconda for your OS from the website. Prevent the base environment from automatically activating. conda config --set auto_activate_base false Create an empty environment. conda create -n rna-seq_test. Activate the environment conda activate rna-seq_test. Add conda-forge as first channel conda config --env --add channels conda-forge. Ensure that conda-forge is used if the package is available. conda config --env --set channel_priority strict Install packages conda install .... Install packages not in conda-forge. Search in conda webpage search. conda install -c .... Verify Jupyter Notebooks in correct environment …!?… In jupyter: sys.executable Video reference: Bioinformatics - Downloading and Setting Up Conda Environments. 1.2.3 Conda activate error When trying to initialize environment in terminal with the conda activate rna-seq_testcommand, the following message pops up. CommandNotFoundError: Your shell has not been properly configured to use &#39;conda activate&#39;. To initialize your shell, run $ conda init &lt;SHELL_NAME&gt; Currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell See &#39;conda init --help&#39; for more information and options. IMPORTANT: You may need to close and restart your shell after running &#39;conda init&#39;. I tried: conda init powershell conda init zsh So far the only way to enter environment is though anaconda app. open &quot;/Applications/Anaconda-Navigator.app&quot; Then Environment &gt; rna-seq_test» &gt; Open in terminal… [Terminal] Another temporary solution is using the code: # For the rna-seq_test environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3/envs/rna-seq_test # For anaconda3 base environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3; 1.3 Alignment Procedures and files. This section was created based in this reference. After installing “conda,” and to gain time, download the genome of the species to be study. In this case, download the mouse (mus muslculus) genome file. This file contains the list of all the mouse genes and their codes. We need something to map our reads against once we get to the results. Files for mouse (Mus musculus) are available for download at Johns Hopkins University Center for Computational Biology (CCB) at TopHat. A spliced read mapper for RNA-Seq. There are different ways: Using tophat Using Star Custom/personal code. 1.3.1 Using Tophat (early version) Not Working!!! To download: 1. Look for the Mus musculus Build37.2 from the NCBI. 1. Right click the link and copy the link address. 1. go back to the conda environment and type wget and the paste the link. wget ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Mus_musculus/NCBI/build37.2/Mus_musculus_NCBI_build37.2.tar.gz 1.3.2 Using Tophat Not Working!!! Tophat can be installed using the same conda install conda install \\-c bioconda tophat When this is finished installing, then we will need to get the mouse genome from the Johns Hopkins Univeristy Center for computational BIology. The version of the mouse genome that I am using here is the NCBI build37.2. Instead of downloading this from the website and having to move it to the cluser, I will just download it using wget into the folder that has the raw reads, trimmed reads, and the FastQC files. wget ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Mus_musculus/NCBI/build37.2/Mus_musculus_NCBI_build37.2.tar.gz This will take a long time to download because the file is a little less than 16GB zipped. Installation of TopHat failed.!!!!!!!!!!!!!!!!!!!!!!! Try STAR 1.3.3 Using STAR Complicated!!! STAR can be installed the same way as the previous programs with conda install (conda install -c bioconda star). In order to run STAR, we need to creaate indices just like with tophat, but STAR has this built in. I’m going to be using the same genome and GTF file as previously downloaded, but Dr. Ge uses a different zipped genome from the gencode database. ~/miniconda2/bin/STAR \\ --runThreadN 80 \\ --runMode genomeGenerate \\ --genomeDir starIndex \\ --genomeFastaFiles Index/genome.fa \\ #same when we made the bowtie indices --sjdbGTFfile Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf With the index files made, we can start aligning with STAR. It’s important here than we only pick the paired end reads and not use all of the reads. Tophat is able to use all 4 reads but STAR doesn’t allow that, so we need to make sure that we feed in the large files from trimming. ~/miniconda2/bin/STAR --runThreadN 80 --genomeDir starIndex --readFilesIn 770_fp.fq 770_rp.fq --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix 2121770 --outSAMtype BAM SortedByCoordinate [here]() Complicated.!!!!!!!!!!!!!!!!!!!!!!! 1.3.4 Custom/personal way to Download the Mus_musculus_NCBI_build37.2.tar.gz file. Esaest so far. Go to the iGenomes Ready-To-Use Reference Sequences and Annotations from illumina.. Copy the Mus musculus (Mouse) NCBI build37.2 link. Paste the link in a new tab/window on a web browser (chrome) and click enter. Popup window will ask where to save the file, choose folder and save. File is 23Gb so it will take about 3 to 4 hrs to download. 1.3.5 Get the Sample files. Samples files come as “x_1.fastq.gz” or “x_2.fastq.gz,” where x is the name of the file, 1 is for forward and 2 for reverse pair reads. example: we will place them in a folder (00_Rawdata) mPDL_RNA7D_Ko1_S1_L001_R1_001.fastq.gz mPDL_RNA7D_Ko1_S1_L001_R2_001.fastq.gz mPDL_RNA7D_Ko2_S1_L001_R1_001.fastq.gz mPDL_RNA7D_Ko2_S1_L001_R2_001.fastq.gz mPDL_RNA7D_Ko3_S1_L001_R1_001.fastq.gz mPDL_RNA7D_Ko3_S1_L001_R2_001.fastq.gz… etc…. Download multiqc conda install multiqc 1.3.6 Starting to analize fastq.gz files Initialize fastqc fastqc Make an output directory named rawFastQC mkdir rawFastQC Now we have to process all fastq files contained in the folder (00_Rawdata) and place the results in the directory we just made “rawFastQC.” fastqc rawFastQC/*.fastq.gz -o rawFastQC/ Once analysis is finished. Go to the results folder (rawFastQC) cd rawFastQC “fastqc” created .zip files and a .html file report for each sample. To see them individually may be difficult and take time. For a more convenient way to visualize results, merge all sample reports (html file) in one file. Create the report by reading all the files contained in the results folder (rawFastQC) and combine them in one multiqc_report.html file using “multiqc.” # go to the results folder where the html report files are. cd rawFastQC # Check if the files are there. ls # Create the multiqc report. Type (the dot is important!) multiqc . # check if file was created. ls 1.3.7 Trimming with Trimmomatic conda install trimmomatic # parallel my also be required for task piping. conda install parallel 24:40 Conda was used again to run Trimmomatic. This isn’t as easy as using the wildcard like with FastQC because each output has to be personalized for the read files that are input into Trimmomatic. Also, we have to make sure that the adapter sequences are in the same folder that we are running so we can refer to them easily when calling the Trimmomatic program. In this case, we are using the TruSeq3-PE-2.fa adapter sequences For example: ~/miniconda2/bin/trimmomatic PE SRR2121770_1.fastq.gz SRR2121770_2.fastq.gz 770_fp.fq.gz 770_fu.fq.gz 770_rp.fq.gz 770_ru.fq.gz ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 &amp; This would be repeated for each of the pairs (12 in total). We are trimming paired-end reads with the TruSeq3-PE-2 adapters. We are chopping off the first and last 3 bases and if we end up with a sequence less than 36 bases, we get rid of it. We want to make sure that there are enough bases in a read to work with. These parameters can be tweaked for possibly better end results with less being discarded. When Trimmomatic is finished running, it will out put the total number of reads, the total number from both the forward and reverse reads that are kept, the number of only forward reads kept, the number of only reverse reads kept, and the number of discarded reads. The trimmed reads can be analyzed again with FastQC to see how well the trimming worked to make the file better quality. After running FastQC on the trimmed files we see that the quality of those that were really bad quality were improved. There were a few different metrics throughout all of the files that bounced from a warning before the failing, or from passing before to a warning, and so forth, overall creating better quality read files. Read Check Undrstantig Trimmomatic tutorial for this section !!!!!! after trimmomatic, files will be created, .gz and .log files. Use multiqc to merge all logs in one report file. Then check the timmomatic survival Reads. If all samples are over 55M (million) reads then samples are valid for further analysis. Check the order again. Trimmomatic &gt; alligment -&gt; w/ TopHap or STAR 1.3.8 Using STAR to map genes Using the Mus_musculus files we will compare our samples and find where in the genome our reads are. &gt; Build Genome Indexing and useful STAR Flags (quick). See also: novocraft aling. *Opens only on safari. Analyzind RNA-Seq data using Python3 Snakemake. File Snake file. Look for more information with rRNA and Microbial Contamination. Bioinformatics - Contamination QC and FeatureCounts Quick Look at Counts and Setting Up R Project "],["file-download-or-sra-qc-and-trimming.html", "Chapter 2 File Download (or SRA), QC, and Trimming 2.1 Trimmomatic 2.2 Indexing with STAR 2.3 Microbial contamination 2.4 Feature counts. 2.5 Setting R environment.", " Chapter 2 File Download (or SRA), QC, and Trimming Bioinformatics - SRA Download, QC, and Trimming. Create environment (avoid spaces or special characters). Init environment conda install sra-tools This will allow us to pull directly from the sra page. (where the sample ex. Files) Go to page. Select only the files needed. Then in the Selected &gt; click on Accession List &gt; Save (this saves a .txt file with the list of names of the selected files). Drag onto the file structure, so its now in system ls to see the files (SRR_Acc_List.txt) Check ‘head SRR_Acc_List.txt’ command Also you can use the vi SRR_Acc_List.txt command to see the list in the file. Ex. ①. SRR2121770\\ ②. SRR2121771\\ ③. SRR2121774\\ ④. SRR2121778\\ ⑤. Etc. Now that we have the list of files, we have to individually download each one of them. One way to do that is with the fastq-dump --gzi --split-file SRR2121770 &amp; command. ①. This command will take the SRR2121770 file, and save it as a .gzi file (to save space) ②. it will split the file in forward (1) and Reverse (2), ③. the “&amp;” sign means that it will run this command in the background. This will take some time since the file is big. A way to see if the process is finished or not is with the command jobs, which gives a list of the jobs in process or nothing if there are not jobs running. Another way to do it is with the pipe command, so we don’t have to do this process for each file. Use the command cat SRR_Acc_List.txt | parallel fastq-dump --gzi --split-file {}. ①. This will take the SRR_Acc_List.txt and catalog the list. ②. Then it will take each of the element in the list &quot;{}&quot; slipt them, and save them as gzi. ③. In the rawReads folder???.(create rawReads folder). you will have a list of .fastq.gz_1 and .fastq.gz_2 for each element of the list. `…rawReads$ ls`. ④. Each time something is changed in the files, create a new folder and save there so the originals are not modified. Ex. Trimmed. Once all files are downloaded, install multiqc. conda install multiqc. (if not installed) Before running fastqc, create an output directory where to save the processed files. mkdir rawFastQC (make sure you are in the right directory before making this folder). Then run fastqc: fastqc -t 64 rawReads/*fastq.gz -o rawFastQC This means, process files with fastqc using 64 treads (-t 64) windows/linux virtual machine; by taking all fastqc.gz files in the folder rawReads; and save in the output directory (-o) called rawFastQC. This process will take a long time depending on the number and size of the files. Once finished cd rawFastQC and check the files ls Then inside the folder, run multiqc in multiqc .. Once this finished, inside the folder a new “multiqc_report.html” will be created. Open the files and compare. 22:29 Once this quality control is finished we can pass to the trimming of the samples. 2.1 Trimmomatic Trimmomatic web page. Quick start Paired End: # [Trimmomatic web page](http://www.usadellab.org/cms/?page=trimmomatic). java -jar trimmomatic-0.39.jar PE input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 Trimming and Filtering full parameters description and example: # datacarpentry [Trimming and Filtering](https://datacarpentry.org/wrangling-genomics/03-trimming/index.html) trimmomatic PE -threads 4 SRR_1056_1.fastq SRR_1056_2.fastq \\ SRR_1056_1.trimmed.fastq SRR_1056_1un.trimmed.fastq \\ SRR_1056_2.trimmed.fastq SRR_1056_2un.trimmed.fastq \\ ILLUMINACLIP:SRR_adapters.fa SLIDINGWINDOW:4:20 Install trimmomatic, conda install trimmomatic (if not installed). conda install trimmomatic # parallel my also be required for task piping. conda install parallel If we are going to trim the files, we need to make a new folder, so exit rawFastQC folder. cd.. and mkdir trimmedReads, we are going to point trimmomatic the this folder. # exit rawFastQC folder (remember there is a space between cd and .) cd .. # Create new folder for trimmed files mkdir trimmedReads We are going to pull our true adapter sequencer to our working directory. Then it will be a lot easier to point trimmomatic to that vs having to type in the really long path. cp ~/miniconda3/envs/name_of_environment/share/trimmomatic-0.39-1/adapters/TrueSeq3-PE-2.fa . (the last point is important, it means that the command will the done in this folder). This command copy the file TruSeq3-PE-2.fa file to our current folder, why? so the process will be done directly in our folder, instead of the need to type the path to the folder (if not, in the code, instead of the point, type the path to the directory.) cp ~/miniconda3/envs/rna-seq_test/share/trimmomatic-0.39-1/adapters/TrueSeq3-PE-2.fa . This gives error. Sometimes, due to updates in conda and trimmomatic, folder names might change or there is a space in a folders name. Check if this is the case by open \"/usr/local/anaconda3/envs/rna-seq_test/share/\". Seems like the version of timmomatic is “0.39-2” and not “0.39-1, and I installed anaconda3 and not miniconda3. Correct code and try again. Full path is: /usr/local/anaconda3/envs/rna-seq_test/share/trimmomatic-0.39-2/adapters/TruSeq3-PE-2.fa, then the code would be: `cp /usr/local/anaconda3/envs/rna-seq_test/share/trimmomatic-0.39-2/adapters/TruSeq3-PE-2.fa .` Install Parallel, Conda install paralell Create new directory for the trimmed files. mkdir trimmedReads. Now run the trimmomatic. For my samples it would be… # Try 01 FAILED trimmomatic PE -threads 5 rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Try 02 FAILED trimmomatic PE -threads 5 rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Try 03 SUCCESS!!!??? trimmomatic PE rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Try 04 (Datacarpentry) trimmomatic PE -threads 4 rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001 ILLUMINACLIP:SRR_adapters.fa SLIDINGWINDOW:4:20 # datacarpentry [Trimming and Filtering](https://datacarpentry.org/wrangling-genomics/03-trimming/index.html) $ trimmomatic PE -threads 4 SRR_1056_1.fastq SRR_1056_2.fastq \\ SRR_1056_1.trimmed.fastq SRR_1056_1un.trimmed.fastq \\ SRR_1056_2.trimmed.fastq SRR_1056_2un.trimmed.fastq \\ ILLUMINACLIP:SRR_adapters.fa SLIDINGWINDOW:4:20 # Sample 1 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Sample 2 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko2_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko2_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko2_S1_L001_R2_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko2_S1_L001trimming.log java -jar trimmomatic-0.39.jar PE input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 The PE means “Pair end Read”, because we have both forward and reverse ends (1 and 2); If we would have only one end read (1 or 2) then it would be only single read, for single reads we type SE (instead of the PE). Timmomatic usually use up to 5 threads, thus we use “-threads 5”. (What if we don’t type the # of threads? would it use all threads? Why is this important?….) Then type the path to the folder and files containing the files to be trimmed. rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001.fastq.gz (forward), and type also the reverse “rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001.fastq.gz” The “-baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001” means that; the base file name of the output will all have the name ” trimmedReads/mPDL_RNA7D_Ko1_S1_L001”. It will place the file in the trimmedReads folder and all the file with start with the name mPDL_RNA7D_Ko1_S1_L001. Then we use the True sequence adapter (TruSeq3-PE-2.fa) that we moved to the working folder by typing “ILLUMINACLIP:TruSeq3-PE-2.fa:” (you can use the tap for auto completion coz it is in the same folder) Then we place the trimming parameters??… “2:30:10:2keepBothReads”. Add more info here….. how to understand the trimmomatic flags? Understanding Trimmomatic The “LEADING:3 TRALING:3”means that; if the bases have bad quality, then trimm the leading 3 and trailing 3 bases. more info, If the quality is of very good quality we can remove 10, but we dont want to remove/through away that much information from out reeds. Then, since our reads are really short and we are looking at their quality, we want to set a mean length. “MINLEN:36”. So if any or our 51 base pair reads have more than 15 removed (51-15= 36), we are just not going to use or keep them because we lost ~33% of the information of that read, so is not going to be a good (quality?) read. Then we want to keep the output. “2&gt; mPDL_RNA7D_Ko1_S1_L001trimming.log`”, the “2” is to keep output, and then feed that into “&gt;” the “trimmedReads folder, and make (from all the ourput) a nice report like for fastQC and colled it”mPDL_RNA7D_Ko1_S1_L001trimming.log”. From all the code typed, there will be 5 outputs to be loged, …. Since this takes really long time, and option will be to do a cat with the reads and do 4 jobs at a time. For my files..?? # Not working cat Filename.txt | parallel -j 4 &quot;trimmomatic PE -threads 5 rawReads/{}_R1_001.fastq.gz rawReads/{}_R2_001.fastq.gz -baseout trimmedReads/{} ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 2&gt; trimmedReads/{}trimming.log&quot; In the tutorial for auto loading. cat Filename_list.txt | parallel -j 4 &quot;trimmomatic PE -threads 5 rawReads/{}_1.fastq.gz rawReads/{}_2.fastq.gz -baseout trimmedReads/{} ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 2&gt; trimmedReads/{}trimming.log&quot; Control + Z to stop running and add bj 1 (in root?) to run in the background. type jobs (in terminal) to see the jobs running in the background. In the github tutorial: Conda was used again to run Trimmomatic. This isn’t as easy as using the wildcard like with FastQC because each output has to be personalized for the read files that are input into Trimmomatic. Also, we have to make sure that the adapter sequences are in the same folder that we are running so we can refer to them easily when calling the Trimmomatic program. In this case, we are using the TruSeq3-PE-2.fa adapter sequences For example: ~/miniconda2/bin/trimmomatic PE SRR2121770_1.fastq.gz SRR2121770_2.fastq.gz 770_fp.fq.gz 770_fu.fq.gz 770_rp.fq.gz 770_ru.fq.gz ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 &amp; Finally for this trial I used: # Sample 1 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Sample 2 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko2_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko2_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko2_S1_L001_R2_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko2_S1_L001trimming.log Pipe line code for automatic file loading to trimmomatic still not successfully tested. Come back to this later. # Pipe and loop for all files. cat filenames.txt | parallel -j 4 &quot;trimmomatic PE rawReads/{}_1.fastq.gz rawReads/{}_2.fastq.gz -baseout trimmedReads/{} ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/{}trimming.log&quot; #Not successful. Finally re-run the fastqc and multiqc of the trimmed data. # In TrimmedRead folder ls multiqc . This will take all the .log files created in by the TruSeq3-PE-2.fa trimmed data. Note: Seems like multiqc can take all html and log files and combine the information with in them in a single html report file. # fastQC of trimmed files again? mkdir trimmedFastQC # rm -d trimmedFastQC # Make sure folder is in main folder, if not delete # Run fastqc... Trimmed files have no file extension. Why??? fastqc trimmedReads/* -o trimmedFastQC # .zip and qc html files will be created. Run multiqc cd trimmedFastQC multiqc . 2.2 Indexing with STAR Bioinformatics - Building Genome Index and Aligning with STAR STAR is a tool that allow us to build an index of the mouse genome; then, with those index files we can then map the reads against the genome and find the location of each of those reads where they are mapped in the genome. Once we have that, the we can do a the “read count” For more information see [STAR: ultrafast universal RNA-seq aligner] (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3530905/) STAR Manual download link. PDF file in local HD Link to manual page. Download the Mouse genome form the NCBI page. See Custom/personal way to Download the Mus_musculus_NCBI_build37.2.tar.gz file section. (open section in a new tab) See 1.3.4 Once file is downloaded, unzip. (It will take a long time) Make sure to be in the same folder/directory as the tar.gz file. extracted files will be saved in a Mus_musculus folder/directory automatically created. # Check the correct environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3/envs/rna-seq_test # Check the correct folder/directory. cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus_NCBI_build37.2.tar.gz&quot; # cd &quot;folder path&quot; #Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus_NCBI_build37.2.tar.gz: Not a directory cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/&quot; # Check contents ls # Unzip file tar xvfz Mus_musculus_NCBI_build37.2.tar.gz Tar command info for linux here and for mac here Confirm that STAR is installed if not Install STAR. # Make sure of enviroment. STAR --help #If not found install. conda install STAR # Make sure is from &quot;bioconda&quot;. Preceed([y]/n)? message. y # Check again. Long list of flags. STAR --help # Create a directory for starIndex. mkdir starIndex ls Run STAR. Make sure that the unzip folder of Mus_musculus_NCBI_build37.2.tar.gz (Mus_musculus) is in the same directory as trimmed/environment. Is this necessary???! FYI: Mus_musculus_NCBI_build37.2.tar.gz zip file is 23.58 GB. Mus_musculus unziped folder is 98.77 GB. Initially downloaded into: \"/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus_NCBI_build37.2.tar.gz\" Trial analysis forlder in: \"/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02\" Mus_musculus unziped folder moved to: /Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02/Mus_musculus Path to genome.fa file. /Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus/NCBI/build37.2/Sequence/WholeGenomeFasta/genome.fa Path to genes.gtf file. /Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf However better to use the folder Shortcut (known as aliases on Mac) created when unziped. This eliminates the Archives/archive-2015-07-17-14-32-40section of the path. So… use /Mus_musculus/NCBI/build37.2/Annotation/Genes/genes.gtf # Make sure that the unzip folder of Mus_musculus_NCBI_build37.2.tar.gz (Mus_musculus) is in the same directory as environment/analysis folder in this case: cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02/&quot; # Run STAR STAR --runThreadN 64 --runMode genomeGenerate --genomeDir starIndex --genomeFastaFiles Mus_musculus/NCBI/build37.2/Sequence/WholeGenomeFasta/genome.fa --sjdbGTFfile Mus_musculus/NCBI/build37.2/Annotation/Genes/genes.gtf Sep 13 12:47:47 ..... started STAR run Sep 13 12:47:48 ... starting to generate Genome files Sep 13 12:49:24 ..... processing annotations GTF Sep 13 12:49:40 ... starting to sort Suffix Array. This may take a long time... Sep 13 12:49:51 ... sorting Suffix Array chunks and saving them to disk... Sep 13 13:23:01 ... loading chunks from disk, packing SA... Sep 13 13:48:03 ... finished generating suffix array Sep 13 13:48:03 ... generating Suffix Array index Sep 13 13:53:59 ... completed Suffix Array index Sep 13 13:54:00 ..... inserting junctions into the genome indices # Try several times but it could not finished correctly, &quot;System run out of application memory. # It is important that the hole process is fully completed. It takes quite a long time and uses a lot of memory resource. Your System Has Run Out of Application Memory on Mac. Solutions: 1. Close unnecessary webpages/programs. 2. Free up more space on the system HDD (at least 20% of free memory?). 3. Google chrome application memory leak?. Run task manager and check memory usage. 4. Check memory pressure (memory pressure command) and double ckeck your free space. Also try running sudo purge from the terminal. 5. Re-start computer to reset uptime. 6. Update software. 7. Reset Mac’s NVRAM and PRAM. 8. Close chrome and/or Safari.# STAR version: 2.7.9a compiled: :/Users/cshl/data/STAR/STAR/source Sep 13 16:19:40 ..... started STAR run Sep 13 16:19:41 ... starting to generate Genome files Sep 13 16:21:14 ..... processing annotations GTF Sep 13 16:21:28 ... starting to sort Suffix Array. This may take a long time... Sep 13 16:21:37 ... sorting Suffix Array chunks and saving them to disk... Sep 13 16:53:49 ... loading chunks from disk, packing SA... Sep 13 17:18:12 ... finished generating suffix array Sep 13 17:18:12 ... generating Suffix Array index Sep 13 17:23:21 ... completed Suffix Array index Sep 13 17:23:24 ..... inserting junctions into the genome indices Sep 13 17:25:56 ... writing Genome to disk ... Sep 13 17:27:06 ... writing Suffix Array to disk ... Sep 13 17:36:19 ... writing SAindex to disk Sep 13 17:37:01 ..... finished successfully (rna-seq_test) MR-MBP20:Trial02 marcelorosales$ # Check if the files were created in the folder. cd starIndex ls These process will take about 2 hrs or longer depending con computer’s processing power. The optins/flags coded were: –runThreadN 64: Number of threads use for processing. –runMode genomeGenerate: To start star generates the index files therefore genomeGenerate. –genomeDir starIndex:This is the directory for the star index output (is not the genome FASTA files). –genomeFastaFiles Mus_musculus/NCBI/build37.2/Sequence/WholeGenomeFasta/genome.fa: the whole genome of the mouse is in this file. –sjdbGTFfile Mus_musculus/NCBI/build37.2/Annotation/Genes/genes.gtf: This lets star know that the next file we are going to give it is a GTF file which is the anotation file of all the transcript that we are going to try to identify with our reads. It may not be really necessary, but it is recommended to usefor more accuracy, specially in de novo transcrip discovery, you would use this basically to take all the reads and map them. STAR will create the index files and save them in the “starIndex” folder. Whit this files compleated, we will now map the reads of our samples Align reads Create a Folder to save the sample reads. # create a new directory to target as output directory. mkdir starAligned ls For aligning, there are some issues with the flags command Z cat which tells star that the files we’re inputting are zipped. The way around it is to (maybe not the best way) gunzip flag (command/app). The way to use this is to do/perform the command beforehand, and then input on the files that we want, which it would be something like treammedReads/[] in a cat file. (file containing a catalog or list of the files downloaded or to be fed to the application). To create a cat file see Cat command in Linux or see video cat &gt; filenames.txt # Type or copy paste. mPDL_RNA7D_Ko1_S1_L001_R1_001_1P mPDL_RNA7D_Ko1_S1_L001_R1_001_2P mPDL_RNA7D_Ko2_S1_L001_R2_001_1P mPDL_RNA7D_Ko2_S1_L001_R2_001_2P # press control +D to save # Also, might need to instal pigz conda install -c conda-forge pigz mPDL_RNA7D_Ko1_S1_L001_R1_001_1P mPDL_RNA7D_Ko1_S1_L001_R1_001_1U mPDL_RNA7D_Ko1_S1_L001_R1_001_2P mPDL_RNA7D_Ko1_S1_L001_R1_001_2U mPDL_RNA7D_Ko2_S1_L001_R2_001_1P mPDL_RNA7D_Ko2_S1_L001_R2_001_1U mPDL_RNA7D_Ko2_S1_L001_R2_001_2P mPDL_RNA7D_Ko2_S1_L001_R2_001_2U mPDL_RNA7D_Ko1_S1_L001_R1_001_1P mPDL_RNA7D_Ko1_S1_L001_R1_001_2P mPDL_RNA7D_Ko2_S1_L001_R2_001_1P mPDL_RNA7D_Ko2_S1_L001_R2_001_2P changed to match filenames.txt mPDL_RNA7D_Ko1_1P mPDL_RNA7D_Ko1_2P mPDL_RNA7D_Ko2_1P mPDL_RNA7D_Ko2_2P # Original cat filenames2.txt | parallel -j 2 &quot;gunzip trimmedReads/{}_*P.gz &amp;&amp; STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; # ERROR # zsh:1: no matches found: trimmedReads/mPDL_RNA7D_Ko1_*P.gz # zsh:1: no matches found: trimmedReads/mPDL_RNA7D_Ko2_*P.gz # zsh:1: no matches found: trimmedReads/mPDL_RNA7D_Ko1_*P.gz # zsh:1: no matches found: trimmedReads/mPDL_RNA7D_Ko2_*P.gz # With no extensions. cat filenames2.txt | parallel -j 2 &quot;gunzip trimmedReads/{}_*P &amp;&amp; STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; # ERROR #gunzip: trimmedReads/mPDL_RNA7D_Ko1_1P: unknown suffix -- ignored #gunzip: trimmedReads/mPDL_RNA7D_Ko1_2P: unknown suffix -- ignored #gunzip: trimmedReads/mPDL_RNA7D_Ko2_1P: unknown suffix -- ignored #gunzip: trimmedReads/mPDL_RNA7D_Ko2_2P: unknown suffix -- ignored cat filenames2.txt | parallel -j 2 &quot;STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; # cat filenames2.txt | parallel -j 2 &quot;gunzip trimmedReads/{}_*P.gz &amp;&amp; STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; # No gunzip cat filenames2.txt | parallel -j 2 &quot;STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; ## NOT WORKING... OPTIONS: # 1. FIRST convert all .*P files to gz () and do it in the background (use &amp; at the end of line). pigz trimmedReads/*P &amp; # Check bg 1 # to see if it is working jobs # [1] running pigz trimmedReads/*P # to see Process type top # see commad &quot;pigz&quot; &quot;STAR&quot; if running. also top # To stop control + Z # To exit control + C # Now all P files are gz. run code. cat filenames2.txt | parallel -j 2 &quot;gunzip trimmedReads/{}_*P.gz &amp;&amp; STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --outSAMtype BAM SortedByCoordinate &amp;&amp; pigz trimmedReads/{}_*P&quot; &amp; # Found better code. cat filenames2.txt | parallel -j 2 &quot;parallel gunzip ::: trimmedReads/{}_*P.gz &amp;&amp; STAR --runThreadN 64 --genomeLoad LoadAndKeep --genomeDir starIndex/ --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --limitBAMsortRAM 5000000000 --outSAMtype BAM SortedByCoordinate --outReadsUnmapped Fastx &amp;&amp; pigz trimmedReads/{}_*P&quot; &amp; # I there is no need to unzip cat filenames2.txt | parallel -j 2 &quot;STAR --runThreadN 64 --genomeLoad LoadAndKeep --genomeDir starIndex/ --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --limitBAMsortRAM 5000000000 --outSAMtype BAM SortedByCoordinate --outReadsUnmapped Fastx &amp;&amp; pigz trimmedReads/{}_*P&quot; # ERROR # Shared memory error: 4, errno: Invalid argument(22) # EXITING because of FATAL ERROR: problems with shared memory: error from shmget() or shm_open(). # SOLUTION: check shared memory settings as explained in STAR manual, OR run STAR with --genomeLoad NoSharedMemory to avoid using shared memory cat filenames2.txt | parallel -j 2 &quot;STAR --runThreadN 64 --genomeLoad NoSharedMemory --genomeDir starIndex/ --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --limitBAMsortRAM 5000000000 --outSAMtype BAM SortedByCoordinate --outReadsUnmapped Fastx&quot; # ERROR # BAMoutput.cpp:27:BAMoutput: exiting because of *OUTPUT FILE* error: could not create output file starAligned/mPDL_RNA7D_Ko2_STARtmp//BAMsort/49/2 # SOLUTION: check that the path exists and you have write permission for this file. Also check ulimit -n and increase it to allow more open files. ulimit -n #2560 ulimit -n 100000 fg1 #? What us tgus for? cat filenames2.txt | parallel -j 2 &quot;STAR --runThreadN 64 --genomeLoad NoSharedMemory --genomeDir starIndex/ --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --limitBAMsortRAM 5000000000 --outSAMtype BAM SortedByCoordinate --outReadsUnmapped Fastx&quot; cat filenames2.txt | parallel -j 1 &quot;STAR --runThreadN 64 --genomeLoad NoSharedMemory --genomeDir starIndex/ --readFilesIn trimmedReads/{}_1P trimmedReads/{}_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/{} --limitBAMsortRAM 5000000000 --outSAMtype BAM SortedByCoordinate --outReadsUnmapped Fastx&quot; STAR --runThreadN 32 --genomeDir starIndex --readFilesIn trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1P trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_2P --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix starAligned/mPDL_RNA7D_Ko1_S1_L001_R1_001 --outSAMtype BAM SortedByCoordinate SAM is human readable, BAM is compress binary version (for CPU to read), 2.3 Microbial contamination For this use/install Kraken2 2.4 Feature counts. video # Install subreads. conda install subread # count featureCounts -h cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02/Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/&quot; head genes.gtf # GTF file has gene_id (sametimes is doesnt work!), and transcipt_id. This two are going to be used to label genes. in the fearuresCounts -h you can see the code to input the *_id. # make a count Directoru cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02&quot; mkdir readCounts # Read counts # as .txt featureCounts -T 8 -a Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf -g `transcript_id` -o readCounts/readCounts.txt starAlign/*.bam # as .csv? featureCounts -T 8 -a Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf -g `transcript_id` -o readCounts/readCounts.csv starAlign/*.bam # make the report cd readCounts multiqc . 2.5 Setting R environment. Intall packages Packages readr (install.packages(‘readr’)) limma (BiocManager::install(‘limma’)) DESeq2 (BiocManager::install(‘DESeq2’)) dplyr (install.packages(“dplyr”)) ggplot2 (install.packages(“ggplot2”)) gplots (install.packages(“gplots”)) Annotations (BiocManager::install(‘AnnotationDbi’)) org.Hs.eg.db (BiocManager::install(‘org.Hs.eg.db’)) This is for Human org.Mm.eg.db (BiocManager::install(‘org.Mm.eg.db’)) This is for Mouse ggrepel (install.packages(“ggrepel”)) ReportingTools (BiocManager::install(‘ReportingTools’)) GO.db (BiocManager::install(‘GO.db’)) GOstats (BiocManager::install(‘GOstats’)) pathview (BiocManager::install(‘pathview’)) gage (BiocManager::install(‘gage’)) gageData (BiocManager::install(‘gageData’)) select (BiocManager::install(‘Select’)) install.packages(c(&quot;dplyr&quot;, &quot;ggplots&quot;, &quot;ggplot2&quot;, &quot;greppel&quot; )) BiocManager::install(c(&quot;lima&quot;, &quot;DESeq2&quot;, &quot;AnotationDbi&quot;, &quot;org.Mn.eg.db&quot;, &quot;ReportingTools&quot;, &quot;GO.db&quot;, &quot;GOstats&quot;, &quot;pathview&quot;, &quot;gage&quot;, &quot;gageDATA&quot;, &quot;select&quot;)) # Libraries library(limma) library(DESeq2) library(dplyr) library(readr) countData = read_csv(&quot;readCounts.csv&quot;, skip = 1) ##End "],["methods.html", "Chapter 3 Methods", " Chapter 3 Methods We describe our methods in this chapter. Set Environment QC/multiqc of raw Reads Trimming with Trimmomatic QC/multiqc of trimmed Reads Genome Index and Aligning with STAR Raw Data file names original: mPDL_RNA7D_Ko2_S1_L001_R2_001_2.fastq.gz mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz mPDL_RNA7D_Ko2_S1_L001_R1_001_1.fastq.gz Change (for easy management) to: mPDL_RNA7D_Ko1_1.fastq.gz mPDL_RNA7D_Ko1_2.fastq.gz mPDL_RNA7D_Ko2_1.fastq.gz mPDL_RNA7D_Ko2_2.fastq.gz Seems like original raw data was already splited # Create the cat file with the file names. cat &gt; filenames.txt #Type or copy paste the name of the files to be analyzed. # In last line press enter and then control + D to save the file names in the cat file. #Check the list head filenames.txt # Since already spliced not need to run this section. # In conda environment mkdir rawReads cd rawReads # Download files from webpage source. (one by one) fastq-dump --gzip --split-file mPDL_RNA7D_Ko1 &amp; # The &amp; indicates to run in the background. To see the jobs in the bkg. jobs # Download files from webpage source. (all at once). Better to do overnight. cat filenames.txt | parallel &quot;fastq-dump --gzip --split-file {}&quot; # files will be Forward (1) Reverse (2) or Paired reads. conda install multiqc # Some git preferences for git contributions. git status git config --list # set git email git config user.email &quot;email@example.com&quot; # confirm emal git config --global user.email # For the rna-seq_test environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3/envs/rna-seq_test cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02&quot; ## Run FAST QC mkdir rawFastQC fastqc -t 64 rawReads/*fastq.gz -o rawFastQC fastqc rawReads/*fastq.gz -o rawFastQC cd rawFastQC ls ## Run multyQC multiqc . ls cd.. ## Trimming cat &gt; filenames2.txt mPDL_RNA7D_Ko1 mPDL_RNA7D_Ko2 cat filenames2.txt mkdir trimmedReads # Pull TrueSeq to folder. cp /usr/local/anaconda3/envs/rna-seq_test/share/trimmomatic-0.39-2/adapters/TruSeq3-PE-2.fa . # Run Trimmomatic # Original (one by one) trimmomatic PE -threads 5 rawReads/mPDL_RNA7D_Ko1_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1 ILLUMINACLIP:truSeq-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1trimming.log #???????????? HOw to determing leading, trailing and minimun length # Original (all automatically) cat filenames2.txt | parallel -j 4 &quot;trimmomatic PE -threads 5 rawReads/{}_1.fastq.gz rawReads/{}_2.fastq.gz -baseout trimmedReads/{} ILLUMINACLIP:truSeq-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/{}trimming.log&quot; # Check if jobs are running jobs # Problems: Takes a long time and sometimes it stops. # The generic trimmomatic command: java -jar trimmomatic-0.39.jar PE inputforward.fq.gz inputreverse.fq.gz outputforwardpaired.fq.gz outputforwardunpaired.fq.gz outputreversepaired.fq.gz outputreverseunpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 # Try 03 SUCCESS!!!? trimmomatic PE rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Sample 1 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko1_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko1_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko1_S1_L001_R1_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko1_S1_L001trimming.log # Sample 2 Success!!!!???? error but TrimmomaticPE: Completed successfully message. # error in TruSeq3-PE.fa (No such file or directory)... Change to TruSeq3-PE-2.fa (not tested yet) trimmomatic PE rawReads/mPDL_RNA7D_Ko2_S1_L001_R1_001_1.fastq.gz rawReads/mPDL_RNA7D_Ko2_S1_L001_R2_001_2.fastq.gz -baseout trimmedReads/mPDL_RNA7D_Ko2_S1_L001_R2_001 ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/mPDL_RNA7D_Ko2_S1_L001trimming.log # Pipe and loop for all files. cat filenames.txt | parallel -j 4 &quot;trimmomatic PE rawReads/{}_1.fastq.gz rawReads/{}_2.fastq.gz -baseout trimmedReads/{} ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRAILING:3 MINLEN:36 2&gt; trimmedReads/{}trimming.log&quot; #Not successful. # In TrimmedRead run multiqc ls multiqc . # fastQC of trimmed files again? mkdir trimmedFastQC # rm -d trimmedFastQC # Make sure folder is in main folder, if not delete # Run fastqc... Trimmed files have no file extension. Why??? fastqc trimmedReads/* -o trimmedFastQC # .zip and qc html files will be created. Run multiqc cd trimmedFastQC multiqc . Alignment with STAR Download the Mouse genome form the NCBI page. See 1.3.4 Unzip the tar.gz file. FYI: This processes require a long time. # Check the correct environment. . /usr/local/anaconda3/bin/activate &amp;&amp; conda activate /usr/local/anaconda3/envs/rna-seq_test # Check the correct folder/directory. cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus_NCBI_build37.2.tar.gz&quot; #Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/Mus_musculus_NCBI_build37.2.tar.gz: Not a directory cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/60-499583816_60-501009934/Result/Mus Musculus/&quot; # Unzip file tar xvfz Mus_musculus_NCBI_build37.2.tar.gz Confirm that STAR is installed if not Install STAR. # Make sure of enviroment. STAR --help #If not found install. conda install STAR # Make sure is from &quot;bioconda&quot;. Preceed([y]/n)? message. y # Check again. Long list of flags. STAR --help # Create directory for starIndex. mkdir starIndex Run STAR 1st. Index Mus_Musculus whole genome, 2nd. Index Samples against Mus_Musculus Index. # Make sure that the unzip folder of Mus_musculus_NCBI_build37.2.tar.gz (Mus_musculus) is in the same directory as environment/analysis folder in this case: cd &quot;/Volumes/HD-PCFSU3-A/Experiments Data/Genewiz/Trial02/&quot; # Run STAR. Takes long time. wait until ..... finished successfully message appears. if not rerun again. STAR --runThreadN 64 --runMode genomeGenerate --genomeDir starIndex --genomeFastaFiles Mus_musculus/NCBI/build37.2/Sequence/WholeGenomeFasta/genome.fa --sjdbGTFfile Mus_musculus/NCBI/build37.2/Annotation/Genes/genes.gtf Align reads # create a new directory mkdir starAligned Git token "],["rna-seq-differentially-expressed-go-enrichment-and-pathway-analysis.html", "Chapter 4 RNA Seq Differentially Expressed, GO Enrichment, and Pathway analysis 4.1 Background 4.2 Cleaning Data 4.3 Differentially Expressed Sequence Identification 4.4 Interactions cause a difference between the lfc betwen pooled data, e.g. p53+/+ (control and IR) and p53-/- (control and IR) 4.5 7. GO Enrichment analysis using GOstats 4.6 8. Pathway analysis using expression data", " Chapter 4 RNA Seq Differentially Expressed, GO Enrichment, and Pathway analysis based on: for STAT736 Alex Soupir Tutorial ACSoupir/Bioinformatics_RNASeq/Mouse_RNA_Seq_p53_genotoxic.Rmd (Raw md file.) See here for full view: Mouse_RNA_Seq_p53_genotoxic.md. 4.1 Background For STAT736-Fall-2019, we are analyzing the RNA-Seq from the publication Genome-wide analysis of p53 transcriptional programs in B cells upon exposure to genotoxic stress in vivo. We are only using the sequences B cells from spleen and not the non-B cells from spleen from the SRA Run Selector on NCBI. The mice were exposed to whole-body ionizing radiation and sequences were extracted from both Bcells and non-B cells from the spleens of the mice. Two genotypes of mice were used: mice with p53 knocked out and the wild-type C57/Bl6. There were 4 different group combinations including the 2 different genotypes; each genotype was subjected to the ionizing radiation as well as control/mock. library(knitr) experimental_design = data.frame(&#39;Genotype&#39; = c(&#39;p53&#39;, &#39;C57/Bl6&#39;, &#39;p53&#39;, &#39;C57/Bl6&#39;), &#39;Treatment&#39; = c(&#39;Mock&#39;, &#39;Mock&#39;, &#39;IR&#39;, &#39;IR&#39;)) rownames(experimental_design) = c(&#39;Group 1&#39;, &#39;Group 2&#39;, &#39;Group 3&#39;, &#39;Group 4&#39;) library(kableExtra) library(reticulate) kable(experimental_design[1:4,1:2] #, &quot;latex&quot; , caption = &#39;Treatment groups of the mice that were either controls or treated with ionizing radiation to determine reaction of p53.&#39; #,booktabs = T ) %&gt;% kable_styling(latex_options = c(&quot;striped&quot;, &quot;repeat_header&quot;)) (#tab:experimental_design)Treatment groups of the mice that were either controls or treated with ionizing radiation to determine reaction of p53. Genotype Treatment Group 1 p53 Mock Group 2 C57/Bl6 Mock Group 3 p53 IR Group 4 C57/Bl6 IR This document will contain 2 different pipelines: The first one is going to be using the genome to map the reads too, and the secod is going to be de novo. Genome De novo ##Genome Mapping {#genome-mapping} The pipeline used in this analysis used conda on South Dakota State University’s High Performance Computing cluster to run the programs FastQC, Trimmomatic, and Tophat. This is different than previous RNA-Seq analyses where I used my workstation pc with Ubuntu 18.04 to run FastQC, Trimmomatic, HiSat2, HTSeq, and DESeq2 locally. Also, the previous RNA-Seq alayses were of Soybean with treatment combinations of mycorrhizae and rhizobia inoculation. 4.2 Cleaning Data 4.2.1 Programs used? FastQC Trimmomatic 0.39 Bowtie 2.2.5.0 Tophat 2.1.1 STAR Cufflinks Kraken2 MultiQC featureCount 4.2.1.1 Picking the right node To find a node that we can use on our own, we need to see which nodes are already allocated to jobs and which ones are idle. To do this, we can run sinfo. We want to pick one of the nodes that are marked ‘idle’ so we get the whole thing and we aren’t interrupting someone elses job. For the sake of this exercise, lets work on big-mem. Once a node that is idle has been found, you can ssh into it by typing ssh -X big-mem00# where # is the node number. ssh -X big-mem005 Once on the node, the modules will have to be pulled from the shared folder again, otherwise we will be left with very basic ones. NOTE: if running programs that are in a personal folder such as miniconda (these examples), it is not necessary to add the other modules. module use /cm/shared/modulefiles_local/ After loading the modules you can use it just as you would any other command line. 4.2.1.2 Creating slurm scripts When running on a cluster, it can sometime be difficult to find open nodes with the resources needed to run the jobs that we have. Making a slurm script is really easy. Fist we make a new file with the touch command. touch commands.slurm Now in our directory we have the file commands.slurm which we can edit to hold our code in. We can edit it with the vi command. vi commands.slurm We have a few things that we need to put in the file header so slurm knows what to do with our commands. #!/bin/bash #SBATCH --job-name=example #SBATCH --nodes=1 #SBATCH --ntasks-per-node=10 #SBATCH --output=job-%j-%N.log #SBATCH --partition=bigmem #SBATCH --time=10:00:00 When we break this down, we see –job-name which is what we will see when we look at whats running later, –nodes is the number of nodes we have, –ntasks-per-node is the number of cores that we are requesting to have allocated, –output is the output log file of the job (here it names the output file with the job number and the node that we used), –partition here is requesting a big-mem node but compute can also be used, and finally –time is how long we are requesting the allocation for. If the time runs out before the job is done I believe that it just kills the job even if not finished so we need to think a little about how much time to set. If the time is set too low, the job is killed and if the time is set too long, we may face issues with getting the node allocated to us. To submit a job we can use sbatch commands.slurm and then we have the job ID. To check the status of our submission we use sbatch and then it shows all of the submitted jobs and how long they have been running along with the name that we set in the script. 4.2.2 Acquiring sequences To download the sequences from the sequence read archive (SRA), the SRA Toolkit was used. The downloading of the files took a very long time, so this was left to run over night. The –gzip was used to keep the files a relatively small, although this can be left out to download uncompressed files, and –split-files was used to split the forward read from the reverse read for paired end read trimming through Trimmomatic. ~/tools/sratoolkit.2.9.6-1-centos_linux64/bin/fastq-dump --gzip --split-files SRR2121770 This is an example of the single file, but the above code needed to be ran for all of the following SRA numbers: SRR2121770 SRR2121771 SRR2121774 SRR2121775 SRR2121778 SRR2121779 SRR2121780 SRR2121781 SRR2121786 SRR2121787 SRR2121788 SRR2121789 The results from downloading with –split-files gives 2 files per SRR, as mentioned before, one forward and one reverse. The suffix of the split files is one with _1.fastq.gz and another with _2.fastq.gz. 4.2.3 FastQC FastQC can be run on all of the read files by using the wild card (*) as in *.fastq.gz. This prevents the need to hard code each individual read file into a FastQC command, which saves a lot of time since there are 24 read files in total for these 12 samples. ~/miniconda2/bin/fastqc *.fastq.gz The output from running FastQC is a zipped folder and an HTML file for each of the .gz files in the folder. The HTML document looks something like this: ![FastQC of Raw SRR2121770_1.fastq.gz Read](./TopFastQCRaw.PNG) This is just the top of the file, and every category under the Summary heading has a graph that shows how the read quality looks for that particular metric. These reports can give insight into whether the reads are of decent quality or if the quality is poor. The raw reads we have here all passed for adapter content and sequence length distribution and everything failed per base sequence content. SRR2121770, SRR2121771, SRR2121774, SRR2121775, SRR2121788, SRR2121781-2, and SRR2121789-1 were fairly decent quality reads. SRR2121778, SRR2121779, SRR2121780, SRR2121786, SRR2121787, SRR2121781-1, and SRR2121789-2 were of fairly lower quality (failing 3 or more in both reads. All of them failed both per base sequence quality and per tile sequence quality. 4.2.3.1 MultiQC First lets install multiqc with conda. The command for this is conda install -c bioconda multiqc. When that is finished, we can run MultiQC in the folder with the QC files (they should be moved into a folder alone so things don’t get cluttered later on in the analyses). ~/miniconda/bin/multiqc . When MultiQC is finished running, there will be a new folder called multiqc_data where the summaries are stored. Now lets go back up a level where our raw data folder and fastqc folder is and make a new folder for all of our MultiQC data. We will copy the FastQC output from MultiQC to this new folder. mkdir MultiQC_All cp RawQC/multiqc_data/multiqc_fastqc.txt MultiQC_All/ 4.2.4 Trimming with Trimmomatic Conda was used again to run Trimmomatic. This isn’t as easy as using the wildcard like with FastQC because each output has to be personalized for the read files that are input into Trimmomatic. Also, we have to make sure that the adapter sequences are in the same folder that we are running so we can refer to them easily when calling the Trimmomatic program. In this case, we are using the TruSeq3-PE-2.fa adapter sequences For example: ~/miniconda2/bin/trimmomatic PE SRR2121770_1.fastq.gz SRR2121770_2.fastq.gz 770_fp.fq.gz 770_fu.fq.gz 770_rp.fq.gz 770_ru.fq.gz ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:2keepBothReads LEADING:3 TRALING:3 MINLEN:36 &amp; This would be repeated for each of the pairs (12 in total). We are trimming paired-end reads with the TruSeq3-PE-2 adapters. We are chopping off the first and last 3 bases and if we end up with a sequence less than 36 bases, we get rid of it. We want to make sure that there are enough bases in a read to work with. These parameters can be tweaked for possibly better end results with less being discarded. When Trimmomatic is finished running, it will out put the total number of reads, the total number from both the forward and reverse reads that are kept, the number of only forward reads kept, the number of only reverse reads kept, and the number of discarded reads. The highest number of reads dropped was from trimming SRR2121786, where 20.55% dropped. Most reads were between 5% and 10% dropped. SRR2121786, SRR2121787, and SRR2121779 had sequence drops greater than 15%. The trimmed reads can be analyzed again with FastQC to see how well the trimming worked to make the file better quality. After running FastQC on the trimmed files we see that the quality of those that were really bad quality were improved. There were a few different metrics throughout all of the files that bounced from a warning before the failing, or from passing before to a warning, and so forth, overall creating better quality read files. 4.2.5 Alignment 4.2.5.1 Using Tophat Tophat can be installed using the same conda install (conda install -c bioconda tophat). When this is finished installing, then we will need to get the mouse genome from the Johns Hopkins Univeristy Center for computational BIology. The version of the mouse genome that I am using here is the NCBI build37.2. Instead of downloading this from the website and having to move it to the cluser, I will just download it using wget into the folder that has the raw reads, trimmed reads, and the FastQC files. wget ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Mus_musculus/NCBI/build37.2/Mus_musculus_NCBI_build37.2.tar.gz This will take a long time to download because the file is a little less than 16GB zipped. We notice here that we have a zipped tar file. To make this file easier to use, lets unzip it. tar zxvf Mus_muculus_NCBI_build37.2.tar.gz Since Tophat is requiring *.bt21 files (large index) and the files downloaded for the genome above are only small index files, we have to create a large index using bowtie2-build. For this, lets navigate to the WholeGenomeFasta folder within the extracted folder and then run bowtie2-build. ~/miniconda2/bin/bowtie2-build --large-index genome.fa genome This process took about 26 minutes to run. Now lets copy the index files to a folder close to our reads so we can access them easier, rather than having to refer to the longer path where we build them. After they are copied to a new folder closer to our working directory, I went ahead and unzipped the trimmed read files to try and make the Tophat faster but it turned out not to work. The multicore call with -p didn’t use more cores than 1 until bowtie2-align-s, then 20 cores were used. ~/miniconda2/bin/tophat --no-converage-search -p 20 -G Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf -0 770_thout ./Index/genome 770_fp.fq.gz 770_rp.fq.gz 770_fu.fq 770_ru.fq This run took almost 3 hours to complete.. Running with 80 cores rather than 20 cores took just 4 minutes less, so the whole process must be limited by a single core and the core clock speed. The process does use close to 8,000% at its peak so there is a benefit to multicore, just isn’t very scalable. 4.2.5.2 Using STAR STAR can be installed the same way as the previous programs with conda install (conda install -c bioconda star). In order to run STAR, we need to creaate indices just like with tophat, but STAR has this built in. I’m going to be using the same genome and GTF file as previously downloaded, but Dr. Ge uses a different zipped genome from the gencode database. ~/miniconda2/bin/STAR \\ --runThreadN 80 \\ --runMode genomeGenerate \\ --genomeDir starIndex \\ --genomeFastaFiles Index/genome.fa \\ #same when we made the bowtie indices --sjdbGTFfile Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf With the index files made, we can start aligning with STAR. It’s important here than we only pick the paired end reads and not use all of the reads. Tophat is able to use all 4 reads but STAR doesn’t allow that, so we need to make sure that we feed in the large files from trimming. ~/miniconda2/bin/STAR --runThreadN 80 --genomeDir starIndex --readFilesIn 770_fp.fq 770_rp.fq --outFilterIntronMotifs RemoveNoncanonical --outFileNamePrefix 2121770 --outSAMtype BAM SortedByCoordinate 4.2.6 Assembling transcripts with Cufflinks Once STAR is done running, we can assemble the transcripts with Cufflinks. This can also be installed with conda install (conda install -c bioconda cufflinks). ~/miniconda2/bin/cufflinks -p 20 -o SRR2121771_clout --library-type fr-firststrand 2121770Aligned.sortedByCoord.out.bam 4.2.7 Checking for Contamination 4.2.7.1 PhiX contamination Now we will look at what kind of contamination we are looking at. When samples are sequenced with Illumina, a PhiX control is run along side them. This control is for cluster generation, sequencing, alignment, and calibration for cross-talk matrix generation. We will use Bowtie to create a file to determine the PhiX contamination level. ~/miniconda2/bin/bowtie2 -p 20 -x PhiX/Illumina/RTA/Sequence/Bowtie2Index/genome \\ -1 TrimmedReads/770_fp.fq -2 TrimmedReads/770_rp.fq -S phix.sam &amp;&gt; PhiXout/SRR2121770_phix.out When the job is done running, the output file will show how much PhiX contamination we have. For example, lookin at the SRR2121770_phix.out created above, we see that 0.11% of the reads aligned with PhiX. The lower this value the better. 4.2.7.2 rRNA Sequences To retreive the rRNA sequences for mouse, we need to search the taxonomy database on NCBI for Mus musculus. Click on Mus musculus on the next page, and then the top Mus musculus at the head of the list. Now, select the top subtree link in the Nucleotide database. Select rRNA sequences on the left side of the page and download full list just downloading with Send &gt; Complete Record &gt; File &gt; FASTA &gt; Create File. Drag the file using WinSCP to the raw folder on the cluster and rename it to rRNA.fa. We are going to need to install bwa with conda in order to get the alignments to work. This can be done with conda install -c bioconda bwa. Following this, we will need to make indixes for the rRNA that we downloaded. To make this more clean, lets make a directory for the rRNA sequences that we downloaded and the indices that we make. mkdir rRNA Then we move the rRNA.fa to the new rRNA folder with WinSCP and then we can run the bwa. time ~/miniconda2/bin/bwa mem -t 20 rRNA/rRNA.fa TrimmedReads/770_fp.fq TrimmedReads/770_rp.fq &gt; rnaAlign/770_rna.sam When we are done creating the new *.sam files for all of the forward/reverse read combinations, we can use samtools to convert the *.sam file to *.bam files which are essentially the same file just that sam is easier for us to look at while bam is binary. Samtools can be installed with conda install -c bioconda samtools. ~/miniconda2/bin/samtools view -@ 10 -bS -o rnaAlign/770_rna.bam rnaAlign/770.sam Now in the rnaAlign folder we have our sam and bam file for each of the libraries. Lets create an output file with flagstat. ~/miniconda2/bin/samtools flagstat -@ 10 rnaAlign/770_rna.out Wihtin this file we will be able to see the summary of our alignments to the rRNA file that we downloaded from NCBI. #From 770_rna.out 205559289 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 85 + 0 supplementary 0 + 0 duplicates 4265179 + 0 mapped (2.07% : N/A) 205559204 + 0 paired in sequencing 102779602 + 0 read1 102779602 + 0 read2 4151684 + 0 properly paired (2.02% : N/A) 4187608 + 0 with itself and mate mapped 77486 + 0 singletons (0.04% : N/A) 4222 + 0 with mate mapped to a different chr 1026 + 0 with mate mapped to a different chr (mapQ&gt;=5) 4.2.7.3 Bacterial contamination In order to find out the contamination, we need to install Kraken2 with conda install -c bioconda kraken2 and download a pre-built database containing bacteria, archaea, and viral sequences. The database we are going to download only contains about 5% of k-mers from the original database (but directions are sort of lacking to build an entirely new database). More information can be found at https://ccb.jhu.edu/software/kraken/ for the pre-built databases. Using the code in the next chunk will download the 8GB database and then extract the files so we can use them with the Kraken2 program. Lets do this in the main project folder. wget ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/minikraken2_v2_8GB_201904_UPDATE.tgz tar xzf minikraken2_v2_8GB_201904_UPDATE.tgz Now lets make a directory for the output. mkdir krakenOut We can call Kraken with the extracted database folder and point it to the location of out paired end reads from trimming and to the output folder that we just created for the outputs. ~/miniconda2/bin/kraken2 --db minikraken2_v2_8GB_201904_UPDATE/ --output krakenOut/770.out --threads 10 --paired TrimmedReads/770_fp.fq TrimmedReads/770_rp.fq When Kraken is done running, it will print out the number (and percentage) of reads that were classified. In this case, we have used 102779602 sequences, of which 19142843 sequences were classified (18.63%) and 83636759 sequences were unclassified (81.37%). My interpretation of this is that 18.63% of the reads are possibly from microbial cell contamination. 4.2.8 Counting Transcripts Since we have the bam files from the alignments of the different samples, we can count the features for each and get the transcipt counts using featureCounts form conda install -c bioconda/label/cf201901 subread. The genome and annotations that we previously downloaded were from genome mm9 so we have to specify to featureCounts what we want to actually count. FeatureCounts defaults to using gene_id which our output bam files don’t have described correctly for featureCounts to read them. This is a single line of code because we can use a wildcard to run through all of the bam files. #Move to the Star Alignment output folder for a working directory cd StarOut ~/miniconda2/bin/featureCounts -a /gpfs/scratch/alex.soupir/Mus/raw/Mus_musculus/NCBI/build37.2/Annotation/Archives/archive-2015-07-17-14-32-40/Genes/genes.gtf -g &#39;transcript_id&#39; -o readCounds.txt *bam With the files that we are working with, this will take between 3.5 minutes to 5 minutes per bam file. The output will be a file that can be imported into excel and saved as csv which we then can work with in R. 4.2.8.1 Final QC of cleaning the data Lets look at the data that we have collected from all of the MultiQC runs that we had with initial FastQC, Trimmomatic, STAR alignment, PhiX contamination, rRNA contamination, and the final feature counts. qc = read.csv(&#39;Whole Data QC.csv&#39;, header=TRUE, na.strings=&quot;&quot;) kable(qc) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;800px&quot;) 4.3 Differentially Expressed Sequence Identification Programs Used R RStudio Packages readr (install.packages(‘readr’)) limma (BiocManager::install(‘limma’)) DESeq2 (BiocManager::install(‘DESeq2’)) dplyr (install.packages(“dplyr”)) ggplot2 (install.packages(“ggplot2”)) gplots (install.packages(“gplots”)) Annotations (BiocManager::install(‘AnnotationDbi’)) org.Hs.eg.db (BiocManager::install(‘org.Hs.eg.db’)) This is for Human org.Mm.eg.db (BiocManager::install(‘org.Mm.eg.db’)) This is for Mouse ggrepel (install.packages(“ggrepel”)) ReportingTools (BiocManager::install(‘ReportingTools’)) GO.db (BiocManager::install(‘GO.db’)) GOstats (BiocManager::install(‘GOstats’)) pathview (BiocManager::install(‘pathview’)) gage (BiocManager::install(‘gage’)) gageData (BiocManager::install(‘gageData’)) select (BiocManager::install(‘Select’)) With these, you most certainly will have to step through each and install extra things when you start calling the packages. Take it step by step to ensure that each dependency is installed. 4.3.1 Analyzing Reads Counts When the count file is completed, we can import it into R and start working with it to determine differentially expressed genes. First we will import it into R library(limma) library(DESeq2) library(dplyr) library(readr) countData = read_csv(&quot;readCounts.csv&quot;, skip = 1) This gives us our dataframe from out featureCounts program, but if we look at the data we see that featureCounts added some extra information that characterizes each gene_id. kable(head(countData)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;320px&quot;) We also need to set out row names to the gene_id. We will do some data frame manipulation and then look at the data again. countData = as.data.frame(countData) rownames(countData) = countData$Geneid countData = countData[,-c(1:6)] kable(head(countData)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) 4.3.1.1 Quick Data Exploration dim(countData) kable(summary(countData)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) Let’s also go ahead and change the names to describe out data a little better. columns = c(&#39;Trp53m_mock_1&#39;, &#39;Trp53m_mock_2&#39;, &#39;Trp53m_4h7Gy_1&#39;, &#39;Trp53m_4h7Gy_2&#39;, &#39;Trp53p_mock_1&#39;, &#39;Trp53p_mock_2&#39;, &#39;Trp53p_mock_3&#39;, &#39;Trp53p_mock_4&#39;, &#39;Trp53p_4h7Gy_1&#39;, &#39;Trp53p_4h7Gy_2&#39;, &#39;Trp53p_4h7Gy_3&#39;, &#39;Trp53p_4h7Gy_4&#39;) colnames(countData) = columns Here we have to make sure that we convert the +/+ and -/- to characters. These characters par(mar=c(8,4,4,1)+0.1) barplot( colSums(countData)/1e6, col=&quot;green&quot;,las=3,main=&quot;Total read counts (millions)&quot;, ylab=&quot;Total read counts in millions&quot;) hist(countData[,1], br=200, xlab=&quot;Number of Reads Counts per Feature&quot;, main=&quot;Histogram of Read Counts for Trp53-/- Mock&quot;) We can see that our count data is highly skewed to the right. This is a great case for using log transformation! logCountData = log2(1+countData) par(mfrow = c(1, 2), mar=c(8,4,4,1)) # two columns hist(logCountData[,1], main=&quot;Histogram of Log Read Counts&quot;, xlab=&quot;Log transformed counts&quot;) boxplot(logCountData,las=3, main=&quot;Boxplot of Log Read Counts&quot;) x &lt;- logCountData myColors = rainbow(dim(x)[2]) plot(density(x[,1]),col = myColors[1], lwd=2, xlab=&quot;Expresson values&quot;, ylab=&quot;Density&quot;, main= &quot;Distribution of transformed data&quot;, ylim=c(0, max(density(x[,1])$y)+.02 ) ) for( i in 2:dim(x)[2] ) lines(density(x[,i]),col=myColors[i], lwd=2) legend(&quot;topright&quot;, cex=1.1,colnames(x), lty=rep(1,dim(x)[2]), col=myColors ) plot(logCountData[,1],logCountData[,2], xlab=&quot;Trp53-/- mock replication 1&quot;, ylab=&quot;Trp53-/- mock replication 2&quot;) 4.3.1.2 Filtering, Normalization, and Trasformation using DESeq2 We have to make the experiment design into a small dataframe so we can tell DESeq how we want to analyze the data. Here will will make a small table that has the rep names that we changed the column names to previously, and then a column for which columns are Trp53+/+ or Trp53-/-, and which columns were control mice and which columns were treated with ionizing radiation. detectGroups &lt;- function (x){ # x are col names tem &lt;- gsub(&quot;[0-9]*$&quot;,&quot;&quot;,x) # Remove all numbers from end #tem = gsub(&quot;_Rep|_rep|_REP&quot;,&quot;&quot;,tem) tem &lt;- gsub(&quot;_$&quot;,&quot;&quot;,tem); # remove &quot;_&quot; from end tem &lt;- gsub(&quot;_Rep$&quot;,&quot;&quot;,tem); # remove &quot;_Rep&quot; from end tem &lt;- gsub(&quot;_rep$&quot;,&quot;&quot;,tem); # remove &quot;_rep&quot; from end tem &lt;- gsub(&quot;_REP$&quot;,&quot;&quot;,tem) # remove &quot;_REP&quot; from end return( tem ) } groups = as.character ( detectGroups( colnames( countData ) ) ) groups p53 = c(&quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;m&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;) treatment = c(&quot;control&quot;, &quot;control&quot;, &quot;IR&quot;, &quot;IR&quot;, &quot;control&quot;, &quot;control&quot;, &quot;control&quot;, &quot;control&quot;, &quot;IR&quot;, &quot;IR&quot;, &quot;IR&quot;, &quot;IR&quot;) colData = cbind(colnames(countData), p53 ) colData colData = as.data.frame(cbind(colnames(countData), p53, treatment)) colData str(colData) Creating a DESeq Dataset dds = DESeqDataSetFromMatrix(countData=countData, colData=colData, design= ~ p53+treatment+p53*treatment) # note that the study design is changed. dds = DESeq(dds) # main function nrow(dds) Filtering: we will only keep rows that have a sum count between all samples greater than 5. This will remove most of the genes that mostly have “0” counts. dds &lt;- dds[ rowSums(counts(dds)) &gt; 5, ] nrow(dds) Regularized log transformation - used for clustering rld &lt;- rlog(dds, blind = FALSE) kable(head(assay(rld), 6)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) Variance Stabilizing Transformation 4.4 Interactions cause a difference between the lfc betwen pooled data, e.g. p53+/+ (control and IR) and p53-/- (control and IR) vsd &lt;- vst(dds, blind = FALSE) kable(head(assay(vsd), 6)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) For the log2 approach, we need to first estimate size factors to account for sequencing depth, and then specify normalized=TRUE. Sequencing depth correction is done automatically for the rlog and the vst. Size Factor dds &lt;- estimateSizeFactors(dds) kable(sizeFactors(dds)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;300px&quot;, height = &quot;520px&quot;) We will first look at the log transformed data slog &lt;- log2(counts(dds, normalized=TRUE)+1) kable(head(slog)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) par(mfrow = c(1, 3)) # 3 columns plot(slog[,1],slog[,2]) plot(assay(rld)[,1],assay(rld)[,2]) plot(assay(vsd)[,1],assay(vsd)[,2]) As the log transformation constant increases, the information of the data is lost. par(mfrow = c(1, 3)) # 3 columns slog &lt;- log2(counts(dds, normalized=TRUE)+1) plot(slog[,1],slog[,2]) slog &lt;- log2(counts(dds, normalized=TRUE)+4) plot(slog[,1],slog[,2], xlim=c(0,20)) slog &lt;- log2(counts(dds, normalized=TRUE)+20) plot(slog[,1],slog[,2], xlim=c(0,20)) library(&quot;dplyr&quot;) library(&quot;ggplot2&quot;) df &lt;- bind_rows( as_data_frame(slog[,1:2]) %&gt;% mutate(transformation = &quot;log2(x + 1)&quot;), as_data_frame(assay(rld)[, 1:2]) %&gt;% mutate(transformation = &quot;rlog&quot;), as_data_frame(assay(vsd)[, 1:2]) %&gt;% mutate(transformation = &quot;vst&quot;)) colnames(df)[1:2] &lt;- c(&quot;x&quot;, &quot;y&quot;) ggplot(df, aes(x = x, y = y)) + geom_hex(bins = 80) + coord_fixed() + facet_grid( . ~ transformation) 4.4.1 Exploratory Data Analysis PCA plot plotPCA(rld, intgroup = c(&quot;p53&quot;, &quot;treatment&quot;)) + theme(aspect.ratio=1) A prettier PCA plot created with GGPlot2 pca.object &lt;- prcomp(t(assay(rld))) # PCA pcaData = as.data.frame(pca.object$x[,1:2]); pcaData = cbind(pcaData,detectGroups(colnames(assay(rld)) )) colnames(pcaData) = c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;Type&quot;) percentVar=round(100*summary(pca.object)$importance[2,1:2],0) #plot p=ggplot(pcaData, aes(PC1, PC2, color=Type, shape = Type)) + geom_point(size=5) p=p+xlab(paste0(&quot;PC1: &quot;,percentVar[1],&quot;% variance&quot;)) p=p+ylab(paste0(&quot;PC2: &quot;,percentVar[2],&quot;% variance&quot;)) p=p+ggtitle(&quot;Principal component analysis (PCA)&quot;)+coord_fixed(ratio=1.0)+ theme(plot.title = element_text(size = 16,hjust = 0.5)) + theme(aspect.ratio=1) + theme(axis.text.x = element_text( size = 16), axis.text.y = element_text( size = 16), axis.title.x = element_text( size = 16), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) print(p) Multidimensional Scaling Plot dist2 &lt;- function(x, ...) # distance function = 1-PCC (Pearson&#39;s correlation coefficient) as.dist(1-cor(t(x), method=&quot;pearson&quot;)) fit = cmdscale( dist2(t(assay(rld))) , eig=T, k=2) mdsData &lt;- as.data.frame(fit$points[,1:2]); mdsData &lt;- cbind(mdsData,detectGroups(colnames(assay(rld))) ) colnames(mdsData) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;Type&quot;) p&lt;-ggplot(mdsData, aes(x1, x2, color=Type, shape = Type)) + geom_point(size=5) p=p+xlab(&quot;Dimension 1&quot;) p=p+ylab(&quot;Dimension 2&quot;) p=p+ggtitle(&quot;Multidimensional scaling (MDS)&quot;)+ coord_fixed(ratio=1.)+ theme(plot.title = element_text(hjust = 0.5)) + theme(aspect.ratio=1) + theme(axis.text.x = element_text( size = 16), axis.text.y = element_text( size = 16), axis.title.x = element_text( size = 16), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) print(p) Creating a heatmap library(gplots) hclust2 &lt;- function(x, method=&quot;average&quot;, ...) # average linkage in hierarchical clustering hclust(x, method=method, ...) n=100 # number of top genes by standard deviation x = assay(rld) if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data x = x[order(apply(x,1,sd),decreasing=TRUE),] # sort genes by standard deviation x = x[1:n,] # only keep the n genes # this will cutoff very large values, which could skew the color x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) cutoff = median(unlist(x)) + 4*sd (unlist(x)) x[x&gt;cutoff] &lt;- cutoff cutoff = median(unlist(x)) - 4*sd (unlist(x)) x[x&lt; cutoff] &lt;- cutoff groups = detectGroups(colnames(x) ) groups.colors = rainbow(length(unique(groups) ) ) lmat = rbind(c(5,4),c(0,1),c(3,2)) lwid = c(1.5,4) lhei = c(1,.2,4) heatmap.2(x, distfun = dist2,hclustfun=hclust2, col=greenred(75), density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.5 ,key=T, symkey=F ,ColSideColors=groups.colors[ as.factor(groups)] ,margins=c(8,12) ,cexRow=1 ,srtCol=45 ,cexCol=1. # size of font for sample names ,lmat = lmat, lwid = lwid, lhei = lhei ) 4.4.2 Identification of Differentially Expressed Genes dds &lt;- DESeq(dds) res &lt;- results(dds) kable(head(res)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) DESeq2 uses the Benjamini-Hochberg (BH) adjustment (Benjamini and Hochberg 1995) as implemented in the base R p.adjust function res &lt;- results(dds, alpha = 0.5, lfcThreshold=0.01) summary(res) Now lets sort genes by fold change res &lt;- res[order(abs( res$log2FoldChange), decreasing=TRUE),] kable(head(res)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) MA Plot Show the significant genes. The lower the average read counts for all samples and the higher the variation between the samples, the less significant those genes are. DESeq2::plotMA(res, ylim = c(-5, 5)) Volcano plot library(dplyr) res1 = as.data.frame(res) # add a new column using the mutate function in dplyr res1 = mutate(res1, sig=ifelse(res1$padj&lt;0.05, &quot;FDR&lt;0.05&quot;, &quot;Not Sig&quot;)) res1[which(abs(res1$log2FoldChange)&lt;0.5),&#39;sig&#39;] &lt;- &quot;Not Sig&quot; p = ggplot(res1, aes(log2FoldChange, -log10(padj))) + geom_point(aes(col=sig)) + scale_color_manual(values=c(&quot;red&quot;, &quot;black&quot;)) p 4.4.3 Gene Annotations Plot counts of top gene topGene &lt;- rownames(res)[1] plotCounts(dds, gene = topGene, intgroup=c(&quot;p53&quot;, &quot;treatment&quot;)) Here we see an interesting point or our normalized counts under the Trp53p_4h7Gy group that seems to be extremely high, while the other 3 replicates are around 0.5. I cannot get this portion to work, however. I get an error stating that None of the keys entered are valid keys for ‘SYMBOL.’ Let’s look at the keys that we have to work with for our res file from DESeq2 head(row.names(res)) Now we need to find the same key in the Mm database. library(AnnotationDbi) library(org.Mm.eg.db) columns(org.Mm.eg.db) #key = gsub(&quot;\\\\..*&quot;,&quot;&quot;, row.names(res)) res$symbol &lt;- gsub(&quot;\\\\..*&quot;,&quot;&quot;, row.names(res)) #res$symbol &lt;- gsub(&quot; &quot;,&quot;&quot;,row.names(res)) message(&quot;Ensembl IDs&quot;) key.en = keys(org.Mm.eg.db, keytype=&quot;ENSEMBL&quot;) head(key.en) cat(&quot;\\n\\n&quot;) message(&quot;SYMBOL names&quot;) key.sy = keys(org.Mm.eg.db, keytype=&quot;SYMBOL&quot;) head(key.sy) These are ENSEMBL symbols, so we need to designate that when looking for the genes that we have. res$ensembl &lt;- gsub(&quot;\\\\..*&quot;,&quot;&quot;, row.names(res)) res$entrez &lt;- mapIds(org.Mm.eg.db, keys= res$ensembl, column=&quot;ENTREZID&quot;, keytype=&quot;ENSEMBL&quot;, #Out ID is ENSMBL multiVals=&quot;first&quot;) res$symbol &lt;- mapIds(org.Mm.eg.db, keys= res$ensembl, column=&quot;SYMBOL&quot;, keytype=&quot;ENSEMBL&quot;, #Out ID is ENSMBL multiVals=&quot;first&quot;) write.csv(res, file = &quot;results.csv&quot;) kable(head(res)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) Let’s make a file with just the genes with an adjusted p-value &lt; 0.5 resSig = as.data.frame(subset(res,padj&lt;0.5) ) resSig = resSig[order(resSig$log2FoldChange,decreasing=TRUE),] head(resSig) write.csv(resSig,&quot;SigGenes.csv&quot;) Here is a volcano plot that shows the symbol that we created at each point. library(dplyr) res1 = as.data.frame(res) # add a new column using the mutate function in dplyr res1 = mutate(res1, sig=ifelse(res1$padj&lt;0.5, &quot;FDR&lt;0.05&quot;, &quot;Not Sig&quot;)) res1[which(abs(res1$log2FoldChange)&lt;1),&#39;sig&#39;] &lt;- &quot;Not Sig&quot; p = ggplot(res1, aes(log2FoldChange, -log10(pvalue))) + geom_point(aes(col=sig)) + scale_color_manual(values=c(&quot;red&quot;, &quot;black&quot;)) p+geom_text(data=filter(res1, padj&lt;1e-50), aes(label=symbol)) library(dplyr) # Install ggrepel package if needed # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;slowkow/ggrepel&quot;) library(ggrepel) # &quot;repels&quot; overlapping text p+geom_text_repel(data=filter(res1, abs(log2FoldChange)&gt;10 | padj &lt; 1e-50 ), aes(label=symbol)) library(&quot;ReportingTools&quot;) htmlRep &lt;- HTMLReport(shortName=&quot;report&quot;, title=&quot;My report&quot;, reportDirectory=&quot;./report&quot;) publish(resSig, htmlRep) url &lt;- finish(htmlRep) #browseURL(url) 4.5 7. GO Enrichment analysis using GOstats Here we will do a GO Enrichment analysis for genes that have a decreased fold-change of 5 or more library(GO.db) library(GOstats) selectedGenes = unique(resSig[resSig$log2FoldChange&gt;5,&#39;entrez&#39;]) # upregulated genes universeGenes = unique( mapIds(org.Mm.eg.db, keys= res$ensembl, column=&quot;ENTREZID&quot;, keytype=&quot;ENSEMBL&quot;, #Out ID is ENSMBL multiVals=&quot;first&quot;) ) hgCutoff &lt;- 0.001 params &lt;- new(&quot;GOHyperGParams&quot;, geneIds=selectedGenes, universeGeneIds=universeGenes, annotation=&quot;org.Mm.eg.db&quot;, ontology=&quot;BP&quot;, pvalueCutoff=hgCutoff, conditional=FALSE, testDirection=&quot;over&quot;) hgOver &lt;- hyperGTest(params) summary(hgOver)[1:10,] summary(hgOver)[1:10,c(&quot;GOBPID&quot;,&quot;Pvalue&quot;,&quot;Term&quot;)] params1 &lt;- params ontology(params1) &lt;- &quot;CC&quot; hgOver &lt;- hyperGTest(params1) summary(hgOver)[1:10,c(&quot;GOCCID&quot;,&quot;Pvalue&quot;,&quot;Term&quot;)] params1 &lt;- params ontology(params1) &lt;- &quot;MF&quot; hgOver &lt;- hyperGTest(params1) summary(hgOver)[1:10,c(&quot;GOMFID&quot;,&quot;Pvalue&quot;,&quot;Term&quot;)] 4.5.1 GO Enrichment analysis of downregulated genes Next we will have a look at the genes that are upregulated by a fold-change of 5 or greater. selectedGenes = unique(resSig[resSig$log2FoldChange&lt;5,&#39;entrez&#39;]) # upregulated genes params &lt;- new(&quot;GOHyperGParams&quot;, geneIds=selectedGenes, universeGeneIds=universeGenes, annotation=&quot;org.Mm.eg.db&quot;, ontology=&quot;BP&quot;, pvalueCutoff=hgCutoff, conditional=FALSE, testDirection=&quot;over&quot;) hgOver &lt;- hyperGTest(params) summary(hgOver)[1:10,c(&quot;GOBPID&quot;,&quot;Pvalue&quot;,&quot;Term&quot;)] 4.6 8. Pathway analysis using expression data # bioconductor packages # source(&quot;https://bioconductor.org/biocLite.R&quot;); # biocLite(c(&quot;pathview&quot;,&quot;gage&quot;,&quot;gageData&quot;)) library(pathview) library(gage) 4.6.1 Prepare data foldchanges = res$log2FoldChange names(foldchanges) = res$entrez head(foldchanges) library(gageData) data(go.sets.mm) data(go.subs.mm) gobpsets = go.sets.mm[go.subs.mm$BP] gobpres = gage(foldchanges, gsets=gobpsets, same.dir=TRUE) #lapply(gobpres, head) message(&quot;Greater&quot;) kable(head(gobpres$greater)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Less&quot;) kable(head(gobpres$less)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Stats&quot;) kable(head(gobpres$stats)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) 4.6.2 KEGG pathways library(gageData) data(kegg.sets.mm) data(sigmet.idx.mm) kegg.sets.mm = kegg.sets.mm[sigmet.idx.mm] #head(kegg.sets.mm, 3) message(&quot;Greater&quot;) kable(head(kegg.sets.mm$greater)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Less&quot;) kable(head(kegg.sets.mm$less)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Stats&quot;) kable(head(kegg.sets.mm$stats)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) # Get the results keggres = gage(foldchanges, gsets=kegg.sets.mm, same.dir=TRUE) # Look at both up (greater), down (less), and statatistics. #lapply(keggres, head, n=10) message(&quot;Greater&quot;) kable(head(keggres$greater)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Less&quot;) kable(head(keggres$less)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) message(&quot;Stats&quot;) kable(head(keggres$stats)) %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;1000px&quot;, height = &quot;300px&quot;) # Get the pathways keggrespathways = data.frame(id=rownames(keggres$less), keggres$less) %&gt;% tbl_df() %&gt;% filter(row_number()&lt;=5) %&gt;% .$id %&gt;% as.character() keggrespathways # Get the IDs. keggresids = substr(keggrespathways, start=1, stop=8) keggresids # Define plotting function for applying later plot_pathway = function(pid) pathview(gene.data=foldchanges, pathway.id=pid, species=&quot;mmu&quot;, new.signature=FALSE) # plot multiple pathways (plots saved to disk and returns a throwaway list object) tmp = sapply(keggresids, function(pid) pathview(gene.data=foldchanges, pathway.id=pid, species=&quot;mmu&quot;)) 4.6.3 Pathway and regulation of genes for Oxidative phosphorylation. ![Oxidative Phosphorylation](./Mouse_RNA_Seq_p53_genotoxic_files/figure-html/mmu00190.pathview.png) 4.6.4 Pathway and regulation of genes for Glycosylphosphatidylinositol(GPI)-anchor biosynthesis. ![Glycosylphosphatidylinositol(GPI)-anchor biosynthesis](./Mouse_RNA_Seq_p53_genotoxic_files/figure-html/mmu00563.pathview.png) 4.6.5 Pathway and regulation of genes for RNA polymerase. ![RNA polymerase](./Mouse_RNA_Seq_p53_genotoxic_files/figure-html/mmu03020.pathview.png) 4.6.6 Pathway and regulation of genes for Nucleotide excision repair. ![Nucleotide excision repair](./Mouse_RNA_Seq_p53_genotoxic_files/figure-html/mmu03420.pathview.png) 4.6.7 Pathway and regulation of genes for Non-homologous end-joining. ![Non-homologous end-joining](./Mouse_RNA_Seq_p53_genotoxic_files/figure-html/mmu03450.pathview.png) ##De novo Assembly {#denovo-assembly} AT THIS TIME, MINICONDA3 WAS INSTALLED SO FURTHER TOOLS ARE ALL INSTALLED UNDER THIS Having the genome for RNA-sequencing analysis is very useful, but sometimes it is not available so de novo assembly is used. de novo assembly is using the reads from sequencing to create longer seqeunces called contigs (contiguous sequences). These sequences are then compared to a protein database to get an idea of what proteins are possibly present. The raw sequences are also mapped back to the contigs, treating the contigs as the “genome,” much like we do when we have the genome from the host available. Lets jump right into it. We are going to be using Trinity for the de novo assembly and analysis because there are many tools built into the Trinity tool that allow for the building of contigs, counting of sequences, and even DeSeq/edgeR analyses. To install Trinity, all I did was ran conda install -c bioconda trinity. This installs all of the previously mentioned tools in one go. In addition to Trinity, BLAST (conda install -c bioconda blast) and RSEM (conda install -c bioconda rsem) were installed. Trinity --seqType fq \\ --left trimmedReads/SRR2121770_Trimmed_1P.fq.gz,trimmedReads/SRR2121771_Trimmed_1P.fq.gz,trimmedReads/SRR2121774_Trimmed_1P.fq.gz,trimmedReads/SRR2121775_Trimmed_1P.fq.gz,trimmedReads/SRR2121778_Trimmed_1P.fq.gz,trimmedReads/SRR2121779_Trimmed_1P.fq.gz,trimmedReads/SRR2121780_Trimmed_1P.fq.gz,trimmedReads/SRR2121781_Trimmed_1P.fq.gz,trimmedReads/SRR2121786_Trimmed_1P.fq.gz,trimmedReads/SRR2121787_Trimmed_1P.fq.gz,trimmedReads/SRR2121788_Trimmed_1P.fq.gz,trimmedReads/SRR2121789_Trimmed_1P.fq.gz \\ --right trimmedReads/SRR2121770_Trimmed_2P.fq.gz,trimmedReads/SRR2121771_Trimmed_2P.fq.gz,trimmedReads/SRR2121774_Trimmed_2P.fq.gz,trimmedReads/SRR2121775_Trimmed_2P.fq.gz,trimmedReads/SRR2121778_Trimmed_2P.fq.gz,trimmedReads/SRR2121779_Trimmed_2P.fq.gz,trimmedReads/SRR2121780_Trimmed_2P.fq.gz,trimmedReads/SRR2121781_Trimmed_2P.fq.gz,trimmedReads/SRR2121786_Trimmed_2P.fq.gz,trimmedReads/SRR2121787_Trimmed_2P.fq.gz,trimmedReads/SRR2121788_Trimmed_2P.fq.gz,trimmedReads/SRR2121789_Trimmed_2P.fq.gz \\ --CPU 80 --max_memory 2000G --min_contig_length 150 TrinityStats.pl trinity_out_dir/Trinity.fasta ################################ ## Counts of transcripts, etc. ################################ Total trinity &#39;genes&#39;: 602870 Total trinity transcripts: 730297 Percent GC: 45.89 ######################################## Stats based on ALL transcript contigs: ######################################## Contig N10: 8589 Contig N20: 5955 Contig N30: 4400 Contig N40: 3276 Contig N50: 2413 Median contig length: 413 Average contig: 1028.24 Total assembled bases: 750921120 ##################################################### ## Stats based on ONLY LONGEST ISOFORM per &#39;GENE&#39;: ##################################################### Contig N10: 5470 Contig N20: 3434 Contig N30: 2391 Contig N40: 1741 Contig N50: 1285 Median contig length: 343 Average contig: 703.04 Total assembled bases: 423841627 bowtie2-build trinity_out_dir/Trinity.fasta trinity_out_dir/Trinity.fasta bowtie2 --local --no-unal -x trinity_out ##download uniprot swiss-prot db ##ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz gunzip uniprot_sprot.fasta.gz mkdir -p blast_protdb mv uniprot_sprot.fasta blast_protdb/. makeblastdb -in uniprot_sprot.fasta -dbtype prot cd .. blastx -query trinity_out_dir/Trinity.fasta -db blast_protdb/uniprot_sprot.fasta -out blastx.outfmt6 -evalue 1e-20 -num_threads 80 -max_target_seqs 1 -outfmt 6 analyze_blastPlus_topHit_coverage.pl blastx.outfmt6 trinity_out_dir/Trinity.fasta blast_protdb/uniprot_sprot.fasta | column -t #hit_pct_cov_bin count_in_bin &gt;bin_below 100 7361 7361 90 1117 8478 80 981 9459 70 971 10430 60 1003 11433 50 865 12298 40 924 13222 30 1102 14324 20 1478 15802 10 932 16734 $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121770_1.fastq.gz -2 rawReads/SRR2121770_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121770.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121771_1.fastq.gz -2 rawReads/SRR2121771_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121771.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121774_1.fastq.gz -2 rawReads/SRR2121774_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121774.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121775_1.fastq.gz -2 rawReads/SRR2121775_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121775.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121778_1.fastq.gz -2 rawReads/SRR2121778_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121778.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121779_1.fastq.gz -2 rawReads/SRR2121779_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121779.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121780_1.fastq.gz -2 rawReads/SRR2121780_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121780.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121781_1.fastq.gz -2 rawReads/SRR2121781_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121781.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121786_1.fastq.gz -2 rawReads/SRR2121786_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121786.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121787_1.fastq.gz -2 rawReads/SRR2121787_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121787.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121788_1.fastq.gz -2 rawReads/SRR2121788_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121788.coordSorted.bam $ bowtie2 --local --no-unal -x trinity_out_dir/Trinity.fasta -q -1 rawReads/SRR2121789_1.fastq.gz -2 rawReads/SRR2121789_2.fastq.gz --threads 10 | samtools view --threads 10 -Sb - | samtools sort --threads 10 -o SRR2121789.coordSorted.bam $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121770_1.fastq.gz --right rawReads/SRR2121770_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121770.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121771_1.fastq.gz --right rawReads/SRR2121771_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121771.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121774_1.fastq.gz --right rawReads/SRR2121774_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121774.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121775_1.fastq.gz --right rawReads/SRR2121775_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121775.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121778_1.fastq.gz --right rawReads/SRR2121778_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121778.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121779_1.fastq.gz --right rawReads/SRR2121779_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121779.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121780_1.fastq.gz --right rawReads/SRR2121780_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121780.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121781_1.fastq.gz --right rawReads/SRR2121781_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121781.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121786_1.fastq.gz --right rawReads/SRR2121786_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121786.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121787_1.fastq.gz --right rawReads/SRR2121787_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121787.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121788_1.fastq.gz --right rawReads/SRR2121788_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121788.RSEM $ time align_and_estimate_abundance.pl --seqType fq --thread_count $SLURM_NTASKS --left rawReads/SRR2121789_1.fastq.gz --right rawReads/SRR2121789_2.fastq.gz --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie2 --trinity_mode --prep_reference --output_dir SRR2121789.RSEM time abundance_estimates_to_matrix.pl --est_method RSEM --out_prefix Trinity_trans SRR2121770.RSEM/SRR2121770.RSEM.trans.results \\ SRR2121771.RSEM/SRR2121771.RSEM.trans.results \\ SRR2121774.RSEM/SRR2121774.RSEM.trans.results \\ SRR2121775.RSEM/SRR2121775.RSEM.trans.results \\ SRR2121778.RSEM/SRR2121778.RSEM.trans.results \\ SRR2121779.RSEM/SRR2121779.RSEM.trans.results \\ SRR2121780.RSEM/SRR2121780.RSEM.trans.results \\ SRR2121781.RSEM/SRR2121781.RSEM.trans.results \\ SRR2121786.RSEM/SRR2121786.RSEM.trans.results \\ SRR2121787.RSEM/SRR2121787.RSEM.trans.results \\ SRR2121788.RSEM/SRR2121788.RSEM.trans.results \\ SRR2121789.RSEM/SRR2121789.RSEM.trans.results --gene_trans_map none time abundance_estimates_to_matrix.pl --est_method RSEM --out_prefix Trinity_genes SRR2121770.RSEM/SRR2121770.RSEM.genes.results \\ SRR2121771.RSEM/SRR2121771.RSEM.genes.results \\ SRR2121774.RSEM/SRR2121774.RSEM.genes.results \\ SRR2121775.RSEM/SRR2121775.RSEM.genes.results \\ SRR2121778.RSEM/SRR2121778.RSEM.genes.results \\ SRR2121779.RSEM/SRR2121779.RSEM.genes.results \\ SRR2121780.RSEM/SRR2121780.RSEM.genes.results \\ SRR2121781.RSEM/SRR2121781.RSEM.genes.results \\ SRR2121786.RSEM/SRR2121786.RSEM.genes.results \\ SRR2121787.RSEM/SRR2121787.RSEM.genes.results \\ SRR2121788.RSEM/SRR2121788.RSEM.genes.results \\ SRR2121789.RSEM/SRR2121789.RSEM.genes.results --gene_trans_map none contig_Exn50_statistic.pl Trinity_trans.TMM.EXPR.matrix trinity_out_dir/Trinity.fasta &gt; ExN50_trans.stats Make samples.txt mock- SRR2121770.RSEM mock- SRR2121771.RSEM IR- SRR2121774.RSEM IR- SRR2121775.RSEM mock+ SRR2121778.RSEM mock+ SRR2121779.RSEM mock+ SRR2121780.RSEM mock+ SRR2121781.RSEM IR+ SRR2121786.RSEM IR+ SRR2121787.RSEM IR+ SRR2121788.RSEM IR+ SRR2121789.RSEM The way that the installed version of run_DE_analysis.pl tries to install or check for edgeR doesn’t work for the new versions of R (3.6.1). In the perl script I just had to edit a few lines under the edgeR section for it to run smoothly, as well as install *BiocManager before hand. I changed the perl script, under sub run_edgeR_sample_pair, when writing the R script to look like: print $ofh &quot;if (! require(edgeR)) {\\n&quot;; print $ofh &quot; install.packages(\\&quot;BiocManager\\&quot;)\\n&quot;; print $ofh &quot; BiocManager::install(\\&quot;edgeR\\&quot;)\\n&quot;; print $ofh &quot; library(edgeR)\\n&quot;; print $ofh &quot;}\\n\\n&quot;; To make sure BiocManager and edgeR work, they were installed in the R terminal. R #runs the installed version of R in terminal mode install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;edgeR&quot;) Since we don’t have at least 3 replicates for each of the treatments, edgeR wants a dispersion parameter. 0.035 seems to be pretty common. If the dispersion parameter has the squareroot taken of it we get ~ 0.19, meaning that we are saying the true abundance for each gene can vary up or down by 19% between replicates. run_DE_analysis.pl --matrix Trinity_trans.counts.matrix --method edgeR --output edgeR_trans --dispersion 0.035 --samples_file samples.txt head edgeR_trans/Trinity_trans.counts.matrix.IR-_vs_mock-.edgeR.DE_results | column -t sampleA sampleB logFC logCPM PValue FDR TRINITY_DN2468_c0_g4_i1 IR- mock- -14.7753615825754 4.45315041918 5.51021995613131e-115 5.85185359341145e-110 TRINITY_DN2505_c0_g1_i2 IR- mock- -10.1817621187735 4.11815268306374 8.54695600746168e-88 4.53843363996215e-83 TRINITY_DN3231_c0_g2_i15 IR- mock- -13.5922145319911 3.27307743751541 6.29068575237937e-81 2.2269027563423e-76 TRINITY_DN4975_c0_g1_i7 IR- mock- 13.4941229058571 3.17132827495398 5.25978730838885e-79 1.39647353037724e-74 TRINITY_DN4360_c0_g1_i5 IR- mock- -13.5215746751431 3.20272600532575 1.0222845072488e-70 2.17133229339645e-66 TRINITY_DN128_c0_g1_i20 IR- mock- 13.1582688371709 2.83599676163376 1.8443766792831e-69 3.26454672233108e-65 TRINITY_DN644_c1_g1_i6 IR- mock- -5.91850038396836 4.31456225100214 8.01440426808572e-67 1.21589961895815e-62 TRINITY_DN2043_c0_g1_i13 IR- mock- 13.7803059024088 3.45719012794474 3.30519380237759e-66 4.38764477265625e-62 TRINITY_DN3321_c0_g1_i2 IR- mock- 12.8215942182179 2.49995284585527 9.5059376972195e-61 1.1217006482719e-56 #BiocManager::install(&quot;EnsDb.Mmusculus.v79&quot;) library(GO.db) library(GOstats) library(EnsDb.Mmusculus.v79) res.3 = subset(res.2, !is.na(res.2$entrezgene_id)) selectedGenes = unique(resSig[resSig$log2FoldChange&gt;0,&#39;entrezgene_id&#39;]) # upregulated genes universeGenes = unique( mapIds(org.Mm.eg.db, keys=gsub(&quot;\\\\.[0-9]*$&quot;,&quot;&quot;,res.3$entrezgene_id), # this is causing problems for mapping column=&quot;ENSEMBL&quot;, keytype=&quot;SYMBOL&quot;, multiVals=&quot;first&quot;) ) hgCutoff &lt;- 0.001 params &lt;- new(&quot;GOHyperGParams&quot;, geneIds=selectedGenes, universeGeneIds=universeGenes, annotation=&quot;org.Hs.eg.db&quot;, ontology=&quot;BP&quot;, pvalueCutoff=hgCutoff, conditional=FALSE, testDirection=&quot;over&quot;) hgOver &lt;- hyperGTest(params) summary(hgOver)[1:10,] #BiocManager::install(&quot;AnnotationHub&quot;) library(AnnotationHub) hub = AnnotationHub() query(hub, c(&quot;Medicago&quot;, &quot;OrgDb&quot;)) Mt.orgdb = hub[[&quot;AH72235&quot;]] Mt.orgdb #BiocManager::install(&quot;AnnotationHub&quot;) library(AnnotationHub) hub = AnnotationHub() query(hub, c(&quot;Glycine&quot;, &quot;OrgDb&quot;)) Gm.orgdb = hub[[&quot;AH72142&quot;]] Gm.orgdb library(AnnotationDbi) keytypes(Mt.orgdb) #key.Gm = keys(Mt.orgdb, keytype=&quot;GENENAME&quot;) #head(key.Gm) "],["rna-seq-mkdata.html", "Chapter 5 RNA-Seq-MKdata 5.1 PCA 5.2 Differential expression 5.3 RNA-seq (ScienceparkSG) 5.4 False discovery rates FDR / Benjamini-Hocheberg method 5.5 Volcano plot 5.6 Heatmap &amp; normalization 5.7 MA plots 5.8 Eastern New Mexico University ENMU method", " Chapter 5 RNA-Seq-MKdata 5.1 PCA # PCA of Raw count file # Load the data file (count) -------- # all_tpmCSV &lt;- read.csv (&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/all.tpm02.csv&quot;, header = T, row.names=1) library(readxl) all_raw_count &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/all.raw.count.xlsx&quot;) head(all_raw_count) class(all_raw_count) dim(all_raw_count) all_raw_count00 &lt;- all_raw_count %&gt;% column_to_rownames(var=&quot;GeneID&quot;) # Extract column names. colnames &lt;- colnames(all_raw_count) colnames # “r convert list to comma separated string” paste(shQuote(colnames), collapse=&quot;, &quot;) # with quotes. paste(colnames, collapse = &quot;,&quot;) # without quotes. excluded_vars &lt;- c(&quot;GeneName&quot;, &quot;Chr&quot;, &quot;Start&quot;, &quot;End&quot;, &quot;Strand&quot;, &quot;Length&quot; ) library(dplyr) # for select function all_raw_count01 &lt;- select(all_raw_count, -excluded_vars) # it works, but... better use: all_raw_count01 &lt;- select(all_raw_count, -all_of(excluded_vars)) #exclude all variables in excluded_vars head(all_raw_count01) dim(all_raw_count01) class(all_raw_count01) # data.frame # df preparation -------- # Convert values of a column into row names in a df. Source: https://stackoverflow.com/questions/5555408/convert-the-values-in-a-column-into-row-names-in-an-existing-data-frame library(tidyverse) # Method01 # rownames(all_raw_count01) &lt;- all_raw_count01[,1] # Converting first column into row names.* Column will still remain. # all_raw_count01[,1] &lt;- NULL # Erasing 1st column. # all_raw_count01 # Method03: #Worked!! all_raw_count01 &lt;- all_raw_count01 %&gt;% column_to_rownames(var=&quot;GeneID&quot;) # Source: https://www.geeksforgeeks.org/convert-values-in-column-into-row-names-of-dataframe-in-r/ head(all_raw_count01 [,1:5]) # Quick exploration of the data ---------- all_raw_count01 &lt;- na.omit(all_raw_count01) # delete all rows with NA # all_raw_count01_matrix &lt;- as.matrix(all_raw_count01) #convert df into matrix. boxplot(all_raw_count01, las= 2, main = &quot;Count raw 47&quot;) # To many outlier and variation, better work with the log scale. all_raw_count01_log &lt;- log(all_raw_count01+1) #here log +1 because the log of 0 = infinity and we will not be able to see the data. boxplot(all_raw_count01_log, las = 2, col = &quot;lightblue&quot;, ylim=c(-1,15), main = &quot;Count raw log 49&quot;) # las =2 to make the x labels vertically aligned. # Histograms of especific samples. mPDL_RNA14D_Ko1 &lt;- all_raw_count01_log[,1] mPDL_RNA14D_Ko2 &lt;- all_raw_count01_log[,2] mPDL_RNA14D_WT1 &lt;- all_raw_count01_log[,5] hist(mPDL_RNA14D_Ko1, col = &quot;red&quot;) hist(mPDL_RNA14D_Ko2, col = &quot;yellow&quot;) hist(mPDL_RNA14D_WT1, col = &quot;green&quot;, main = paste(&quot;Count raw 14Ko1, 14Ko2, 14Wt1 54&quot;), add=T) # df clean/filter of non expresed genes ------------------ # If Center and Scale needed, remove all rows containing all 0 values. # df1[rowSums(df1[])&gt;0,] all_raw_count02 &lt;- all_raw_count01[rowSums(all_raw_count01[])&gt;0,] head(all_raw_count02 [,1:5]) boxplot(all_raw_count02, las= 2, main = &quot;Count raw no 0 :67&quot;) all_raw_count02_log &lt;- log(all_raw_count02+1) #here log +1 because the log of 0 = infinity and we will not be able to see the data. boxplot(all_raw_count02_log, las = 2, col = &quot;green&quot;, ylim=c(-1,15), main = &quot;Count raw no 0 log :69&quot;) # las =2 to make the x labels vertically aligned. mPDL_RNA14D_Ko1_02 &lt;- all_raw_count02_log[,1] mPDL_RNA14D_Ko2_02 &lt;- all_raw_count02_log[,2] mPDL_RNA14D_WT1_02 &lt;- all_raw_count02_log[,5] col1 &lt;- rgb(1,0,0, 0.5) # red col2 &lt;- rgb(1,1,0, 0.5) # yellow col3 &lt;- rgb(0,0,1, 0.5) # blue col4 &lt;- rgb(0,1,0, 0.5) # green # Histograms hist(mPDL_RNA14D_Ko1_02, col = col1, breaks = 40) hist(mPDL_RNA14D_Ko2_02, col = col2, breaks = 40) hist(mPDL_RNA14D_WT1_02, col = col3, breaks = 40, add=T) # Density Plots. d1 &lt;- density(mPDL_RNA14D_Ko1_02) d2 &lt;- density(mPDL_RNA14D_Ko2_02) d3 &lt;- density(mPDL_RNA14D_WT1_02) plot(d1, col=&quot;red&quot;) polygon(d1, col = col1, border = &quot;red&quot;) # add color and border to d1 lines(d2, col=&quot;yellow&quot;) # add a new line to the density plot created above. polygon(d2, col = col2, border = &quot;green&quot;) # add color and border to d2 lines(d3, col=&quot;blue&quot;) # add one more line to the density plot. polygon(d3, col = col3, border = &quot;blue&quot;) # add color and border to d2 # PCA using prcomp --------------- # https://youtu.be/0Jp4gsfOLMs head(all_raw_count02 [,1:7]) pca &lt;- prcomp(t(all_raw_count02), center = T, scale. = T) # 1. Scale = false because there are 0 values. # 2. table was transpose t(), because prcomp() expects samples in rows and genes in columns. 3. The data is not centered... does this make a difference?... No... read here: https://stats.stackexchange.com/questions/189822/how-does-centering-make-a-difference-in-pca-for-svd-and-eigen-decomposition. Searrched with: variables should be shifted to be zero centered. plot(pca$x[,1], pca$x[,2], main = &quot;Plot PCA C1 v C2 :101&quot;) pca.var &lt;- pca$sdev^2 # To see how much variation PC1 accounts for. pca.var.per &lt;- round(pca.var/sum(pca.var)*100,1) # % of variations that each PC accounts for is more useful than the value, calculate %. pca.var.per barplot(pca.var.per, main = &quot;PCA Scree Plot :104&quot;, xlab = &quot;Principal component&quot;, ylab = &quot;Percent Variation&quot;) # PC1 accounts for 73.8% of the variation, PC2 15.6%, PC3 5.4% and so on.. #*************************************** # prcomp returns 3 Things: # x &lt;- Contains all the principal components )PCs) for drawing a graph. We use the first 2 columns [,1] and [,2] or PC1 and PC2.In this analysis we have 16 samples, therfore we obtain 16 PCs. PC1 accounts for the most variation in data, PC2 accounts for the second most variation and so on. # sdev &lt;- Standard deviation shows how much variation exists between exh sample. # rotation &lt;- prcom calls &quot;loading&quot; scores &quot;rotation&quot;. There are loading scores for each PC. #**************************************** # In ggplot # construct the df for the ggplot library(ggplot2) pca.data_count &lt;- data.frame(Sample=rownames(pca$x), X=pca$x[,1], Y=pca$x[,2]) pca.data_count library(ggrepel) # for the repel function. ggplot(data = pca.data_count, aes(x=X, y=Y, label=Sample, color=Sample, fill=Sample)) + #geom_text(size = 3.5) + geom_point() + geom_text_repel(aes(label = rownames(pca.data_count)), size = 3.5) + xlab(paste(&quot;PC1 - &quot;, pca.var.per[1], &quot;%&quot;, sep = &quot;&quot;)) + ylab(paste(&quot;PC2 - &quot;, pca.var.per[2], &quot;%&quot;, sep = &quot;&quot;)) + ggtitle(&quot;PCA Graph prcomp center scaled :120&quot;) 5.2 Differential expression Top 10 -100 genes # Top 10 genes expresion ------------ # Lets look at how to use loading scores to determine which genes have the largest effect on where samples are plotted in the PCA plot # PC1 loading_scores &lt;- pca$rotation[,1] # Loading score of PC! gene_scores &lt;- abs(loading_scores) # abs() to sort based on the numbers of magnitude rather than from high to low. gene_scores_ranked &lt;- sort(gene_scores, decreasing = T) # Sort the magnitudes of loading scores from high to low. top10_genes &lt;- names(gene_scores_ranked[1:100]) # Get the names of the top 10 genes with the largest loading scores magnitude. top10_genes pca$rotation[top10_genes,1] # show the scores (and +/-) PC1top10.df &lt;- data.frame(PC1= pca$rotation[top10_genes,1], PC2= pca$rotation[top10_genes,2]) # Careful This is not top 10 of PC2 PC1top10.df # Remove PC2 PC1top10.df[,2] &lt;- NULL PC1top10.df #PC2 loading_scores &lt;- pca$rotation[,2] # Loading score of PC gene_scores &lt;- abs(loading_scores) # abs() to sort based on the numbers of magnitude rather than from high to low. gene_scores_ranked &lt;- sort(gene_scores, decreasing = T) # Sort the magnitudes of loading scores from high to low. top10_genes &lt;- names(gene_scores_ranked[1:100]) # Get the names of the top 10 genes with the largest loading scores magnitude. top10_genes # **I am saving using the same name as the others, so this will change for each component. pca$rotation[top10_genes,2] # show the scores (and +/-) PC2top10.df &lt;- data.frame(PC2= pca$rotation[top10_genes,2]) PC2top10.df Top10DEgenes_prcomp &lt;- merge(PC1top10.df, PC2top10.df, by=0, all=T) Top10DEgenes_prcomp Top100DEgenes_prcomp &lt;- merge(PC1top10.df, PC2top10.df, by=0, all=T) # Change code above from 10 to 100. Top100DEgenes_prcomp rm(TopDEgenes) # Save DE genes table in a file. -------- # .csv file. write.table(Top10DEgenes_prcomp, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/TopDEgenes_prcomp.csv&quot;, sep = &quot;,&quot;, row.names = F) #Excel file. Source: http://www.sthda.com/english/wiki/writing-data-from-r-to-excel-files-xls-xlsx library(&quot;xlsx&quot;) # Write the first data set in a new workbook write.xlsx(Top10DEgenes_prcomp, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheetName = &quot;top10&quot;, row.names = F, append = FALSE) # Add a second data set in a new worksheet write.xlsx(Top100DEgenes_prcomp, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheetName = &quot;top100&quot;, row.names = F, append = TRUE) # to add as a new sheet. # Add a third data set..... # install.packages(&quot;writexl&quot;) library(&quot;writexl&quot;) write_xlsx(TopDEgenes_prcomp, &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/all_raw_count01.xlsx&quot;, sheet= top10_genes) 5.3 RNA-seq (ScienceparkSG) # RNA-seq (ScienceparkSG) ****** ----------------- # Metadata table construction ----------------- # experimental metadata., metadata, cold data file construction. # Extract column names. colnames &lt;- colnames(df) # “r convert list to comma separated string” paste(shQuote(df), collapse=&quot;, &quot;) # with quotes. paste(df, collapse = &quot;,&quot;) # without quotes. # Excel #Copy/paste list to excel &gt; Data &gt; Text to columns &gt; coma separated &gt; Transpose. To delete quotes: Find/replace &#39; to nothing. # Construct rest of the table in excel (it&#39;s faster) then import to R. all_raw_count02_colnames &lt;- colnames(all_raw_count02) all_raw_count02_colnames all_raw_count02_colnames2 &lt;- paste(shQuote(all_raw_count02_colnames), collapse=&quot;, &quot;) # with quotes. all_raw_count02_colnames2 &lt;- paste(all_raw_count02_colnames, collapse=&quot;, &quot;) # without quotes. all_raw_count02_colnames2 library(readxl) Metadata &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Notes.xlsx&quot;, sheet = &quot;MetaData&quot;) head(Metadata) # Order Metadata as you want to appear in the graphs. library(readxl) Metadata2 &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Notes.xlsx&quot;, sheet = &quot;MetaData2&quot;) Metadata2 # Or construct directly in R. # Convert data.frame column to a vector? vector &lt;- as.vector(df[&#39;colName&#39;]) # Op1 As a Tibble. class(vector) vector2 &lt;- df[[&#39;colName&#39;]] #Opt2 As a Tibble. class(vector) vector3 &lt;- df[,2] #Opt.3 As a Tibble. class(avector) vector4 &lt;- df$colName #Opt.4 as string?... GenotypeVec &lt;- Metadata[,2] class(GenotypeVec) GenotypeVec GenotypeVec &lt;- as.vector(Metadata[&#39;Genotype&#39;]) class(GenotypeVec) GenotypeVec &lt;- Metadata$Genotype GenotypeVec GenotypeVec &lt;- paste(shQuote(Genotype), collapse = &quot;,&quot;) # copy/paste result in c(). Genotype &lt;- c(&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;) TimeVect &lt;- Metadata$Time TimeVect TimeVect2 &lt;- paste(shQuote(TimeVect), collapse = &quot;,&quot;) # copy/paste result in c(). TimeVect2 Time &lt;- c(&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;) TissueVect &lt;- Metadata$Tissue TissueVect # Instead of new vector name just save in same vector TissueVect &lt;- paste(shQuote(TissueVect), collapse = &quot;,&quot;) # copy/paste result in c(). TissueVect Tissue &lt;- c(&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;) ShortNVect &lt;- Metadata$ShortName ShortNVect # Instead of new vector name just save in same vector ShortNVect &lt;- paste(shQuote(ShortNVect), collapse = &quot;,&quot;) # copy/paste result in c(). ShortNVect ShortName &lt;- c(&#39;14_Ko1&#39;,&#39;14_Ko2&#39;,&#39;14_Ko3&#39;,&#39;14_Ko4&#39;,&#39;14_WT1&#39;,&#39;14_WT2&#39;,&#39;14_WT3&#39;,&#39;14_WT4&#39;,&#39;7_Ko1&#39;,&#39;7_Ko2&#39;,&#39;7_Ko3&#39;,&#39;7_Ko4&#39;,&#39;7_WT1&#39;,&#39;7_WT2&#39;,&#39;7_WT3&#39;,&#39;7_WT4&#39;) SampNVect &lt;- Metadata$SampleName SampNVect # Instead of new vector name just save in same vector SampNVect &lt;- paste(shQuote(SampNVect), collapse = &quot;,&quot;) # copy/paste result in c(). SampNVect SampName &lt;- c(&#39;mPDL_RNA14D_Ko1&#39;,&#39;mPDL_RNA14D_Ko2&#39;,&#39;mPDL_RNA14D_Ko3&#39;,&#39;mPDL_RNA14D_Ko4&#39;,&#39;mPDL_RNA14D_WT1&#39;,&#39;mPDL_RNA14D_WT2&#39;,&#39;mPDL_RNA14D_WT3&#39;,&#39;mPDL_RNA14D_WT4&#39;,&#39;mPDL_RNA7D_Ko1&#39;,&#39;mPDL_RNA7D_Ko2&#39;,&#39;mPDL_RNA7D_Ko3&#39;,&#39;mPDL_RNA7D_Ko4&#39;,&#39;mPDL_RNA7D_WT1&#39;,&#39;mPDL_RNA7D_WT2&#39;,&#39;mPDL_RNA7D_WT3&#39;,&#39;mPDL_RNA7D_WT4&#39;) # Or create the Metadata file manually in R. #Create vectors containing the data. SampName &lt;- c(&#39;mPDL_RNA14D_Ko1&#39;,&#39;mPDL_RNA14D_Ko2&#39;,&#39;mPDL_RNA14D_Ko3&#39;,&#39;mPDL_RNA14D_Ko4&#39;,&#39;mPDL_RNA14D_WT1&#39;,&#39;mPDL_RNA14D_WT2&#39;,&#39;mPDL_RNA14D_WT3&#39;,&#39;mPDL_RNA14D_WT4&#39;,&#39;mPDL_RNA7D_Ko1&#39;,&#39;mPDL_RNA7D_Ko2&#39;,&#39;mPDL_RNA7D_Ko3&#39;,&#39;mPDL_RNA7D_Ko4&#39;,&#39;mPDL_RNA7D_WT1&#39;,&#39;mPDL_RNA7D_WT2&#39;,&#39;mPDL_RNA7D_WT3&#39;,&#39;mPDL_RNA7D_WT4&#39;) # create Samples list as they appear in the df. Genotype &lt;- c(&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;Ko&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;,&#39;WT&#39;) # Order according to the samples. Time &lt;- c(&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;14d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;,&#39;7d&#39;) Tissue &lt;- c(&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;,&#39;PDL&#39;) ShortName &lt;- c(&#39;14_Ko1&#39;,&#39;14_Ko2&#39;,&#39;14_Ko3&#39;,&#39;14_Ko4&#39;,&#39;14_WT1&#39;,&#39;14_WT2&#39;,&#39;14_WT3&#39;,&#39;14_WT4&#39;,&#39;7_Ko1&#39;,&#39;7_Ko2&#39;,&#39;7_Ko3&#39;,&#39;7_Ko4&#39;,&#39;7_WT1&#39;,&#39;7_WT2&#39;,&#39;7_WT3&#39;,&#39;7_WT4&#39;) # Combine vectors into a data frame. ColdData &lt;- data.frame(Genotype, Time, Tissue, ShortName) ColdData #Create row names with the associated sample names. rownames(ColdData) &lt;- c(&#39;mPDL_RNA14D_Ko1&#39;,&#39;mPDL_RNA14D_Ko2&#39;,&#39;mPDL_RNA14D_Ko3&#39;,&#39;mPDL_RNA14D_Ko4&#39;,&#39;mPDL_RNA14D_WT1&#39;,&#39;mPDL_RNA14D_WT2&#39;,&#39;mPDL_RNA14D_WT3&#39;,&#39;mPDL_RNA14D_WT4&#39;,&#39;mPDL_RNA7D_Ko1&#39;,&#39;mPDL_RNA7D_Ko2&#39;,&#39;mPDL_RNA7D_Ko3&#39;,&#39;mPDL_RNA7D_Ko4&#39;,&#39;mPDL_RNA7D_WT1&#39;,&#39;mPDL_RNA7D_WT2&#39;,&#39;mPDL_RNA7D_WT3&#39;,&#39;mPDL_RNA7D_WT4&#39;) ColdData # If df includes the Sample names as a column. # Combine vectors into a data frame. ColdData2 &lt;- data.frame(SampName, Genotype, Time, Tissue, ShortName) ColdData2 # Convert values of a column into row names in a df. Source: https://stackoverflow.com/questions/5555408/convert-the-values-in-a-column-into-row-names-in-an-existing-data-frame library(tidyverse) # Method01 rownames(ColdData2) &lt;- ColdData2[,1] # Converting first column into row names.* Column will still remain. ColdData2 ColdData2[,1] &lt;- NULL # Erasing 1st column. ColdData2 # Method02 row.names(ColdData2) &lt;- ColdData2$SampName ColdData2 ColdData2[1] &lt;- NULL ColdData2 # Method03: ColdData2 &lt;- ColdData2 %&gt;% remove_rownames %&gt;% column_to_rownames(var=&quot;SampName&quot;) ColdData2 &lt;- ColdData2 %&gt;% column_to_rownames(var=&quot;SampName&quot;) # no need for remove_rowmanes? ColdData2 # Source: https://www.geeksforgeeks.org/convert-values-in-column-into-row-names-of-dataframe-in-r/ # PCA applied to RNA-seq data -------- library(DESeq2) library(magrittr) # for piper %&gt;% library(tidyverse) # for tibble (column to rowname), and other packages. #from the https://scienceparkstudygroup.github.io/rna-seq-lesson/aio/index.html # Imported data head(all_raw_count01 [1:7]) # Raw count df head(all_raw_count02 [1:7]) # df with no 0s for centering and scaling. head (all_raw_count02[,1:7]) # Use this for dds construction (no 0) # reorder counts columns according to the experimental design file -------- colnames(Metadata2) counts &lt;- all_raw_count02[,Metadata2$SampleName] head(counts [1:7]) # first five rows and five columns counts[1:5, 1:5] # Create the dds object that will be used through the rest of this episode. # Check that sample names match in both files all(colnames(counts) %in% Metadata2$SampleName) all(colnames(counts) == Metadata2$SampleName) # Differential expression analysis. ## Creation of the DESeqDataSet object dds &lt;- DESeqDataSetFromMatrix(countData = counts, colData = Metadata2, design = ~ Genotype + Time) # Variance stabilization --------- # Plot of mean - sd comparison # Variance - mean plot for all genes head(counts) p_mean_sd_scaled &lt;- counts %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;gene&quot;) %&gt;% pivot_longer(cols = - gene, names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) %&gt;% group_by(gene) %&gt;% summarise(gene_average = mean(counts), gene_stdev = sd(counts)) %&gt;% ungroup() %&gt;% ggplot(., aes(x = log10(gene_average), y = log10(gene_stdev))) + geom_point(alpha = 0.5, fill = &quot;grey&quot;, colour = &quot;black&quot;) + labs(x = &quot;Gene count average (log10 scale)&quot;, y = &quot;Gene count standard deviation (log10 scale)&quot;) + ggtitle(&quot;Mean - Standard deviation relationship\\n(no variance stabilisation)&quot;) p_mean_sd_scaled is.data.frame(counts2) counts2 &lt;- rownames_to_column(counts, &quot;gene&quot;) counts2 &lt;- pivot_longer(counts2, cols = -gene, names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) counts2 &lt;- group_by(gene) head(counts2[1:5,]) library(&quot;vsn&quot;) meanSdPlot(cts, ranks = FALSE) # Variance stabilisation # dds &lt;- estimateSizeFactors(dds) dds &lt;- estimateDispersions(object = dds, fitType = &quot;parametric&quot;, quiet = TRUE) dds &lt;- estimateSizeFactors(dds) dds &lt;- estimateDispersions(object = dds, fitType = &quot;parametric&quot;, quiet = TRUE) vsd = varianceStabilizingTransformation(object = dds, blind = TRUE, # do not take the design formula into account # best practice for sample-level QC fitType = &quot;parametric&quot;) # extract the matrix of variance stabilised counts variance_stabilised_counts &lt;- assay(vsd) # create the mean-sd plot p_mean_sd_vst &lt;- variance_stabilised_counts %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;gene&quot;) %&gt;% pivot_longer(cols = - gene, names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) %&gt;% group_by(gene) %&gt;% summarise(gene_average = mean(counts), gene_stdev = sd(counts)) %&gt;% ungroup() %&gt;% ggplot(., aes(x = gene_average, y = gene_stdev)) + geom_point(alpha = 0.5, fill = &quot;grey&quot;, colour = &quot;black&quot;) + labs(x = &quot;Gene count average (variance stabilised)&quot;, y = &quot;Gene count standard deviation (variance stabilised)&quot;) + ggtitle(&quot;Mean - Standard deviation relationship\\n(after variance stabilisation &quot;) p_mean_sd_vst # RNA-seq scree plot ----------- # Custom PCA function # define a custom R function called &quot;mypca()&quot;&quot; mypca &lt;- function(x, center = TRUE, scale = TRUE){ # Samples should be in rows # Variables in the columns # remove constant variables constant_val = apply(x,2,&#39;sd&#39;) x_reduced = x[,constant_val&gt;0] # perform SVD SVD &lt;- svd(scale(x_reduced,center = center, scale = scale)) # create scores data frame scores &lt;- as.data.frame(SVD$u %*% diag(SVD$d)) rownames(scores) &lt;- rownames(x) colnames(scores) &lt;- paste0(&quot;PC&quot;, c(1:dim(scores)[2])) # create loadings data frams loadings &lt;- data.frame(SVD$v) colnames(loadings) &lt;- paste0(&quot;PC&quot;, c(1:dim(loadings)[2])) rownames(loadings) &lt;- colnames(x_reduced) # create data frame for explained variances explained_var &lt;- as.data.frame(round((SVD$d^2) / sum(SVD$d^2)*100, digits = 1)) rownames(explained_var) &lt;- paste0(&quot;PC&quot;, c(1:dim(loadings)[2])) colnames(explained_var) &lt;- &quot;exp_var&quot; # return result return (list(&quot;scores&quot; = scores, &quot;loadings&quot; = loadings, &quot;explained_var&quot; = explained_var)) } # transpose the data because in variance_stabilised_counts the rows are the variables and the columns correspond to the samples t_variance_stabilised_counts &lt;- variance_stabilised_counts # this is not doing anything!!!! # before computing the PCA, check that samples are in rows and genes in columns pca_results &lt;- mypca(t(t_variance_stabilised_counts), # added the transpose t() funtion here!!!.. now it works.!!! center = TRUE, scale = TRUE) # make the plot ggplot(pca_results$explained_var, aes(x = seq(from = 1, to = nrow(pca_results$explained_var)), y = exp_var)) + ylab(&#39;explained variance (%)&#39;) + ggtitle(&#39;Explained variance per component&#39;) + geom_bar(stat = &quot;identity&quot;) + labs(x = &quot;Principal Component number&quot;) + scale_x_continuous(breaks = seq( from = 1, to = nrow(pca_results$explained_var))) # How much percentage of the total variance are “caught” by PC1 and PC2? # How many PCs are necessary to get 50% of the total variance? # Solution cumsum(pca_results$explained_var)[2,1] # shows you that 28.8% of the varaince are explained by PC1 and PC2. cumsum(pca_results$explained_var) %&gt;% as.data.frame() %&gt;% filter(exp_var &gt; 50) %&gt;% head(n = 1) # You need to go up to PC7 to catch 51% of the variance. scores &lt;- pca_results$scores # first 5 rows and columns scores[1:5,1:5] scores_with_conditions &lt;- scores %&gt;% rownames_to_column(&quot;SampleName&quot;) %&gt;% # to prepare to join on the &quot;sample&quot; column left_join(x = ., # this means that we are passing the &#39;scores&#39; dataframe y = Metadata2, # this dataframe contains the sample to condition correspondence by = &quot;SampleName&quot;) # shows the first 5 rows and the last 6 columns. Note that conditions were added to the table. scores_with_conditions[1:5, 15:20] # PC14 PC15 PC16 Genotype Time Tissue # 1 11.18538 11.34342 -2.053225e-12 WT 7 PDL # 2 -24.19255 42.96321 -2.053225e-12 WT 7 PDL # 3 30.91639 -20.58249 -2.053225e-12 WT 7 PDL # 4 -26.27940 -26.47902 -2.053225e-12 WT 7 PDL # 5 -67.95911 -14.25815 -2.053225e-12 Ko 7 PDL # explained variance # one % variance value per PC explained_variance &lt;- pca_results$explained_var %&gt;% pull(&quot;exp_var&quot;) explained_variance # RNAseq Ploting ------------------ # Genotype Plot ggplot(scores_with_conditions, aes(PC1, PC2, color = Genotype)) + geom_point(size = 2) + geom_text_repel(aes(label = SampleName), size = 3) + xlab(paste0(&quot;PC1: &quot;,explained_variance[1],&quot;% variance&quot;)) + ylab(paste0(&quot;PC2: &quot;,explained_variance[2],&quot;% variance&quot;)) + coord_fixed(ratio = 1) + ggtitle(&quot;PCA score plot with the Genotype condition overlaid&quot;) # Time Plot ggplot(scores_with_conditions, aes(PC1, PC2, color = Time)) + geom_point(size = 2) + geom_text_repel(aes(label = ShortName), size = 3) + xlab(paste0(&quot;PC1: &quot;,explained_variance[1],&quot;% variance&quot;)) + ylab(paste0(&quot;PC2: &quot;,explained_variance[2],&quot;% variance&quot;)) + coord_fixed(ratio = 1) + ggtitle(&quot;PCA score plot with Time condition overlaid&quot;) # Other Condition... ggplot(scores_with_conditions, aes(PC1, PC2, color = dpi)) + geom_point(size = 4) + geom_text_repel(aes(label = sample), size = 3.5) + xlab(paste0(&quot;PC1: &quot;,explained_variance[1],&quot;% variance&quot;)) + ylab(paste0(&quot;PC2: &quot;,explained_variance[2],&quot;% variance&quot;)) + coord_fixed(ratio = 1) + ggtitle(&quot;PCA score plot with the time after infection (dpi) overlaid&quot;) # ADD on not working ------ # Lets look at how to use loading scores to dermine which genes have the largest effect on where samples are plotted in the PCA plot # Are Lodings and rotation the same? Seems like yes!! loading_scores2 &lt;- pca_results$loadings[,1] gene_scores2 &lt;- abs(loading_scores2) gene_scores_ranked2 &lt;- sort(gene_scores2, decreasing = T) top10_genes2 &lt;- row.names(gene_scores_ranked2[1:10]) top10_genes2 pca$rotation[top10_genes,1] # show the scores (and +/-) # DESeq2 count normalization ---- # Let’s see how, in practice, we can use DESeq2 median-of-ratios method to normalize the gene counts. # Data Import and matching to the experimantal design and counts data same as above. head(counts[,1:5]) # Create the DESeqDataSet object # suppressPackageStartupMessages(library(DESeq2)) # to load DESeq2 and suppress the long startup message # Creation of the DESeqDataSet object dds2 &lt;- DESeqDataSetFromMatrix(countData = all_raw_count02, colData = Metadata2, design = ~ Genotype) dds2 # Generate normalized counts dds2 &lt;- estimateSizeFactors(dds2) sizeFactors(dds2) # We can plot these size factors to see how much they differ between samples. library(tidyverse) # create a dplyr tibble size_factors_df &lt;- tibble( sample = names(sizeFactors(dds2)), correction_factor = sizeFactors(dds2) ) # line plot to connect the different size factor values p &lt;- ggplot(size_factors_df, aes(x = sample, y = correction_factor, group = 1)) + geom_point() + geom_line() + theme(axis.text.x = element_text(angle = 90, size = 5)) + scale_y_continuous(limits = c(0.5,2))+ # xlab(paste(&quot;PC1 - &quot;, pca.var.per[1], &quot;%&quot;, sep = &quot;&quot;)) + #ylab(paste(&quot;PC2 - &quot;, pca.var.per[2], &quot;%&quot;, sep = &quot;&quot;)) + ggtitle(&quot;Median of ratios method of normalization (size factors) to see how much samples differ between eachother &quot;) # to display the plot p # extract the normalised counts counts_normalised = counts(dds2, normalized = TRUE) counts_normalised[1:5,1:5] counts_log10 &lt;- log10(counts+1) boxplot(counts_log10, las=2, main=&quot;Log10 of counts&quot;) counts_normalised_log10 &lt;- log10(counts_normalised+1) boxplot(counts_normalised_log10, las=2, col= &quot;green&quot;, main=&quot;Normalize log10 counts&quot;) # Differential expression analysis ----------------------- # Warning ************************************* # We do not want to work on all comparisons, we will filter out the samples and conditions that we do not need. In this example, only the mock growth and the P. syringae infected condition will remain. # You should still have the counts and xp_design objects in your R environment. If not, please run the following code. # read the xp design file if not available in your environment # Metadata2 &lt;- read.delim(&quot;experimental_design_modified.txt&quot;, # header = T, # stringsAsFactors = F, # colClasses = rep(&quot;character&quot;,4)) # # change col names # colnames(Metadata2) &lt;- c(&quot;sample&quot;, &quot;seed&quot;, &quot;infected&quot;, &quot;dpi&quot;) # # # counts &lt;- read.delim(&quot;counts.txt&quot;, header = T, stringsAsFactors = F) # genes &lt;- counts[,1] # counts &lt;- counts[,-1] # row.names(counts) &lt;- genes # # # reorder counts columns according to the experimental design file # counts &lt;- counts[, xp_design$sample] #****************************************************************************** # We will now filter both the counts and xp_design objects to keep a one-factor comparison to investigate....? library(DESeq2) str(Metadata2) Metadata2$Time &lt;- as.factor(Metadata2$Time) Metadata2$Genotype &lt;- as.factor(Metadata2$Genotype) str(Metadata2) # filter design file (mock versus P. syringae at 7 dpi) var_GenetypeKo_vs_Time14 = Metadata2 %&gt;% filter(Time == &quot;14&quot;) # (Genotype == &quot;Ko&quot; &amp; Time == &quot;14&quot;) # Filter count file accordingly (to keep only samples present in the filtered xp_design file) counts_filtered = counts[, colnames(counts) %in% var_GenetypeKo_vs_Time14$SampleName] ## Creation of the DESeqDataSet dds3 &lt;- DESeqDataSetFromMatrix(countData = counts_filtered, colData = var_GenetypeKo_vs_Time14, design = ~ Genotype) # It is important to make sure that levels are properly ordered so we are indeed using the mock group as our reference level. A positive gene fold change will for instance signify that the gene is upregulated in the P. syringae condition relatively to the mock condition. #One way to see how levels are interpreted within the DESeqDataSet object is to display the factor levels. dds3$Genotype dds3 &lt;- DESeq(dds3) res &lt;- results(dds3) # have a peek at the DESeqResults object res res2 &lt;- results(dds3, contrast = c(&quot;Genotype&quot;, # name of the factor &quot;Ko&quot;, # name of the numerator level for fold change &quot;WT&quot;)) # name of the denominator level all_equal(res, res2) mcols(res) 5.4 False discovery rates FDR / Benjamini-Hocheberg method # False discovery rates FDR / Benjamini-Hocheberg method ---------- # Explanation of this method here: https://youtu.be/K8LQSvtjcEo # We can count the number of genes that are differentially regulated at a certain \\(\\alpha\\) level. library(dplyr) # threshold of p = 0.01 res %&gt;% as.data.frame() %&gt;% filter(padj &lt; 0.01) %&gt;% dim() # 2347 genes out of 6 samples 2347*100/nrow(counts) # 6.977643 or around ~7% # threshold of p = 0.001 FDR.001 &lt;- res %&gt;% as.data.frame() %&gt;% filter(padj &lt; 0.001) %&gt;% dim() FDR.001 FDR.001*100/nrow(counts) # 4.83410631 or around ~5% # You should obtain 2347 differentially expressed genes at 1% and 1626 at 0.1% which are quite important numbers: indeed, it corresponds to respectively ~7% and ~5% of the whole number transcriptome (nrow(counts) = total number of mRNA is 33636). # distribution of adjusted p-values hist(res$padj, col=&quot;lightblue&quot;, main = &quot;Adjusted p-value distribution&quot;) # distribution of non-adjusted p-values hist(res$pvalue, col=&quot;grey&quot;, main = &quot;Non-adjusted p-value distribution&quot;) # As you can see, the distribution of p-values was already quite similar suggesting that a good proportion of the tests have a significant p-value (inferior to \\(\\alpha\\) = 0.01 for instance). This suggests that a good proportion of these will be true positives (genes truly differentially regulated). # Extracting the table of differential genes ------------ diff = res %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;genes&quot;) %&gt;% filter(padj &lt; 0.01) %&gt;% arrange(desc(log2FoldChange), desc(padj)) head(diff) dim(diff) # Save differential genes table in a file. -------- # # .csv file. # write.table(diff, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/diff.csv&quot;, sep = &quot;,&quot;, row.names = F) # # # #Excel file. Source: http://www.sthda.com/english/wiki/writing-data-from-r-to-excel-files-xls-xlsx # library(&quot;xlsx&quot;) # # Write the first data set in a new workbook # write.xlsx(diff, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/diff.xlsx&quot;, # sheetName = &quot;diff1&quot;, row.names = F, append = FALSE) # # Add a second data set in a new worksheet # write.xlsx(diff2, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, # sheetName = &quot;diff2&quot;, row.names = F, append = TRUE) # to add as a new sheet. # Add a third data set..... I AM ADDING THIS SHEET TO AN EXISTING FILE FROM THE PREVIOUS PCA ANALISYS. write.xlsx(diff, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheetName = &quot;diff1&quot;, row.names = F, append = TRUE) # to add as a new sheet. # # Physically opening an excel file within R (maybe Windows only) # Top10DEgenes_prcomp.xlsx_path &lt;- &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot; # command &lt;- paste(&quot;open excel&quot;, Top10DEgenes_prcomp.xlsx_path) # system(command) # # install.packages(&quot;writexl&quot;) # library(&quot;writexl&quot;) # write_xlsx(TopDEgenes_prcomp, &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/all_raw_count01.xlsx&quot;, sheet= top10_genes) 5.5 Volcano plot # Volcano plot ----------- # First, we are going to “shrink” the \\(\\log2\\) fold changes to remove the noise associated with fold changes coming from genes with low count levels. Shrinkage of effect size (LFC estimates) is useful for visualization and ranking of genes. This helps to get more meaningful log2 fold changes for all genes independently of their expression level. resLFC &lt;- lfcShrink(dds = dds3, res = res, type = &quot;normal&quot;, coef = 2) # corresponds to &quot;WT vs Ko&quot; comparison resLFC # EnhancedVolcano Installation # if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;) #BiocManager::install(&quot;EnhancedVolcano&quot;) # load the library if not done yet library(&quot;EnhancedVolcano&quot;) # The main function is named after the package EnhancedVolcano(toptable = resLFC, # We use the shrunken log2 fold change as noise associated with low count genes is removed x = &quot;log2FoldChange&quot;, # Name of the column in resLFC that contains the log2 fold changes y = &quot;padj&quot;, # Name of the column in resLFC that contains the p-value lab = rownames(resLFC) ) EnhancedVolcano(toptable = resLFC, x = &quot;log2FoldChange&quot;, y = &quot;padj&quot;, lab = rownames(resLFC), labSize = 3, xlim = c(-10, +10), ylim = c(0,100), pCutoff = 1e-06, pointSize = 2.0, FCcutoff = 2, title = &quot;WT vs Ko comparison (fold change cutoff = 2, p-value cutoff = 1e-06)&quot;, subtitle = &#39;Differential expression&#39;, ) 5.6 Heatmap &amp; normalization # Heatmap -------------------- library(pheatmap) # df &lt;- scale(mtcars) # pheatmap(df) # import custom function ------ # source(&quot;normalization_function.R&quot;) # cant import, so I pasted below. mor_normalization. mor_normalization = function(data){ library(dplyr) library(tibble) # take the log log_data = log(data) # find the psuedo-references per sample by taking the geometric mean log_data = log_data %&gt;% rownames_to_column(&#39;gene&#39;) %&gt;% mutate (gene_averages = rowMeans(log_data)) %&gt;% filter(gene_averages != &quot;-Inf&quot;) # the last columns is the pseudo-reference column pseudo_column = ncol(log_data) # where to stop before the pseudo column before_pseduo = pseudo_column - 1 # find the ratio of the log data to the pseudo-reference ratios = sweep(log_data[,2:before_pseduo], 1, log_data[,pseudo_column], &quot;-&quot;) # find the median of the ratios sample_medians = apply(ratios, 2, median) # convert the median to a scaling factor scaling_factors = exp(sample_medians) # use scaling factors to scale the original data manually_normalized = sweep(data, 2, scaling_factors, &quot;/&quot;) return(manually_normalized) } # First version counts_normalised_only_diff_genes = mor_normalization(counts) %&gt;% # normalize the counts using our custom function rownames_to_column(&quot;genes&quot;) %&gt;% pivot_longer(- genes, # pivot_longer() is an update version of gather() since tidyr version 1.0 names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) %&gt;% filter(genes %in% diff$genes) %&gt;% pivot_wider(names_from = &quot;sample&quot;, # pivot_wider() is an updated approach to spread() values_from = &quot;counts&quot;) %&gt;% column_to_rownames(&quot;genes&quot;) # the gene column is converted back to row names to create a matrix usable with pheatmap dim(counts_normalised_only_diff_genes) # check that you have the expected number of rows and columns pheatmap(counts_normalised_only_diff_genes, cluster_rows = FALSE, cluster_cols = FALSE, scale = &quot;none&quot;, show_rownames = FALSE, show_colnames = TRUE) # Heatmap is all blue!! WHY?!!!!!!!!!!!!! # distribution of values in the counts_normalised_only_diff_genes table: counts_normalised_only_diff_genes %&gt;% rownames_to_column(&quot;genes&quot;) %&gt;% pivot_longer(- genes, names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) %&gt;% with(., hist(counts, col = &quot;dodgerblue&quot;)) # The scale on which gene counts are represented is the (main) issue here. # There are a lot of genes for which the number of counts are very low. If you \\(\\log2\\) transform the counts, you get a nice distribution again where all gene frequency become visible again. counts_normalised_only_diff_genes %&gt;% rownames_to_column(&quot;genes&quot;) %&gt;% pivot_longer(- genes,names_to = &quot;sample&quot;, values_to = &quot;counts&quot;) %&gt;% with(., hist(log2(counts), col = &quot;dodgerblue&quot;)) # If you re-run the code for the first heatmap with a log2 transformation, you will get a simple way to display different gene count levels. We add + 1 to account for genes with count values equal to 0. pheatmap(log2(counts_normalised_only_diff_genes + 1), cluster_rows = FALSE, cluster_cols = FALSE, scale = &quot;none&quot;, show_rownames = FALSE, show_colnames = TRUE) # Second version with scaling #Scaling trial set.seed(1) x &lt;- runif(10) # Manually scaling (x - mean(x)) / sd(x) # With scale function scale(x)[,1] remove(x) counts_scaled = counts_normalised_only_diff_genes %&gt;% t(.) %&gt;% # transpose to have the genes in columns scale() %&gt;% # scale(x, center = TRUE, scale = TRUE) t(.) # back in original shape # sanity check # the majority of the values should be around zero apply(counts_scaled, MARGIN = 1, mean) %&gt;% # calculate the mean per row hist(., main = &quot;&quot;, xlab = &quot;Z-score values&quot;, col = &quot;dodgerblue2&quot;) pheatmap(counts_scaled, cluster_rows = FALSE, cluster_cols = FALSE, show_rownames = FALSE, scale = &quot;none&quot;, # already done &quot;manually&quot; show_colnames = TRUE) # Third version with genes and samples grouped by profiles pheatmap(counts_scaled, cluster_rows = TRUE, cluster_cols = TRUE, show_rownames = FALSE, show_colnames = TRUE, main = &quot;Clustering on&quot;) # Fourth version of our heatmap with the 8 samples being investigated. counts_scaled_filtered = counts_scaled %&gt;% as.data.frame() %&gt;% dplyr::select(var_GenetypeKo_vs_Time14$SampleName) # keep the 8 samples head(counts_scaled_filtered) # Anotations for the map anno_col_info = var_GenetypeKo_vs_Time14 %&gt;% column_to_rownames(&quot;SampleName&quot;) anno_info_colors = list( Tissue = c(PDL = &quot;#d8b365&quot;), Genotype = c(WT = &quot;lightgrey&quot;, Ko = &quot;black&quot;), Time = c(&quot;14&quot; = &quot;dodgerblue4&quot;) ) # Heatmatp with anotations pheatmap(counts_scaled_filtered, cluster_rows = TRUE, cluster_cols = TRUE, show_rownames = FALSE, show_colnames = TRUE, annotation_col = anno_col_info, annotation_colors = anno_info_colors, main = &quot;Clustering with ward method&quot;) 5.7 MA plots # MA plots ------- plotMA(dds3, alpha = 0.01) ## S4 method for signature &#39;DESeqDataSet&#39; plotMA( dds3, alpha = 0.01, main = &quot;DESeqDataSet plotMA&quot;, xlab = &quot;mean of normalized counts&quot;, # ylim, colNonSig = &quot;gray60&quot;, colSig = &quot;red&quot;, colLine = &quot;grey40&quot;, returnData = FALSE, MLE = FALSE, ) 5.8 Eastern New Mexico University ENMU method # Eastern New Mexico University ENMU ***** ------ # Load Data library(readxl) all_raw_count &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/all.raw.count.xlsx&quot;) head(all_raw_count) class(all_raw_count) dim(all_raw_count) # Extract column names. colnames &lt;- colnames(all_raw_count) colnames # “r convert list to comma separated string” paste(shQuote(colnames), collapse=&quot;, &quot;) # with quotes. paste(colnames, collapse = &quot;,&quot;) # without quotes. excluded_vars &lt;- c(&quot;GeneName&quot;, &quot;Chr&quot;, &quot;Start&quot;, &quot;End&quot;, &quot;Strand&quot;, &quot;Length&quot; ) library(dplyr) # for select function all_raw_count01 &lt;- select(all_raw_count, -excluded_vars) # it works, but... better use: all_raw_count01 &lt;- select(all_raw_count, -all_of(excluded_vars)) #exclude all variables in excluded_vars head(all_raw_count01) dim(all_raw_count01) class(all_raw_count01) library(tidyverse) # Converting first column into row names all_raw_count01 &lt;- all_raw_count01 %&gt;% column_to_rownames(var=&quot;GeneID&quot;) # Clean/filter of non expresed genes # If Center and Scale needed, remove all rows containing all 0 values. # df1[rowSums(df1[])&gt;0,] all_raw_count02 &lt;- all_raw_count01[rowSums(all_raw_count01[])&gt;0,] head(all_raw_count02 [,1:5]) # Load Metadata library(readxl) Metadata &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Notes.xlsx&quot;, sheet = &quot;MetaData&quot;) head(Metadata) # Order Metadata as you want to appear in the graphs. library(readxl) Metadata2 &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Notes.xlsx&quot;, sheet = &quot;MetaData2&quot;) Metadata2 str(Metadata2) Metadata2$Time &lt;- as.factor(Metadata2$Time) Metadata2$Genotype &lt;- as.factor(Metadata2$Genotype) str(Metadata2) # Create dds file library(DESeq2) ## Creation of the DESeqDataSet dds4 &lt;- DESeqDataSetFromMatrix(countData = all_raw_count02, colData = Metadata2, design = ~ Genotype) # only one comparison. Time not included. #?`DESeq2-package` # Keep only the genes with count &gt;10 keep &lt;- rowSums(counts(dds4))&gt;=10 # Filter out keep. dds4 &lt;- dds4[keep,] # Estimate Size Factor ddsN &lt;- estimateSizeFactors(dds4) ddsN &lt;- estimateDispersions(ddsN) # Normalize Data Ndds &lt;- counts(ddsN, normalized=T) head(Ndds) # Save into a file. # Make the differentiation Expression Table. ddsDE &lt;- DESeq(dds4) #Why dds4 and not Ndds? head(ddsDE) # Call the results of the differentiation expression analysis and define alpha. res4 &lt;- results(ddsDE, alpha = 0.001) head(res4) dim(res4) # Save as file. # Order padj values from smallest to largest res4Ordered &lt;- res4[order(res4$padj),] head(res4Ordered) # Save values in a file. library(&quot;xlsx&quot;) # Add another data set..... I AM ADDING THIS AS A NEW SHEET TO AN EXISTING FILE FROM THE PREVIOUS PCA ANALISYS. write.xlsx(res4Ordered, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheetName = &quot;diff2ENMU.001&quot;, row.names = T, append = TRUE) # to add as a new sheet. # TAKES A LONG TIME TO SAVE... BE PATIENT. ***************************************** # PlotMA plotMA(ddsDE, colSig = &quot;red&quot;,) # Plot PCA # Apply a variance stabilizing transformation (VST) to the count data vsd &lt;- vst(dds4, blind = F) vsd str(vsd) plotPCA(vsd, intgroup = c(&quot;Time&quot;, &quot;Genotype&quot;)) # Sample to sample distribution library(RColorBrewer) library(pheatmap) sampleDist &lt;- dist(t(assay(vsd))) sampleDist sampleDistMatrix &lt;- as.matrix(sampleDist) sampleDistMatrix rownames(sampleDistMatrix) &lt;- vsd$Genotype sampleDistMatrix colnames(sampleDistMatrix) &lt;- NULL sampleDistMatrix #colors &lt;- colorRampPalette(rev(brewer.pal(9, &quot;Blues&quot;))), (225)) pheatmap(sampleDistMatrix, clustering_distance_rows = sampleDist, clustering_distance_cols = sampleDist, #col=colors ) # Gene expression plotting library(ggplot2) #install.packages(&quot;meltt&quot;) library(reshape) # Expression file (Ndds) head(Ndds) # Is a matrix # DE results file head(res4Ordered) # Is not a matrix. but was saved in a file # Load DE results file library(readxl) statsDE &lt;- read_excel(&quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheet = &quot;diff2ENMU.01&quot;) head(statsDE) # Change column of GeneID to row names Method 3 statsDE &lt;- statsDE %&gt;% column_to_rownames(var=&quot;...1&quot;) head(statsDE) dim(statsDE) # Check if there are NA values in the df. If true then omit all NA rows. apply(statsDE, 2, function(x) any(is.na(x))) # check by columns # baseMean log2FoldChange lfcSE stat pvalue padj # FALSE FALSE FALSE FALSE FALSE TRUE statsDE &lt;- na.omit(statsDE) dim(statsDE) # Filter Significant values. 0.05 or 0.01 or 0.001 statsDE$sig &lt;- ifelse(statsDE$padj &lt;= 0.01, &quot;sig&quot;, &quot;not&quot;) head(statsDE) plotMA &lt;- ggplot(statsDE, aes(x= log10(baseMean), y= log2FoldChange, color=sig)) + geom_point() plotMA # Volcano Plot volcanoplot &lt;- ggplot(statsDE, aes(x= log2FoldChange, y= -log10(padj), color = sig)) + geom_point() volcanoplot # Extract the top 10 differentially expressed genes. topTen &lt;- statsDE[1:100,] topTen all_raw_count00 &lt;- all_raw_count %&gt;% column_to_rownames(var=&quot;GeneID&quot;) # For all data columns all_raw_count00[1:5,] topTenMerg &lt;- merge(topTen, all_raw_count00, by=0) topTenMerg [1:5,] # Save values in a file. library(&quot;xlsx&quot;) # Add another data set..... I AM ADDING THIS AS A NEW SHEET TO AN EXISTING FILE FROM THE PREVIOUS PCA ANALISYS. write.xlsx(topTenMerg, file = &quot;~/Box Sync/Niigata Uni Box/Kakenhi/2020-22 Kakenhi/Raw data/Top10DEgenes_prcomp.xlsx&quot;, sheetName = &quot;top100MergENMU&quot;, row.names = T, append = TRUE) # to add as a new sheet. # Heat Map of top10 genes. # Cunstruct Matrix. # Extract column names. colnames(topTenMerg) paste(shQuote(colnames(topTenMerg)), collapse=&quot;, &quot;) # with quotes. include_var &lt;- c(&#39;Row.names&#39;, &#39;mPDL_RNA14D_Ko1&#39;, &#39;mPDL_RNA14D_Ko2&#39;, &#39;mPDL_RNA14D_Ko3&#39;, &#39;mPDL_RNA14D_Ko4&#39;, &#39;mPDL_RNA14D_WT1&#39;, &#39;mPDL_RNA14D_WT2&#39;, &#39;mPDL_RNA14D_WT3&#39;, &#39;mPDL_RNA14D_WT4&#39;, &#39;mPDL_RNA7D_Ko1&#39;, &#39;mPDL_RNA7D_Ko2&#39;, &#39;mPDL_RNA7D_Ko3&#39;, &#39;mPDL_RNA7D_Ko4&#39;, &#39;mPDL_RNA7D_WT1&#39;, &#39;mPDL_RNA7D_WT2&#39;, &#39;mPDL_RNA7D_WT3&#39;, &#39;mPDL_RNA7D_WT4&#39; ) # Top10heat &lt;- topTenMerg[,names(topTenMerg)] %in% include_var #Not working, gives T/F vector instead of matrix. # Top10heat Top10heat &lt;- select(topTenMerg, all_of(include_var)) #exclude all variables in excluded_vars head(Top10heat) dim(Top10heat) class(Top10heat) library(tidyverse) # col1 to rownames Top10heat &lt;- Top10heat %&gt;% column_to_rownames(var=&quot;Row.names&quot;) # Source: https://www.geeksforgeeks.org/convert-values-in-column-into-row-names-of-dataframe-in-r/ head(Top10heat) # reorder columns according to the experimental design file colnames(Metadata2) Top10heatord &lt;- Top10heat[,Metadata2$SampleName] head(Top10heatord [1:7]) Top10heatord # Heat plot pheatmap(Top10heatord, main = &quot;heatmap top 10 genes try1&quot;) pheatmap(log2(Top10heatord+1), main = &quot;heatmap top 100 genes try2&quot;) # Individual expression values of the DE genes # Only for the top 10 genes. newtop10 &lt;- Top10heatord[1:10,] newtop10 dim(newtop10) # construct appropiate df newtop10 &lt;- melt(as.matrix(newtop10)) # Rename columns names(newtop10) &lt;- c(&quot;GeneID&quot;, &quot;Sample&quot;, &quot;count&quot;) # maybe better use exp (expression) instead of count. head(newtop10) # Add new columns Genetype and Time newtop10$Genetype &lt;- ifelse(grepl(&quot;WT&quot;, newtop10$Sample), &quot;WT&quot;, &quot;Ko&quot;) head(newtop10) newtop10$Time &lt;- as.factor( ifelse(grepl(&quot;7&quot;, newtop10$Sample), &quot;7&quot;, &quot;14&quot;)) head(newtop10) str(newtop10) ggplot(newtop10, aes(x= Genetype, y= log2(count+1), color= Genetype)) + geom_point() + facet_grid(Time~GeneID) + theme() # Extremely quick tutorial on DESequ analysis ***** ----------------------------- library(htmltools) library(DESeq2) library(ggplot2) #setwd() # Load Data -&gt; construct appropiate df. all_raw_count02 head(all_raw_count02) # Load Metadata -&gt; construct appropiate df. Metadata2 head(Metadata2) # Contruct DESeqDataSet object dds210721 &lt;- DESeqDataSetFromMatrix(countData = all_raw_count02, colData = Metadata2, design = ~ Genotype +Time, tidy = F) #If the 1st column of countData is the rownames for the count matrix then TRUE dds210721 #Run DESeq function for the differentiation Expression Table dds210721 &lt;- DESeq(dds210721) # Call the results of the differentiation expression analysis and define alpha. res210721 &lt;- results(dds210721, alpha = 0.001) head(res210721, tidy=F) dim(res210721) summary(res210721) # Sort/order summary list with padj values from smallest to largest res210721Rank &lt;- res210721[order(res210721$padj),] head(res210721Rank) # Plot PCA # Apply a variance stabilizing transformation (VST) to the count data vsd210721 &lt;- vst(dds210721, blind = F) vsd210721 str(vsd210721) plotPCA(vsd210721, intgroup = c(&quot;Time&quot;, &quot;Genotype&quot;)) "],["r-code-modules-to-be-used-for-stand-alone-analysis..html", "Chapter 6 R code modules to be used for stand-alone analysis. 6.1 Local installation 6.2 Install packages 6.3 Global variables 6.4 Read data and pre-process 6.5 Hierarchical clustering 6.6 PCA 6.7 K-means clustering 6.8 Differential expression 6.9 Pathway analysis 6.10 Genome-wide view 6.11 Biclustering 6.12 Co-expression network", " Chapter 6 R code modules to be used for stand-alone analysis. Base on the South Dakota State University analysis protocol http://bioinformatics.sdstate.edu/ Integrated Differential Expression and Pathway analysis 1.ShinyGO: Gene Ontology Enrichment Analysis Github: iDEP-SDSU/idep 6.1 Local installation Local installation of this software is possible through steps below. But it is not supported or updated freqently. Local install is for non-profit organizations only. For-profit businesses please contact us to license the database. To run iDEP on your local machine (Windows, MacOS, Linux): Requirements: More than 250GB available storage More than 4GB memory Most recent version of R and RStudio installed. Upgrade to the most recent version of R and Rstudio. Start RStudio and install all the R packages. As we need so many R packages, this may take several hours. You can let it run and get started on steps 3 and 4 below to save time. From RStudio console window: source https://raw.githubusercontent.com/iDEP-SDSU/idep/master/classes/librarySetup.R Download iDEP source code and example data files from GitHub. The best is to click the green “Code” button and select “Download ZIP” on this page. Unzip to a folder such as C:/IDEP, so that it contains all the subfolders such as config, classes, shinyapps, and so on. Download the most recent database file from here. Unzip it to the same folder (C:/IDEP), so that your database can be found at C:/IDEP/data/data104. Start Rstudio and load the ui.R and server.R scripts in the folder C:/IDEP/shinyapps/idep94. And then click on Run app. Similarily, the ShinyGO app could be started at the folder, C:/IDEP/shinyapps/go74/. 6.2 Install packages source https://raw.githubusercontent.com/iDEP-SDSU/idep/master/classes/librarySetup.R # dplyr complains this required libraries: libudunits2-dev, libmariadb-client-lgpl-dev #demo # install.packages(&quot;plotly&quot;, repos=&quot;http://cran.rstudio.com/&quot;, dependencies=TRUE) # sometimes need to remove all installed packages: https://www.r-bloggers.com/how-to-remove-all-user-installed-packages-in-r/ list.of.packages &lt;- c( &quot;shiny&quot;, &quot;shinyAce&quot;, &quot;shinyBS&quot;, &quot;plotly&quot;, &quot;RSQLite&quot;, &quot;gplots&quot;, &quot;ggplot2&quot;, &quot;dplyr&quot;, #&quot;tidyverse&quot;, &quot;plotly&quot;, &quot;e1071&quot;, &quot;reshape2&quot;, &quot;DT&quot;, &quot;data.table&quot;, &quot;Rcpp&quot;,&quot;WGCNA&quot;,&quot;flashClust&quot;,&quot;statmod&quot;,&quot;biclust&quot;,&quot;igraph&quot;,&quot;Rtsne&quot;, &quot;visNetwork&quot;, &quot;BiocManager&quot;,&quot;feather&quot;,&quot;shinyjs&quot;,&quot;reactable&quot; ) list.of.bio.packages &lt;- c( &quot;getDEE2&quot;, &quot;limma&quot;, &quot;DESeq2&quot;, &quot;edgeR&quot;, &quot;gage&quot;, &quot;fgsea&quot;, &quot;ReactomePA&quot;, &quot;pathview&quot;, &quot;PREDA&quot;, &quot;impute&quot;, &quot;runibic&quot;,&quot;QUBIC&quot;,&quot;rhdf5&quot;, &quot;STRINGdb&quot;, &quot;PREDAsampledata&quot;, &quot;sfsmisc&quot;, &quot;lokern&quot;, &quot;multtest&quot;, &quot;hgu133plus2.db&quot;, &quot;org.Ag.eg.db&quot;,&quot;org.At.tair.db&quot;,&quot;org.Bt.eg.db&quot;,&quot;org.Ce.eg.db&quot;,&quot;org.Cf.eg.db&quot;, &quot;org.Dm.eg.db&quot;,&quot;org.EcK12.eg.db&quot;,&quot;org.EcSakai.eg.db&quot;,&quot;org.Gg.eg.db&quot;, &quot;org.Hs.eg.db&quot;,&quot;org.Mm.eg.db&quot;,&quot;org.Mmu.eg.db&quot;,&quot;org.Pf.plasmo.db&quot;, &quot;org.Pt.eg.db&quot;,&quot;org.Rn.eg.db&quot;,&quot;org.Sc.sgd.db&quot;,&quot;org.Ss.eg.db&quot;,&quot;org.Xl.eg.db&quot; ) if(1) { # remove all old packages, to solve problem caused by Bioconductor upgrade # create a list of all installed packages ip &lt;- as.data.frame(installed.packages()) # head(ip) # if you use MRO, make sure that no packages in this library will be removed ip &lt;- subset(ip, !grepl(&quot;MRO&quot;, ip$LibPath)) # we don&#39;t want to remove base or recommended packages either\\ ip &lt;- ip[!(ip[,&quot;Priority&quot;] %in% c(&quot;base&quot;, &quot;recommended&quot;)),] # determine the library where the packages are installed path.lib &lt;- unique(ip$LibPath) # create a vector with all the names of the packages you want to remove pkgs.to.remove &lt;- ip[,1] # head(pkgs.to.remove) # remove the packages sapply(pkgs.to.remove, remove.packages, lib = path.lib) } new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] new.bio.packages &lt;- list.of.bio.packages[!(list.of.bio.packages %in% installed.packages()[,&quot;Package&quot;])] notInstalledPackageCount = length(new.packages) + length(new.bio.packages) #Install Require packages while(notInstalledPackageCount != 0){ if(length(new.packages)) install.packages(new.packages, repos=&quot;http://cran.rstudio.com/&quot;, dependencies=TRUE, quiet=TRUE) if(length(new.bio.packages)){ BiocManager::install(new.bio.packages, ask = FALSE, dependencies=TRUE, quiet=TRUE) } new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] new.bio.packages &lt;- list.of.bio.packages[!(list.of.bio.packages %in% installed.packages()[,&quot;Package&quot;])] if( notInstalledPackageCount == length(new.packages) + length(new.bio.packages) ) { #no new package installed. break } else { notInstalledPackageCount = length(new.packages) + length(new.bio.packages) } } #PGSEA is deprecated since Bioconductor 3.12. So we have to install manually from source. BiocManager::install(c(&quot;GO.db&quot;,&quot;KEGG.db&quot;, &quot;annaffy&quot;)) # required y PGSEA install.packages(&quot;https://bioconductor.org/packages/3.10/bioc/src/contrib/PGSEA_1.60.0.tar.gz&quot;, repos=NULL, type=&quot;source&quot;) list.of.bio.packages = c(list.of.bio.packages, &quot;PGSEA&quot;) # add package for testing #Load Packages suc = unlist ( lapply(list.of.packages, require, character.only = TRUE) ) if(sum(suc) &lt; length(list.of.packages) ) cat (&quot;\\n\\nWarnning!!!!!! These R packages cannot be loaded:&quot;, list.of.packages[!suc] ) suc = unlist ( lapply(list.of.bio.packages, require, character.only = TRUE) ) if(sum(suc) &lt; length(list.of.bio.packages) ) cat (&quot;\\n\\nWarnning!!!!!! These Bioconductor packages cannot be loaded:&quot;, list.of.bio.packages[!suc] ) ################################################################ # Install packages ################################################################ # dplyr complains this required libraries: libudunits2-dev, libmariadb-client-lgpl-dev # install.packages(&quot;plotly&quot;, repos=&quot;http://cran.rstudio.com/&quot;, dependencies=TRUE) # sometimes need to remove all installed packages: https://www.r-bloggers.com/how-to-remove-all-user-installed-packages-in-r/ #cat(&quot;\\n Installing lots of R packages, this may take several hours ... \\n # Each of these packages took years to develop.\\n So be a patient thief.\\n # \\n Note 1: Sometimes dependencies needs to be installed manually. # \\n Note 2: If you are using an older version of R, and having trouble with package installation, # \\n sometimes, it is easier to install the new version of R and delete all old packages, and start fresh. # &quot;) list.of.packages &lt;- c(&quot;dendextend&quot;, &quot;htmlwidgets&quot;,&quot;RSQLite&quot;, &quot;gplots&quot;, &quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;tidyverse&quot;,&quot;plotly&quot;,&quot;e1071&quot;, &quot;reshape2&quot;, &quot;Rcpp&quot;,&quot;flashClust&quot;,&quot;statmod&quot;, &quot;biclust&quot;,&quot;igraph&quot;,&quot;Rtsne&quot;) list.of.bio.packages &lt;- c(&quot;STRINGdb&quot;, &quot;limma&quot;, &quot;DESeq2&quot;, &quot;edgeR&quot;, &quot;gage&quot;, &quot;PGSEA&quot;, &quot;fgsea&quot;, &quot;ReactomePA&quot;, &quot;pathview&quot;, &quot;PREDA&quot;, &quot;impute&quot;, &quot;runibic&quot;, &quot;QUBIC&quot;,&quot;rhdf5&quot;, &quot;PREDAsampledata&quot;, &quot;sfsmisc&quot;, &quot;lokern&quot;, &quot;multtest&quot;, &quot;GSEABase&quot;,&quot;hgu133plus2.db&quot;) #Install Require packages new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages, repos=&quot;http://cran.rstudio.com/&quot;, dependencies=TRUE) new.bio.packages &lt;- list.of.bio.packages[!(list.of.bio.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.bio.packages)){ if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(new.bio.packages, suppressUpdates = T) } # WGCNA must be installed after AnnotationDbi, impute, GO.db, preprocessCore # install.packages(c(&quot;WGCNA&quot;)) #Test Load Packages This cause an error when too many packages are loaded. # suc = unlist ( lapply(list.of.packages, require, character.only = TRUE) ) # if(sum(suc) &lt; length(list.of.packages) ) # cat (&quot;\\n\\nWarnning!!!!!! These R packages cannot be loaded:&quot;, list.of.packages[!suc] ) # suc = unlist ( lapply(list.of.bio.packages, require, character.only = TRUE) ) # if(sum(suc) &lt; length(list.of.bio.packages) ) # cat (&quot;\\n\\nWarnning!!!!!! These Bioconductor packages cannot be loaded:&quot;, list.of.bio.packages[!suc] ) 6.3 Global variables ################################################################ # Global variables ################################################################ library(RSQLite,verbose=FALSE) # for database connection library(gplots,verbose=FALSE) # for hierarchical clustering library(ggplot2,verbose=FALSE) # graphics library(e1071,verbose=FALSE) # computing kurtosis library(DT,verbose=FALSE) # for renderDataTable library(plotly,verbose=FALSE) # for interactive heatmap library(reshape2,verbose=FALSE) # for melt correlation matrix in heatmap input_goButton = 0 # if 1, use demo data file Min_overlap &lt;- 2 minSetSize = 3; mappingCoverage = 0.60 # 60% percent genes has to be mapped for confident mapping mappingEdge = 0.5 # Top species has 50% more genes mapped PvalGeneInfo = 0.05; minGenes = 10 # min number of genes for ploting kurtosis.log = 50 # log transform is enforced when kurtosis is big kurtosis.warning = 10 # log transformation recommnded minGenesEnrichment = 2 # perform GO or promoter analysis only if more than this many genes PREDA_Permutations =1000 maxGeneClustering = 12000 # max genes for hierarchical clustering and k-Means clustering. Slow if larger maxGeneWGCNA = 2000 # max genes for co-expression network maxFactors =6 # max number of factors in DESeq2 models redudantGeneSetsRatio = 0.9 # remove redundant genesets in enrichment analysis set.seed(2) # seed for random number generator mycolors = sort(rainbow(20))[c(1,20,10,11,2,19,3,12,4,13,5,14,6,15,7,16,8,17,9,18)] # 20 colors for kNN clusters #Each row of this matrix represents a color scheme; hmcols &lt;- colorRampPalette(rev(c(&quot;#D73027&quot;, &quot;#FC8D59&quot;, &quot;#FEE090&quot;, &quot;#FFFFBF&quot;, &quot;#E0F3F8&quot;, &quot;#91BFDB&quot;, &quot;#4575B4&quot;)))(75) heatColors = rbind( greenred(75), bluered(75), colorpanel(75,&quot;green&quot;,&quot;black&quot;,&quot;magenta&quot;),colorpanel(75,&quot;blue&quot;,&quot;yellow&quot;,&quot;red&quot;),hmcols ) rownames(heatColors) = c(&quot;Green-Black-Red&quot;,&quot;Blue-White-Red&quot;,&quot;Green-Black-Magenta&quot;,&quot;Blue-Yellow-Red&quot;,&quot;Blue-white-brown&quot;) colorChoices = setNames(1:dim(heatColors)[1],rownames(heatColors)) # for pull down menu # Create a list for Select Input options speciesChoice = list() speciesChoice &lt;- append( setNames( &quot;NEW&quot;,&quot;**NEW SPECIES**&quot;), speciesChoice ) speciesChoice &lt;- append( setNames( &quot;BestMatch&quot;,&quot;Best matching species&quot;), speciesChoice ) 6.4 Read data and pre-process ################################################################ # Read data and pre-process ################################################################ readData &lt;- function(inFile ) { # these packages moved here to reduce loading time library(edgeR,verbose=FALSE) # count data D.E. library(DESeq2,verbose=FALSE) # count data analysis dataTypeWarning =0 dataType =c(TRUE) #---------------Read file x &lt;- read.csv(inFile) # try CSV if(dim(x)[2] &lt;= 2 ) # if less than 3 columns, try tab-deliminated x &lt;- read.table(inFile, sep=&quot;\\t&quot;,header=TRUE) #-------Remove non-numeric columns, except the first column for(i in 2:dim(x)[2]) dataType = c( dataType, is.numeric(x[,i]) ) if(sum(dataType) &lt;=2) return (NULL) # only less than 2 columns are numbers x &lt;- x[,dataType] # only keep numeric columns # rows with all missing values ix = which( apply(x[,-1],1, function(y) sum( is.na(y) ) ) != dim(x)[2]-1 ) x &lt;- x[ix,] dataSizeOriginal = dim(x); dataSizeOriginal[2] = dataSizeOriginal[2] -1 x[,1] &lt;- toupper(x[,1]) x[,1] &lt;- gsub(&quot; &quot;,&quot;&quot;,x[,1]) # remove spaces in gene ids x = x[order(- apply(x[,2:dim(x)[2]],1,sd) ),] # sort by SD x &lt;- x[!duplicated(x[,1]) ,] # remove duplicated genes rownames(x) &lt;- x[,1] x &lt;- as.matrix(x[,c(-1)]) # remove &quot;-&quot; or &quot;.&quot; from sample names colnames(x) = gsub(&quot;-&quot;,&quot;&quot;,colnames(x)) colnames(x) = gsub(&quot;\\\\.&quot;,&quot;&quot;,colnames(x)) #cat(&quot;\\nhere&quot;,dim(x)) # missng value for median value if(sum(is.na(x))&gt;0) {# if there is missing values if(input_missingValue ==&quot;geneMedian&quot;) { rowMedians &lt;- apply(x,1, function (y) median(y,na.rm=T)) for( i in 1:dim(x)[2] ) { ix = which(is.na(x[,i]) ) x[ix,i] &lt;- rowMedians[ix] } } else if(input_missingValue ==&quot;treatAsZero&quot;) { x[is.na(x) ] &lt;- 0 } else if (input_missingValue ==&quot;geneMedianInGroup&quot;) { sampleGroups = detectGroups( colnames(x)) for (group in unique( sampleGroups) ){ samples = which( sampleGroups == group ) rowMedians &lt;- apply(x[,samples, drop=F],1, function (y) median(y,na.rm=T)) for( i in samples ) { ix = which(is.na(x[ ,i] ) ) if(length(ix) &gt;0 ) x[ix, i ] &lt;- rowMedians[ix] } } # missing for entire sample group, use median for all samples if(sum(is.na(x) )&gt;0 ) { rowMedians &lt;- apply(x,1, function (y) median(y,na.rm=T)) for( i in 1:dim(x)[2] ) { ix = which(is.na(x[,i]) ) x[ix,i] &lt;- rowMedians[ix] } } } } # Compute kurtosis mean.kurtosis = mean(apply(x,2, kurtosis),na.rm=T) rawCounts = NULL pvals= NULL if (input_dataFileFormat == 2 ) { # if FPKM, microarray if ( is.integer(x) ) dataTypeWarning = 1; # Data appears to be read counts #-------------filtering #tem &lt;- apply(x,1,max) #x &lt;- x[which(tem &gt; input_lowFilter),] # max by row is at least x &lt;- x[ which( apply( x, 1, function(y) sum(y &gt;= input_lowFilter)) &gt;= input_NminSamples2 ) , ] x &lt;- x[which(apply(x,1, function(y) max(y)- min(y) ) &gt; 0 ),] # remove rows with all the same levels #--------------Log transform # Takes log if log is selected OR kurtosis is big than 100 if ( (input_transform == TRUE) | (mean.kurtosis &gt; kurtosis.log ) ) x = log(x+abs( input_logStart),2) tem &lt;- apply(x,1,sd) x &lt;- x[order(-tem),] # sort by SD } else if( input_dataFileFormat == 1) { # counts data # data not seems to be read counts if(!is.integer(x) &amp; mean.kurtosis &lt; kurtosis.log ) { dataTypeWarning = -1 } # not used as some counts data like those from CRISPR screen #validate( # if Kurtosis is less than a threshold, it is not read-count # need(mean.kurtosis &gt; kurtosis.log, &quot;Data does not seem to be read count based on distribution. Please double check.&quot;) # ) x &lt;- round(x,0) # enforce the read counts to be integers. Sailfish outputs has decimal points. #x &lt;- x[ which( apply(x,1,max) &gt;= input_minCounts ) , ] # remove all zero counts # remove genes if it does not at least have minCounts in at least NminSamples #x &lt;- x[ which( apply(x,1,function(y) sum(y&gt;=input_minCounts)) &gt;= input_NminSamples ) , ] # filtering on raw counts # using counts per million (CPM) for filtering out genes. # CPM matrix #N samples &gt; minCounts x &lt;- x[ which( apply( cpm(DGEList(counts = x)), 1, function(y) sum(y&gt;=input_minCounts)) &gt;= input_NminSamples ) , ] rawCounts = x; # ??? # construct DESeqExpression Object # colData = cbind(colnames(x), as.character(detectGroups( colnames(x) )) ) tem = rep(&quot;A&quot;,dim(x)[2]); tem[1] &lt;- &quot;B&quot; # making a fake design matrix to allow process, even when there is no replicates colData = cbind(colnames(x), tem ) colnames(colData) = c(&quot;sample&quot;, &quot;groups&quot;) dds &lt;- DESeqDataSetFromMatrix(countData = x, colData = colData, design = ~ groups) dds &lt;- estimateSizeFactors(dds) # estimate size factor for use in normalization later for started log method # regularized log or VST transformation if( input_CountsTransform == 3 ) { # rlog is slow, only do it with 10 samples if(dim(x)[2]&lt;=20 ) { x &lt;- rlog(dds, blind=TRUE); x &lt;- assay(x) } else x &lt;- log2( counts(dds, normalized=TRUE) + input_countsLogStart ) } else { if ( input_CountsTransform == 2 ) { # vst is fast but aggressive x &lt;- vst(dds, blind=TRUE) x &lt;- assay(x) } else{ # normalized by library sizes and add a constant. x &lt;- log2( counts(dds, normalized=TRUE) + input_countsLogStart ) # log(x+c) # This is equivalent to below. But the prior counts is more important #x &lt;- cpm(DGEList(counts = x),log=TRUE, prior.count=input_countsLogStart ) #log CPM from edgeR #x &lt;- x-min(x) # shift values to avoid negative numbers } } } else if( input_dataFileFormat == 3) { # other data type #neg_lfc neg_fdr pos_lfc pos_fdr #11 1 11 1 n2 = ( dim(x)[2] %/% 2) # 5 --&gt; 2 # It looks like it contains P values # ranges of columns add 0.2 and round to whole. For P value columns this should be 1 tem = round( apply(x, 2, function( y) max(y)- min(y)) + .2) if( sum(tem[(1:n2)*2 ] == 1 ) == n2 | sum(tem[(1:n2)*2-1 ] == 1 ) == n2 ) { x = x[,1:(2*n2) ,drop=FALSE ] # if 5, change it to 4 if(tem[2] == 1) { # FDR follows Fold-change pvals = x [,2*(1:n2 ),drop=FALSE ] # 2, 4, 6 x = x[, 2*(1:n2 )-1,drop=FALSE] # 1, 3, 5 } else { # FDR follows Fold-change pvals = x [,2*(1:n2 )-1,drop=FALSE ] # 2, 4, 6 x = x[, 2*(1: n2 ),drop=FALSE] # 1, 3, 5 } } ix = which(apply(x,1, function(y) max(y)- min(y) ) &gt; 0 ) x &lt;- x[ix,] # remove rows with all the same levels if(!is.null(pvals) ) pvals = pvals[ix,] } dataSize = dim(x); if(!(dim(x)[1]&gt;5 &amp; dim(x)[2]&gt;1)) stop ( &quot;Data file not recognized. Please double check.&quot;) sampleInfoDemo=NULL if( input_goButton &gt;0) sampleInfoDemo &lt;- t( read.csv(demoDataFile2,row.names=1,header=T,colClasses=&quot;character&quot;) ) finalResult &lt;- list(data = as.matrix(x), mean.kurtosis = mean.kurtosis, rawCounts = rawCounts, dataTypeWarning=dataTypeWarning, dataSize=c(dataSizeOriginal,dataSize),sampleInfoDemo=sampleInfoDemo, pvals =pvals ) return(finalResult) } readSampleInfo &lt;- function(inFile){ dataTypeWarning =0 dataType =c(TRUE) #---------------Read file x &lt;- read.csv(inFile,row.names=1,header=T,colClasses=&quot;character&quot;) # try CSV if(dim(x)[2] &lt;= 2 ) # if less than 3 columns, try tab-deliminated x &lt;- read.table(inFile, row.names=1,sep=&quot;\\t&quot;,header=TRUE,colClasses=&quot;character&quot;) # remove &quot;-&quot; or &quot;.&quot; from sample names colnames(x) = gsub(&quot;-&quot;,&quot;&quot;,colnames(x)) colnames(x) = gsub(&quot;\\\\.&quot;,&quot;&quot;,colnames(x)) #----------------Matching with column names of expression file ix = match(toupper(colnames(readData.out$data)), toupper(colnames(x)) ) ix = ix[which(!is.na(ix))] # remove NA if(! ( length(unique(ix) ) == dim(readData.out$data)[2] &amp; dim(x)[1]&gt;=1 &amp; dim(x)[1] &lt;500 ) ) # at least one row, it can not be more than 500 rows stop( &quot;Error!!! Sample information file not recognized. Sample names must be exactly the same. Each row is a factor. Each column represent a sample. Please see documentation on format.&quot;) #-----------Double check factor levels, change if needed # remove &quot;-&quot; or &quot;.&quot; from factor levels for( i in 1:dim(x)[1]) { x[i,] = gsub(&quot;-&quot;,&quot;&quot;,x[i,]) x[i,] = gsub(&quot;\\\\.&quot;,&quot;&quot;,x[i,]) } # if levels from different factors match if( length(unique(ix) ) == dim(readData.out$data)[2]) { # matches exactly x = x[,ix] # if the levels of different factors are the same, it may cause problems if( sum( apply(x, 1, function(y) length(unique(y)))) &gt; length(unique(unlist(x) ) ) ) { tem2 =apply(x,2, function(y) paste0( names(y),y)) # factor names are added to levels rownames(tem2) = rownames(x) x &lt;- tem2 } return(t( x ) ) } else retrun(NULL) } textTransform &lt;- function () { k.value = readData.out$mean.kurtosis tem = paste( &quot;Mean Kurtosis = &quot;, round(k.value,2), &quot;.\\n&quot;,sep = &quot;&quot;) if( k.value &gt; kurtosis.log) tem = paste(tem, &quot; Detected extremely large values. \\n When kurtosis &gt;&quot;, kurtosis.log, &quot;, log transformation is automatically applied.\\n&quot;, sep=&quot;&quot;) else if (k.value&gt;kurtosis.warning) {tem = paste(tem, &quot; Detected large numbers with kurtosis &gt;&quot;, kurtosis.warning,&quot;. \\n Log transformation is recommended.&quot;, sep=&quot;&quot;) } if(readData.out$dataTypeWarning == 1 ) { tem = paste (tem, &quot; ------Warning!!! \\nData matrix contains all integers. \\n It seems to be read counts!!! \\n Please select appropriate data type in the previous page and reload file.&quot;)} if(readData.out$dataTypeWarning == -1 ) { tem = paste (tem, &quot; ------Warning!!! \\nData does not look like read counts data. \\n Please select appropriate data type in the previous page and reload file.&quot;)} tem } # Clean up gene sets. Remove spaces and other control characters from gene names cleanGeneSet &lt;- function (x){ # remove duplicate; upper case; remove special characters x &lt;- unique( toupper( gsub(&quot;\\n| &quot;,&quot;&quot;,x) ) ) x &lt;- x[which( nchar(x)&gt;1) ] # genes should have at least two characters return(x) } findSpeciesById &lt;- function (speciesID){ # find species name use id return( orgInfo[which(orgInfo$id == speciesID),] ) } # just return name findSpeciesByIdName &lt;- function (speciesID){ # find species name use id return( orgInfo[which(orgInfo$id == speciesID),3] ) } # convert gene IDs to ensembl gene ids and find species convertID &lt;- function (query,selectOrg, selectGO) { querySet &lt;- cleanGeneSet( unlist( strsplit( toupper(query),&#39;\\t| |\\n|\\\\,&#39;))) # querySet is ensgene data for example, ENSG00000198888, ENSG00000198763, ENSG00000198804 querySTMT &lt;- paste( &quot;select distinct id,ens,species from mapping where id IN (&#39;&quot;, paste(querySet,collapse=&quot;&#39;, &#39;&quot;),&quot;&#39;)&quot;,sep=&quot;&quot;) result &lt;- dbGetQuery(convert, querySTMT) if( dim(result)[1] == 0 ) return(NULL) if(selectOrg == speciesChoice[[1]]) { comb = paste( result$species,result$idType) sortedCounts = sort(table(comb),decreasing=T) recognized =names(sortedCounts[1]) result &lt;- result[which(comb == recognized),] speciesMatched=sortedCounts names(speciesMatched )= sapply(as.numeric(gsub(&quot; .*&quot;,&quot;&quot;,names(sortedCounts) ) ), findSpeciesByIdName ) speciesMatched &lt;- as.data.frame( speciesMatched ) if(length(sortedCounts) == 1) { # if only one species matched speciesMatched[1,1] &lt;-paste( rownames(speciesMatched), &quot;(&quot;,speciesMatched[1,1],&quot;)&quot;,sep=&quot;&quot;) } else {# if more than one species matched speciesMatched[,1] &lt;- as.character(speciesMatched[,1]) speciesMatched[,1] &lt;- paste( speciesMatched[,1],&quot; (&quot;,speciesMatched[,2], &quot;)&quot;, sep=&quot;&quot;) speciesMatched[1,1] &lt;- paste( speciesMatched[1,1],&quot; ***Used in mapping*** To change, select from above and resubmit query.&quot;) speciesMatched &lt;- as.data.frame(speciesMatched[,1]) } } else { # if species is selected result &lt;- result[which(result$species == selectOrg ) ,] if( dim(result)[1] == 0 ) return(NULL) #stop(&quot;ID not recognized!&quot;) speciesMatched &lt;- as.data.frame(paste(&quot;Using selected species &quot;, findSpeciesByIdName(selectOrg) ) ) } result &lt;- result[which(!duplicated(result[,2]) ),] # remove duplicates in ensembl_gene_id result &lt;- result[which(!duplicated(result[,1]) ),] # remove duplicates in user ID colnames(speciesMatched) = c(&quot;Matched Species (genes)&quot; ) conversionTable &lt;- result[,1:2]; colnames(conversionTable) = c(&quot;User_input&quot;,&quot;ensembl_gene_id&quot;) conversionTable$Species = sapply(result[,3], findSpeciesByIdName ) return(list(originalIDs = querySet,IDs=unique( result[,2]), species = findSpeciesById(result$species[1]), #idType = findIDtypeById(result$idType[1] ), speciesMatched = speciesMatched, conversionTable = conversionTable ) ) } # retrieve detailed info on genes geneInfo &lt;- function (fileName = NULL){ if(!is.null(fileName)) # if only one file #WBGene0000001 some ensembl gene ids in lower case { x = read.csv(as.character(fileName) ); x[,1]= toupper(x[,1]) } else # read in the chosen file { return(as.data.frame(&quot;No file.&quot;) ) } Set=rep(&quot;List&quot;,nrow(x)) return( cbind(x,Set) ) } convertedData &lt;- function() { if( is.null(converted.out ) ) return( readData.out$data) # if id or species is not recognized use original data. if(input_noIDConversion) return( readData.out$data ) mapping &lt;- converted.out$conversionTable # cat (paste( &quot;\\nData:&quot;,input_selectOrg) ) x =readData.out$data rownames(x) = toupper(rownames(x)) # any gene not recognized by the database is disregarded # x1 = merge(mapping[,1:2],x, by.y = &#39;row.names&#39;, by.x = &#39;User_input&#39;) # the 3 lines keeps the unrecogized genes using original IDs x1 = merge(mapping[,1:2],x, by.y = &#39;row.names&#39;, by.x = &#39;User_input&#39;, all.y=TRUE) # original IDs used if ID is not matched in database ix = which(is.na(x1[,2]) ) x1[ix,2] = x1[ix,1] #multiple matched IDs, use the one with highest SD tem = apply(x1[,3:(dim(x1)[2])],1,sd) x1 = x1[order(x1[,2],-tem),] x1 = x1[!duplicated(x1[,2]) ,] rownames(x1) = x1[,2] x1 = as.matrix(x1[,c(-1,-2)]) tem = apply(x1,1,sd) x1 = x1[order(-tem),] # sort again by SD return(x1) } convertedCounts &lt;- function() { if( is.null(converted.out ) ) return( readData.out$rawCounts) mapping &lt;- converted.out$conversionTable x =readData.out$rawCounts rownames(x) = toupper(rownames(x)) # any gene not recognized by the database is disregarded # x1 = merge(mapping[,1:2],x, by.y = &#39;row.names&#39;, by.x = &#39;User_input&#39;) # the 3 lines keeps the unrecogized genes using original IDs x1 = merge(mapping[,1:2],x, by.y = &#39;row.names&#39;, by.x = &#39;User_input&#39;, all.y=TRUE) ix = which(is.na(x1[,2]) ) x1[ix,2] = x1[ix,1] # original IDs used #multiple matched IDs, use the one with highest SD tem = apply(x1[,3:(dim(x1)[2])],1,sd) x1 = x1[order(x1[,2],-tem),] x1 = x1[!duplicated(x1[,2]) ,] rownames(x1) = x1[,2] x1 = as.matrix(x1[,c(-1,-2)]) tem = apply(x1,1,sd) x1 = x1[order(-tem),] # sort again by SD return(x1) } # here nGenesFilter &lt;- function() { tem = readData.out$dataSize ix = match( toupper( rownames(convertedData.out)), toupper(converted.out$conversionTable$ensembl_gene_id ) ) nMatched = sum( !is.na(ix) ) if( input_noIDConversion) return( paste(tem[1], &quot;genes in&quot;, tem[4], &quot;samples.&quot;, tem[3], &quot; genes passed filter.\\n Original gene IDs used.&quot; ) ) else return( paste(tem[1], &quot;genes in&quot;, tem[4], &quot;samples. Of the&quot;, tem[3], &quot; genes passed filter, \\n&quot;, nMatched, &quot; were converted to Ensembl gene IDs in our database. \\n The remaining &quot;, tem[3]-nMatched, &quot;genes were kept in the data using original IDs.&quot; ) ) } # Define sample groups based on column names detectGroups &lt;- function (x){ # x are col names tem &lt;- gsub(&quot;[0-9]*$&quot;,&quot;&quot;,x) # Remove all numbers from end #tem = gsub(&quot;_Rep|_rep|_REP&quot;,&quot;&quot;,tem) tem &lt;- gsub(&quot;_$&quot;,&quot;&quot;,tem); # remove &quot;_&quot; from end tem &lt;- gsub(&quot;_Rep$&quot;,&quot;&quot;,tem); # remove &quot;_Rep&quot; from end tem &lt;- gsub(&quot;_rep$&quot;,&quot;&quot;,tem); # remove &quot;_rep&quot; from end tem &lt;- gsub(&quot;_REP$&quot;,&quot;&quot;,tem) # remove &quot;_REP&quot; from end return( tem ) } # EDA plots ------------------------------------- densityPlot &lt;- function() { set.seed(2) # seed for random number generator mycolors = sort(rainbow(20))[c(1,20,10,11,2,19,3,12,4,13,5,14,6,15,7,16,8,17,9,18)] # 20 colors for kNN clusters #Each row of this matrix represents a color scheme; x &lt;- readData.out$data myColors = mycolors plot(density(x[,1]),col = myColors[1], lwd=2, xlab=&quot;Expresson values&quot;, ylab=&quot;Density&quot;, main= &quot;Distribution of transformed data&quot;, ylim=c(0, max(density(x[,1])$y)+.02 ) ) for( i in 2:dim(x)[2] ) lines(density(x[,i]),col=myColors[i], lwd=2 ) if(dim(x)[2]&lt; 31 ) # if too many samples do not show legends legend(&quot;topright&quot;, cex=1,colnames(x), lty=rep(1,dim(x)[2]), col=myColors ) } genePlot &lt;- function() { x &lt;- convertedData.out Symbols &lt;- rownames(x) if( input_selectOrg != &quot;NEW&quot;) { ix = match( rownames(x), allGeneInfo.out[,1]) if( sum( is.na(allGeneInfo.out$symbol )) != dim(allGeneInfo.out )[1] ) { # symbol really exists? Symbols = as.character( allGeneInfo.out$symbol[ix] ) Symbols[which( nchar(Symbols) &lt;= 2 ) ] &lt;- rownames(x) [which( nchar(Symbols) &lt;= 2 ) ] } } x = as.data.frame(x) x$Genes = Symbols # matching from the beginning of symbol ix = which(regexpr( paste(&quot;^&quot; , toupper(input_geneSearch),sep=&quot;&quot;) ,toupper(x$Genes)) &gt; 0) if(grepl(&quot; &quot;, input_geneSearch) ) # if there is space character, do exact match ix = match(gsub(&quot; &quot;,&quot;&quot;, toupper(input_geneSearch)),x$Genes) # too few or too many genes found if(length(ix) == 0 | length(ix) &gt; 50 ) return(NULL) # no genes found mdf = melt(x[ix,],id.vars=&quot;Genes&quot;, value.name=&quot;value&quot;, variable.name=&quot;samples&quot;) p1 &lt;- ggplot(data=mdf, aes(x=samples, y=value, group = Genes, shape=Genes, colour = Genes)) + geom_line() + geom_point( size=5, fill=&quot;white&quot;)+ #shape=21 circle #theme(axis.text.x = element_text(size=16,angle = 45, hjust = 1)) + labs(y=&quot;Transformed expression level&quot;) + coord_cartesian(ylim = c(0, max(mdf$value))) p1 &lt;- p1 + theme(plot.title = element_text(size = 16,hjust = 0.5)) + # theme(aspect.ratio=1) + theme(axis.text.x = element_text(angle=45, size = 16, hjust=1), axis.text.y = element_text( size = 16), axis.title.x = element_blank(), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=12)) p1 } geneBarPlotError &lt;- function() { x &lt;- convertedData.out Symbols &lt;- rownames(x) if( input_selectOrg != &quot;NEW&quot;) { ix = match( rownames(x), allGeneInfo.out[,1]) if( sum( is.na(allGeneInfo.out$symbol )) != dim(allGeneInfo.out )[1] ) { # symbol really exists? Symbols = as.character( allGeneInfo.out$symbol[ix] ) Symbols[which( nchar(Symbols) &lt;= 2 ) ] &lt;- rownames(x) [which( nchar(Symbols) &lt;= 2 ) ] } } x = as.data.frame(x) x$Genes = Symbols #write.csv(x,&quot;tem.csv&quot;) # Search for genes #ix = grep(&quot;HOXA&quot;,toupper(x$Genes) ) # ix = grep(toupper(input_geneSearch),toupper(x$Genes)) # sox --&gt; Tsox # matching from the beginning of symbol ix = which(regexpr( paste(&quot;^&quot; , toupper(input_geneSearch),sep=&quot;&quot;) ,toupper(x$Genes)) &gt; 0) if(grepl(&quot; &quot;, input_geneSearch) ) # if there is space character, do exact match ix = match(gsub(&quot; &quot;,&quot;&quot;, toupper(input_geneSearch)),x$Genes) # too few or too many genes found if(length(ix) == 0 | length(ix) &gt; 50 ) return(NULL) # no genes found mdf = melt(x[ix,],id.vars=&quot;Genes&quot;, value.name=&quot;value&quot;, variable.name=&quot;samples&quot;) mdf$count = 1 g = detectGroups(mdf$samples) Means = aggregate(mdf$value,by=list( g, mdf$Genes ), FUN = mean, na.rm=TRUE ) SDs = aggregate(mdf$value,by=list( g, mdf$Genes ), FUN = sd, na.rm=TRUE ) Ns = aggregate(mdf$count, by= list(g, mdf$Genes) , FUN = sum ) summarized = cbind(Means,SDs[,3],Ns[,3]) colnames(summarized)= c(&quot;Samples&quot;,&quot;Genes&quot;,&quot;Mean&quot;,&quot;SD&quot;,&quot;N&quot;) summarized$SE = summarized$SD / sqrt(summarized$N) #http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization p2 &lt;- ggplot(summarized, aes(x=Genes, y=Mean,fill=Samples) ) + # data &amp; aesthetic mapping geom_bar(stat=&quot;identity&quot;, position=position_dodge()) + # bars represent average geom_errorbar(aes(ymin=Mean-SE, ymax=Mean+SE), width=0.2,position=position_dodge(.9)) + labs(y=&quot;Expression Level&quot;) if(input_useSD == 1) { p2 &lt;- ggplot(summarized, aes(x=Genes, y=Mean,fill=Samples) ) + # data &amp; aesthetic mapping geom_bar(stat=&quot;identity&quot;, position=position_dodge()) + # bars represent average geom_errorbar(aes(ymin=Mean-SD, ymax=Mean+SD), width=0.2,position=position_dodge(.9)) + labs(y=&quot;Expression Level&quot;) } p2 &lt;- p2 + theme(plot.title = element_text(size = 16,hjust = 0.5)) + # theme(aspect.ratio=1) + theme(axis.text.x = element_text(angle=45, size = 16, hjust=1), axis.text.y = element_text( size = 16), axis.title.x = element_blank(), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) p2 } 6.5 Hierarchical clustering ################################################################ # Hierarchical clustering ################################################################ # Functions for hierarchical clustering hclust2 &lt;- function(x, method=&quot;average&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.ward.D &lt;- function(x, method=&quot;ward.D&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.ward.D2 &lt;- function(x, method=&quot;ward.D2&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.single &lt;- function(x, method=&quot;single&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.mcquitty &lt;- function(x, method=&quot;mcquitty&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.median &lt;- function(x, method=&quot;median&quot;, ...) # average linkage hclust(x, method=method, ...) hclust.centroid &lt;- function(x, method=&quot;centroid&quot;, ...) # average linkage hclust(x, method=method, ...) hclustFuns &lt;- list( averge = hclust2, complete=hclust, single=hclust.single, median=hclust.median, centroid=hclust.centroid, mcquitty=hclust.mcquitty) hclustChoices = setNames(1:length(hclustFuns),names(hclustFuns)) # for pull down menu dist2 &lt;- function(x, ...) # distance function = 1-PCC (Pearson&#39;s correlation coefficient) as.dist(1-cor(t(x), method=&quot;pearson&quot;)) dist3 &lt;- function(x, ...) # distance function = 1-abs(PCC) (Pearson&#39;s correlation coefficient) as.dist(1-abs(cor(t(x), method=&quot;pearson&quot;))) distFuns &lt;- list(Correlation=dist2, Euclidean=dist,AbsolutePCC=dist3) # hierarchical clustering tree ---------------------------------------- hmcols &lt;- colorRampPalette(rev(c(&quot;#D73027&quot;, &quot;#FC8D59&quot;, &quot;#FEE090&quot;, &quot;#FFFFBF&quot;, &quot;#E0F3F8&quot;, &quot;#91BFDB&quot;, &quot;#4575B4&quot;)))(75) heatColors = rbind( greenred(75), bluered(75), colorpanel(75,&quot;green&quot;,&quot;black&quot;,&quot;magenta&quot;),colorpanel(75,&quot;blue&quot;,&quot;yellow&quot;,&quot;red&quot;),hmcols ) rownames(heatColors) = c(&quot;Green-Black-Red&quot;,&quot;Blue-White-Red&quot;,&quot;Green-Black-Magenta&quot;,&quot;Blue-Yellow-Red&quot;,&quot;Blue-white-brown&quot;) colorChoices = setNames(1:dim(heatColors)[1],rownames(heatColors)) # for pull down menu # adding sample legends to heatmap; this is for the main heatmap # https://stackoverflow.com/questions/3932038/plot-a-legend-outside-of-the-plotting-area-in-base-graphics add_legend &lt;- function(...) { opar &lt;- par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 6), new=TRUE) on.exit(par(opar)) plot(0, 0, type=&#39;n&#39;, bty=&#39;n&#39;, xaxt=&#39;n&#39;, yaxt=&#39;n&#39;) legend(...) } correlationMatrix &lt;- function( ) { # heatmap of correlation matrix x &lt;- readData.out$data maxGene &lt;- apply(x,1,max) x &lt;- x[which(maxGene &gt; quantile(maxGene)[1] ) ,] # remove bottom 25% lowly expressed genes, which inflate the PPC melted_cormat &lt;- melt(round(cor(x),2), na.rm = TRUE) # melted_cormat &lt;- melted_cormat[which(melted_cormat[,1] != melted_cormat[,2] ) , ] # Create a ggheatmap ggheatmap &lt;- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+ geom_tile(color = &quot;white&quot;)+ scale_fill_gradient2(low = &quot;green&quot;, high = &quot;red&quot;, mid = &quot;white&quot;, space = &quot;Lab&quot;, limit = c(min(melted_cormat[,3]) ,max(melted_cormat[,3])), midpoint = median(melted_cormat[,3]), name=&quot;Pearson\\nCorrelation&quot; ) + theme_minimal()+ # minimal theme theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 15, hjust = 1))+ theme(axis.text.y = element_text( size = 15))+ coord_fixed()+ theme( axis.title.x = element_blank(), axis.title.y = element_blank(), panel.grid.major = element_blank(), panel.border = element_blank(), panel.background = element_blank(), axis.ticks = element_blank(), legend.justification = c(1, 0), legend.position = c(0.6, 0.7), legend.direction = &quot;horizontal&quot;)+ guides(fill = FALSE) # + ggtitle(&quot;Pearson&#39;s Correlation Coefficient (all genes)&quot;) if(input_labelPCC &amp;&amp; ncol(x)&lt;30) ggheatmap &lt;- ggheatmap + geom_text(aes(Var2, Var1, label = value), color = &quot;black&quot;, size = 4) ggheatmap } staticHeatmap &lt;- function () { x &lt;- readData.out$data # x = read.csv(&quot;expression1.csv&quot;) n=input_nGenes #if(n&gt;6000) n = 6000 # max if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data # this will cutoff very large values, which could skew the color if(input_geneCentering) x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) # standardize by gene if(input_geneNormalize) x &lt;- x / apply(x,1,sd) # row centering and normalize x &lt;- scale(x, center = input_sampleCentering, scale = input_sampleNormalize) cutoff = median(unlist(x)) + input_heatmapCutoff * sd (unlist(x)) x[x&gt;cutoff] &lt;- cutoff cutoff = median(unlist(x)) - input_heatmapCutoff *sd (unlist(x)) x[x&lt; cutoff] &lt;- cutoff groups = detectGroups(colnames(x) ) # if sample info file is uploaded us that info: if(!is.null(readSampleInfo.out) &amp;&amp; !is.null(input_selectFactorsHeatmap) ) { if(input_selectFactorsHeatmap == &quot;Sample_Name&quot; ) groups = detectGroups(colnames(x) ) else { ix = match(input_selectFactorsHeatmap, colnames(readSampleInfo.out ) ) groups = readSampleInfo.out[,ix] } } groups.colors = rainbow(length(unique(groups) ) ) #http://stackoverflow.com/questions/15351575/moving-color-key-in-r-heatmap-2-function-of-gplots-package lmat = rbind(c(0,4),c(0,1),c(3,2),c(5,0)) lwid = c(2,6) # width of gene tree; width of heatmap lhei = c(1.5,.2,8,1.1) #layout matrix # [,1] [,2] # [1,] 0 4 # [2,] 0 1 # [3,] 3 2 # [4,] 5 0 # 4--&gt; column tree; 1--&gt; column color bar; 2--&gt; heatmap; 3-&gt; row tree; 5--&gt; color key. # height of 4 rows is specified by lhei; width of columns is given by lwid par(mar = c(12, 4, 1.4, 0.2)) if( n&gt;110) heatmap.2(x, distfun = distFuns[[as.integer(input_distFunctions)]] ,hclustfun=hclustFuns[[as.integer(input_hclustFunctions)]] ,Colv=!input_noSampleClustering #col=colorpanel(75,&quot;green&quot;,&quot;black&quot;,&quot;magenta&quot;) , #col=bluered(75), #col=greenred(75), ,col= heatColors[as.integer(input_heatColors1),] ,density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.5 ,key=T, symkey=F ,ColSideColors=groups.colors[ as.factor(groups)] ,labRow=&quot;&quot; ,margins=c(10,2) ,srtCol=45 ,cexCol=2 # size of font for sample names ,lmat = lmat, lwid = lwid, lhei = lhei ) if( n&lt;=110) heatmap.2(x, distfun = distFuns[[as.integer(input_distFunctions)]] ,hclustfun=hclustFuns[[as.integer(input_hclustFunctions)]] ,Colv=!input_noSampleClustering ,col= heatColors[as.integer(input_heatColors1),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.5 ,key=T, symkey=F #,labRow=labRow ,ColSideColors=groups.colors[ as.factor(groups)] ,margins=c(18,12) ,cexRow=1 ,srtCol=45 ,cexCol=1.8 # size of font for sample names ,lmat = lmat, lwid = lwid, lhei = lhei ) par(lend = 1) # square line ends for the color legend add_legend(&quot;topleft&quot;, legend = unique(groups), # category labels col = groups.colors[ unique(as.factor(groups))], # color key lty= 1, # line style lwd = 10 # line width ) } #Interactive heatmap via Plotly plot ---------------------------------------------- # interactive heatmap with plotly heatmapPlotly &lt;- function () { input_nGenesPlotly= 50 x &lt;- convertedData.out n=input_nGenesPlotly #if(n&gt;6000) n = 6000 # max if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data if(input_geneCentering) x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) # standardize by gene if(input_geneNormalize) x &lt;- x / apply(x,1,sd) # row centering and normalize x &lt;- scale(x, center = input_sampleCentering, scale = input_sampleNormalize) cutoff = median(unlist(x)) + 3*sd (unlist(x)) x[x&gt;cutoff] &lt;- cutoff cutoff = median(unlist(x)) - 3*sd (unlist(x)) x[x&lt; cutoff] &lt;- cutoff # adding gene symbol ix &lt;- match( rownames(x), allGeneInfo.out[,1]) geneSymbols &lt;- as.character( allGeneInfo.out$symbol)[ix] # if missing or duplicated, use Ensembl ID ix &lt;- which(nchar( geneSymbols) &lt;=1 | duplicated(geneSymbols ) | is.null(geneSymbols) | is.na(geneSymbols) ); geneSymbols[ ix ] &lt;- rownames(x)[ix] rownames( x) = geneSymbols; clust &lt;- x %&gt;% dist2() %&gt;% hclust2() # Get order ord &lt;- clust$order # Re-arrange based on order df &lt;- t( x[ord,] )%&gt;% melt() colnames(df)[1:2] &lt;- c(&quot;X&quot;,&quot;Y&quot;) colorNames = unlist(strsplit(tolower(rownames(heatColors)[ as.integer(input_heatColors1) ]),&quot;-&quot; ) ) p &lt;- df %&gt;% ggplot(aes(X, Y, fill = value)) + geom_tile()+ scale_fill_gradient2(low = colorNames[1], mid = colorNames[2],high = colorNames[3]) + theme(axis.title.y=element_blank(), # remove y labels # axis.text.y=element_blank.out, # keep gene names for zooming axis.ticks.y=element_blank(), axis.title.x=element_blank()) + theme(axis.text.x = element_text(size=10,angle = 45, hjust = 1)) ggplotly(p) %&gt;% layout(margin = list(b = 150,l=200)) # prevent cutoff of sample names } 6.6 PCA ################################################################ # PCA ################################################################ PCAplot &lt;- function() { #PCA x &lt;- convertedData.out; pca.object &lt;- prcomp(t(x)) pcaData = as.data.frame(pca.object$x[,1:2]); pcaData = cbind(pcaData,detectGroups(colnames(x)) ) colnames(pcaData) = c(&quot;PC1&quot;, &quot;PC2&quot;, &quot;Sample_Name&quot;) percentVar=round(100*summary(pca.object)$importance[2,1:2],0) if(is.null(readSampleInfo.out)) { p=ggplot(pcaData, aes(PC1, PC2, color=Sample_Name, shape = Sample_Name)) + geom_point(size=5) } else { pcaData = cbind(pcaData,readSampleInfo.out ) p=ggplot(pcaData, aes_string(&quot;PC1&quot;, &quot;PC2&quot;, color=input_selectFactors,shape=input_selectFactors2)) + geom_point(size=5) } p=p+xlab(paste0(&quot;PC1: &quot;,percentVar[1],&quot;% variance&quot;)) p=p+ylab(paste0(&quot;PC2: &quot;,percentVar[2],&quot;% variance&quot;)) p=p+ggtitle(&quot;Principal component analysis (PCA)&quot;)+coord_fixed(ratio=1.0)+ theme(plot.title = element_text(size = 16,hjust = 0.5)) + theme(aspect.ratio=1) + theme(axis.text.x = element_text( size = 16), axis.text.y = element_text( size = 16), axis.title.x = element_text( size = 16), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) print(p) } # variance chart # plot(pca.object,type=&quot;bar&quot;, xlab=&quot;Principal Components&quot;, main =&quot;Variances explained&quot;) MDSplot &lt;- function() { # MDS x &lt;- convertedData.out; fit = cmdscale( dist2(t(x) ), eig=T, k=2) # par(pin=c(5,5)) pcaData = as.data.frame(fit$points[,1:2]); pcaData = cbind(pcaData,detectGroups(colnames(x)) ) colnames(pcaData) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;Sample_Name&quot;) if(is.null(readSampleInfo.out)) { p=ggplot(pcaData, aes(x1, x2, color=Sample_Name, shape = Sample_Name)) + geom_point(size=5) } else { pcaData = cbind(pcaData,readSampleInfo.out ) p=ggplot(pcaData, aes_string(&quot;x1&quot;, &quot;x2&quot;, color=input_selectFactors,shape=input_selectFactors2)) + geom_point(size=5) } p=p+xlab(&quot;Dimension 1&quot;) p=p+ylab(&quot;Dimension 2&quot;) p=p+ggtitle(&quot;Multidimensional scaling (MDS)&quot;)+ coord_fixed(ratio=1.)+ theme(plot.title = element_text(hjust = 0.5)) + theme(aspect.ratio=1) + theme(axis.text.x = element_text( size = 16), axis.text.y = element_text( size = 16), axis.title.x = element_text( size = 16), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) print(p) } tSNEplot &lt;- function() { # t-SNE x &lt;- convertedData.out; library(Rtsne,verbose=FALSE) set.seed(input_tsneSeed2) tsne &lt;- Rtsne(t(x), dims = 2, perplexity=1, verbose=FALSE, max_iter = 400) pcaData = as.data.frame(tsne$Y); pcaData = cbind(pcaData,detectGroups(colnames(x)) ) colnames(pcaData) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;Sample_Name&quot;) if(is.null(readSampleInfo.out)) { p=ggplot(pcaData, aes(x1, x2, color=Sample_Name, shape = Sample_Name)) + geom_point(size=5) } else { pcaData = cbind(pcaData,readSampleInfo.out ) p=ggplot(pcaData, aes_string(&quot;x1&quot;, &quot;x2&quot;, color=input_selectFactors,shape=input_selectFactors2)) + geom_point(size=5) } p=p+xlab(&quot;Dimension 1&quot;) p=p+ylab(&quot;Dimension 2&quot;) p=p+ggtitle(&quot;t-SNE plot&quot;)+ coord_fixed(ratio=1.)+ theme(plot.title = element_text(hjust = 0.5)) + theme(aspect.ratio=1) + theme(axis.text.x = element_text( size = 16), axis.text.y = element_text( size = 16), axis.title.x = element_text( size = 16), axis.title.y = element_text( size = 16) ) + theme(legend.text=element_text(size=16)) print(p) } # read pathway data from local file, not used if using database # Read gene sets GMT file # This functions cleans and converts to upper case readGMTRobust &lt;- function (file1) { # size restriction # Read in the first file x &lt;- scan(file1, what=&quot;&quot;, sep=&quot;\\n&quot;) # x &lt;- gsub(&quot;\\t\\t.&quot;,&quot;&quot;,x) # GMT files saved by Excel has a lot of empty cells &quot;\\t\\t\\t\\t&quot; &quot;\\t.&quot; means one or more tab x &lt;- gsub(&quot; &quot;,&quot;&quot;,x) # remove white space x &lt;- toupper(x) # convert to upper case #----Process the first file # Separate elements by one or more whitespace y &lt;- strsplit(x, &quot;\\t&quot;) # Extract the first vector element and set it as the list element name names(y) &lt;- sapply(y, `[[`, 1) #names(y) &lt;- sapply(y, function(x) x[[1]]) # same as above # Remove the first vector element from each list element y &lt;- lapply(y, `[`, -c(1,2)) #y &lt;- lapply(y, function(x) x[-1]) # same as above # remove duplicated elements for ( i in 1:length(y) ) y[[i]] &lt;- cleanGeneSet(y[[i]]) # check the distribution of the size of gene lists sapply(y, length) hold a vector of sizes if( max( sapply(y,length) ) &lt;5) cat(&quot;Warning! Gene sets have very small number of genes!\\n Please double check format.&quot;) y &lt;- y[which(sapply(y,length) &gt; 1)] # gene sets smaller than 1 is ignored!!! return(y) } readGeneSets &lt;- function (fileName, convertedData, GO,selectOrg, myrange) { pathway &lt;- dbConnect(sqlite,fileName) if(is.null(GO) ) GO &lt;- &quot;GOBP&quot; # initial value not properly set; enforcing # get Gene sets querySet = rownames(convertedData) sqlQuery = paste( &quot; select distinct gene,pathwayID from pathway where gene IN (&#39;&quot;, paste(querySet,collapse=&quot;&#39;, &#39;&quot;),&quot;&#39;)&quot; ,sep=&quot;&quot;) # cat(paste0(&quot;\\n\\nhere:&quot;,GO,&quot;There&quot;)) if( GO != &quot;All&quot;) sqlQuery = paste0(sqlQuery, &quot; AND category =&#39;&quot;,GO,&quot;&#39;&quot;) result &lt;- dbGetQuery( pathway, sqlQuery ) if( dim(result)[1] ==0) {return(list( x=as.data.frame(&quot;No matching species or gene ID file!&quot; )) )} # list pathways and frequency of genes pathwayIDs = aggregate( result$pathwayID, by = list(unique.values = result$pathwayID), FUN = length) pathwayIDs = pathwayIDs[which(pathwayIDs[,2]&gt;= myrange[1] ),] pathwayIDs = pathwayIDs[which( pathwayIDs[,2] &lt;= myrange[2] ),] if(dim(pathwayIDs)[1] ==0 ) geneSets = NULL; # convert pathways into lists like those generated by readGMT geneSets = lapply(pathwayIDs[,1], function(x) result[which(result$pathwayID == x ),1] ) pathwayInfo &lt;- dbGetQuery( pathway, paste( &quot; select distinct id,Description from pathwayInfo where id IN (&#39;&quot;, paste(pathwayIDs[,1],collapse=&quot;&#39;, &#39;&quot;), &quot;&#39;) &quot;,sep=&quot;&quot;) ) ix = match( pathwayIDs[,1], pathwayInfo[,1]) names(geneSets) &lt;- pathwayInfo[ix,2] #geneSets &lt;- geneSets[ -which(duplicated(names(geneSets) ))] # remove geneSets with the same name dbDisconnect(pathway) return( geneSets ) } # Runs pathway analysis using PGSEA; this is copied and revised from PGSEA package myPGSEA &lt;- function (exprs, cl, range = c(25, 500), ref = NULL, center = TRUE, p.value = 0.005, weighted = TRUE, nPermutation=100, enforceRange = TRUE, ...) { if (is(exprs, &quot;ExpressionSet&quot;)) exprs &lt;- exprs(exprs) if (!is.list(cl)) stop(&quot;cl need to be a list&quot;) if (!is.null(ref)) { if (!is.numeric(ref)) stop(&quot;column index&#39;s required&quot;) } if (!is.null(ref)) { if (options.out$verbose) cat(&quot;Creating ratios...&quot;, &quot;\\n&quot;) ref_mean &lt;- apply(exprs[, ref], 1, mean, na.rm = TRUE) exprs &lt;- sweep(exprs, 1, ref_mean, &quot;-&quot;) } if (center) exprs &lt;- scale(exprs, scale = FALSE) # column centering is done results &lt;- matrix(NA, length(cl), ncol(exprs)) rownames(results) &lt;- names(cl) colnames(results) &lt;- colnames(exprs) mode(results) &lt;- &quot;numeric&quot; Setsize = c(rep(0,length(cl))) # gene set size vector mean2 = c(rep(0,length(cl))) # mean of the range of means meanSD = c(rep(0,length(cl))) # SD of the range of means if (is.logical(p.value)) { p.results &lt;- results; mean.results &lt;- results;} for (i in 1:length(cl)) { # for each gene list #cat(&quot;\\nProcessing gene set&quot;,i); if (class(cl[[i]]) == &quot;smc&quot;) { clids &lt;- cl[[i]]@ids } else if (class(cl[[i]]) %in% c(&quot;GeneColorSet&quot;, &quot;GeneSet&quot;)) { clids &lt;- cl[[i]]@geneIds } else { clids &lt;- cl[[i]] } if (options()$verbose) cat(&quot;Testing region &quot;, i, &quot;\\n&quot;) ix &lt;- match(clids, rownames(exprs)) ix &lt;- unique(ix[!is.na(ix)]) present &lt;- sum(!is.na(ix)) Setsize[i] &lt;- present if (present &lt; range[1]) { if (options()$verbose) cat(&quot;Skipping region &quot;, i, &quot; because too small-&quot;, present, &quot;,\\n&quot;) next } if (present &gt; range[2]) { if (options()$verbose) cat(&quot;Skipping region &quot;, i, &quot; because too large-&quot;, present, &quot;\\n&quot;) next } texprs &lt;- exprs[ix, ] # expression matrix for genes in gene set if (any(is.na(texprs))) cat(&quot;Warning - &#39;NA&#39; values within expression data, enrichment scores are estimates only.\\n&quot;) if (!is.matrix(texprs)) texprs &lt;- as.matrix(texprs) stat &lt;- try(apply(texprs, 2, t.test, ...)) means &lt;- try(apply(texprs, 2, mean,trim=0.1)) # trim mean ps &lt;- unlist(lapply(stat, function(x) x$p.value)) stat &lt;- unlist(lapply(stat, function(x) x$statistic)) p.results[i, ] &lt;- ps mean.results[i,] &lt;- means results[i, ] &lt;- as.numeric(stat) # permutation of gene sets of the same size if(nPermutation &gt; 2 ) { # no permutation if &lt;=2 meansRanges = c(0, rep(nPermutation)) for( k in 1:nPermutation ) { ix &lt;- sample.int( dim(exprs)[1], length(ix) ) texprs &lt;- exprs[ix, ] means &lt;- try(apply(texprs, 2, mean,trim=0.1)) # trim mean meansRanges[k] = dynamicRange(means) } mean2[i] = mean(meansRanges) meanSD[i]= sd(meansRanges,na.rm=TRUE) # NA are removed before calculating standard deviation } } return(list(results = results, p.results = p.results, means = mean.results, size=Setsize, mean2=mean2, meanSD=meanSD)) } PCApathway&lt;- function () { # pathway x &lt;- convertedData.out; library(PGSEA,verbose=FALSE) pca.object &lt;- prcomp(t(x)) pca = 100*pca.object$rotation Npca = 5 if (Npca &gt; dim(pca)[2]) { Npca = dim(pca)[2] } else pca &lt;- pca[,1:Npca] #pca = pca[,1:5] if(is.null(GeneSets.out ) ) return(NULL) # no species recognized if(length(GeneSets.out ) &lt;= 1 ) return(NULL) #cat(&quot;\\n\\nGene Sets:&quot;,length( GeneSets.out)) pg = myPGSEA (pca,cl=GeneSets.out,range=c(15,2000),p.value=TRUE, weighted=FALSE,nPermutation=1) # correcting for multiple testing p.matrix = pg$p.result tem = p.adjust(as.numeric(p.matrix),&quot;fdr&quot;) p.matrix = matrix(tem, nrow=dim(p.matrix)[1], ncol = dim(p.matrix)[2] ) rownames(p.matrix) = rownames(pg$p.result); colnames(p.matrix) = colnames(pg$p.result) selected =c() for( i in 1:dim(p.matrix)[2]) { tem = which( rank(p.matrix[,i],ties.method=&#39;first&#39;) &lt;= 5) # rank by P value #tem = which( rank(pg$result[,i],ties.method=&#39;first&#39;) &gt;= dim(p.matrix)[1]-3.1) # rank by mean names(tem) = paste(&quot;PC&quot;,i,&quot; &quot;, rownames(p.matrix)[tem], sep=&quot;&quot; ) selected = c(selected, tem) } rowids = gsub(&quot; .*&quot;,&quot;&quot;,names(selected)) rowids = as.numeric( gsub(&quot;PC&quot;,&quot;&quot;,rowids) ) pvals = p.matrix[ cbind(selected,rowids) ] a=sprintf(&quot;%-1.0e&quot;,pvals) tem = pg$result[selected,] rownames(tem) = paste(a,names(selected)); #colnames(tem)= paste(&quot;PC&quot;,colnames(tem),sep=&quot;&quot;) tem = tem[!duplicated(selected),] #tem = t(tem); tem = t( (tem - apply(tem,1,mean)) ) #/apply(tem,1,sd) ) smcPlot(tem,scale = c(-max(tem), max(tem)), show.grid = T, margins = c(3,1, 6, 23), col = .rwb,cex.lab=0.5, main=&quot;Pathways analysis on PCA&quot;) } # correlation PCA with factors PCA2factor &lt;- function( ){ if(is.null(readSampleInfo.out)) return(NULL) npc = 5 # number of Principal components x &lt;- readData.out$data y &lt;- readSampleInfo.out pca.object &lt;- prcomp(t(x)) pcaData = as.data.frame(pca.object$x[,1:npc]); pvals = matrix(1,nrow=npc,ncol=ncol(y)) for (i in 1:npc ){ for (j in 1:ncol(y) ) pvals[i,j] =summary( aov(pcaData[,i] ~ as.factor(y[,j])))[[1]][[&quot;Pr(&gt;F)&quot;]][1] } pvals = pvals * npc* ncol(y) # correcting for multiple testing pvals[pvals&gt;1] = 1 colnames(pvals) = colnames(y) rownames(pvals) = paste0(&quot;PC&quot;,1:npc) a=&quot;\\n Correlation between Principal Components (PCs) with factors\\n&quot; nchar0 = nchar(a) for ( i in 1:npc){ j = which.min(pvals[i,]) if(pvals[i,j]&lt; 0.05) a=paste0(a,rownames(pvals)[i], &quot; is correlated with &quot;, colnames(pvals)[j], &quot; (p=&quot;, sprintf(&quot;%-3.2e&quot;,pvals[i,j]),&quot;).\\n&quot;) } if(nchar(a) == nchar0 ) return(NULL) else return( a ) } # detecting sequencing depth bias readCountsBias &lt;- function( ){ totalCounts = colSums(readData.out$rawCounts) groups = as.factor( detectGroups(colnames(readData.out$rawCounts ) ) ) tem = NULL # ANOVA of total read counts vs sample groups parsed by sample name pval = summary( aov(totalCounts ~ groups ))[[1]][[&quot;Pr(&gt;F)&quot;]][1] if(pval &lt;0.05) tem = paste(&quot;Warning! Sequencing depth bias detected. Total read counts are significantly different among sample groups (p=&quot;, sprintf(&quot;%-3.2e&quot;,pval),&quot;) based on ANOVA.&quot;) # ANOVA of total read counts vs factors in experiment design if(!is.null(readSampleInfo.out ) ) { y &lt;- readSampleInfo.out for (j in 1:ncol(y) ) { pval = summary( aov(totalCounts ~ as.factor(y[,j])))[[1]][[&quot;Pr(&gt;F)&quot;]][1] if(pval &lt;0.05) tem = paste(tem, &quot; Total read counts seem to be correlated with factor&quot;,colnames(y)[j], &quot;(p=&quot;, sprintf(&quot;%-3.2e&quot;,pval),&quot;). &quot;) } } if(is.null(tem)) return( &quot;No bias detected&quot;) else return( tem ) } 6.7 K-means clustering ################################################################ # K-means clustering ################################################################ #Distribution of SDs distributionSD &lt;- function() { SDs=apply(convertedData.out,1,sd) maxSD = mean(SDs)+ 4*sd(SDs) SDs[ SDs &gt; maxSD] = maxSD top = input_nGenesKNN if(top &gt; length(SDs)) top = length(SDs) Cutoff=sort(SDs,decreasing=TRUE)[top] SDs = as.data.frame(SDs) p &lt;- ggplot(SDs, aes(x=SDs)) + geom_density(color=&quot;darkblue&quot;, fill=&quot;lightblue&quot;) + labs(x = &quot;Standard deviations of all genes&quot;, y=&quot;Density&quot;)+ geom_vline(aes(xintercept=Cutoff), color=&quot;red&quot;, linetype=&quot;dashed&quot;, size=1) + annotate(&quot;text&quot;, x = Cutoff + 0.4*sd(SDs[,1]), y = 1,colour = &quot;red&quot;, label = paste0(&quot;Top &quot;, top)) p } # Decide number of clusters KmeansNclusters &lt;- function() { # Kmeans clustering x &lt;- convertedData.out #x &lt;- readData.out #par(mfrow=c(1,2)) n=input_nGenesKNN #if(n&gt;6000) n = 6000 # max if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data #x1 &lt;- x; #x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) x = 100* x[1:n,] / apply(x[1:n,],1,sum) # this is causing problem?????? #x = x - apply(x,1,mean) # this is causing problem?????? #colnames(x) = gsub(&quot;_.*&quot;,&quot;&quot;,colnames(x)) set.seed(2) k = 30 wss &lt;- (nrow(x)-1)*sum(apply(x,2,var)) for (i in 2:k) wss[i] &lt;- sum(kmeans(x,centers=i,iter.max = 30)$withinss) par(mar=c(4,5,4,4)) plot(1:k, wss, type=&quot;b&quot;, xlab=&quot;Number of Clusters (k)&quot;, ylab=&quot;Within groups sum of squares&quot;, cex=2,cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2 ,xaxt=&quot;n&quot; ) axis(1, at = seq(1, 30, by = 2),cex.axis=1.5,cex=1.5) } Kmeans &lt;- function() { # Kmeans clustering x &lt;- convertedData.out #x &lt;- readData.out #par(mfrow=c(1,2)) n=input_nGenesKNN if(n&gt;maxGeneClustering) n = maxGeneClustering # max if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data #x1 &lt;- x; #x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) #x = 100* x[1:n,] / apply(x[1:n,],1,sum) x = x[1:n,] if( input_kmeansNormalization == &#39;L1Norm&#39;) x = 100* x / apply(x,1,function(y) sum(abs(y))) else # L1 norm if( input_kmeansNormalization == &#39;geneMean&#39;) x = x - apply(x,1,mean) else # this is causing problem?????? if( input_kmeansNormalization == &#39;geneStandardization&#39;) x = (x - apply(x,1,mean) ) / apply(x,1,sd) #colnames(x) = gsub(&quot;_.*&quot;,&quot;&quot;,colnames(x)) set.seed(input_KmeansReRun) k=input_nClusters cl = kmeans(x,k,iter.max = 50) #myheatmap(cl$centers) hc &lt;- hclust2(dist2(cl$centers-apply(cl$centers,1,mean) ) )# perform cluster for the reordering of samples tem = match(cl$cluster,hc$order) # new order x = x[order(tem),] ; bar = sort(tem) #myheatmap2(x-apply(x,1,mean), bar,1000) return(list( x = x, bar = bar)) } myheatmap2 &lt;- function (x,bar=NULL,n=-1,mycolor=1,clusterNames=NULL,sideColors=NULL ) { # number of genes to show ngenes = as.character( table(bar)) if(length(bar) &gt;n &amp;&amp; n != -1) {ix = sort( sample(1:length(bar),n) ); bar = bar[ix]; x = x[ix,] } if(! is.null(bar) ) if(is.null(sideColors) ) sideColors = mycolors # this will cutoff very large values, which could skew the color x=as.matrix(x)-apply(x,1,mean) cutoff = median(unlist(x)) + 3*sd (unlist(x)) x[x&gt;cutoff] &lt;- cutoff cutoff = median(unlist(x)) - 3*sd (unlist(x)) x[x&lt; cutoff] &lt;- cutoff #colnames(x)= detectGroups(colnames(x)) if(is.null(bar)) # no side colors heatmap.2(x, Rowv =F,Colv=F, dendrogram =&quot;none&quot;, col=heatColors[as.integer(mycolor),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.3 ,key=F, labRow = F #,RowSideColors = mycolors[bar] ,margins = c(8, 24) ,srtCol=45 ) else heatmap.2(x, Rowv =F,Colv=F, dendrogram =&quot;none&quot;, col=heatColors[as.integer(mycolor),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.3 ,key=F, labRow = F ,RowSideColors = sideColors[bar] ,margins = c(8, 24) ,srtCol=45 ) if(!is.null(bar)) { legend.text = paste(&quot;Cluster &quot;, toupper(letters)[unique(bar)], &quot; (N=&quot;, ngenes,&quot;)&quot;, sep=&quot;&quot;) if( !is.null( clusterNames ) &amp;&amp; length(clusterNames)&gt;= length( unique(bar) ) ) legend.text = paste(clusterNames[ 1:length( unique(bar) ) ], &quot; (N=&quot;, ngenes,&quot;)&quot;, sep=&quot;&quot;) par(lend = 1) # square line ends for the color legend legend(&quot;topright&quot;, # location of the legend on the heatmap plot legend = legend.text, # category labels col = sideColors, # color key lty= 1, # line style lwd = 10 ) # line width } } KmeansHeatmap &lt;- function() { # Kmeans clustering myheatmap2(Kmeans.out$x-apply(Kmeans.out$x,1,mean), Kmeans.out$bar,1000,mycolor=input_heatColors1) } tSNEgenePlot &lt;- function() { Cluster &lt;- Kmeans.out$bar train &lt;- as.data.frame( cbind(Cluster,Kmeans.out$x) ) library(Rtsne,verbose=FALSE) train = unique(train) Cluster = train$Cluster set.seed(input_seedTSNE) ## Executing the algorithm on curated data tsne &lt;- Rtsne(train[,-1], dims = 2, perplexity=30, verbose=FALSE, max_iter = 400) nClusters = length(unique(Cluster) ) if(input_colorGenes) { plot(tsne$Y[,1], tsne$Y[,2], pch = (0:(nClusters-1))[Cluster], cex = 1.,col = mycolors[Cluster], xlab=&quot;X&quot;,ylab=&quot;Y&quot;) legend(&quot;topright&quot;,toupper(letters)[1:nClusters], pch = 0:(nClusters-1), col=mycolors, title=&quot;Cluster&quot; ) } else plot(tsne$Y[,1], tsne$Y[,2], cex = 1., xlab=&quot;X&quot;,ylab=&quot;Y&quot;) } # Main function. Find a query set of genes enriched with functional category FindOverlap &lt;- function (converted,gInfo, GO,selectOrg,minFDR, reduced = FALSE) { maxTerms =15 # max number of enriched terms idNotRecognized = as.data.frame(&quot;ID not recognized!&quot;) if(is.null(converted) ) return(idNotRecognized) # no ID # only coding gInfo &lt;- gInfo[which( gInfo$gene_biotype == &quot;protein_coding&quot;),] querySet &lt;- intersect( converted$IDs, gInfo[,1]); if(length(querySet) == 0) return(idNotRecognized ) ix = grep(converted$species[1,1],gmtFiles) totalGenes &lt;- converted$species[1,7] if (length(ix) == 0 ) {return(idNotRecognized )} # If selected species is not the default &quot;bestMatch&quot;, use that species directly if(selectOrg != speciesChoice[[1]]) { ix = grep(findSpeciesById(selectOrg)[1,1], gmtFiles ) if (length(ix) == 0 ) {return(idNotRecognized )} totalGenes &lt;- orgInfo[which(orgInfo$id == as.numeric(selectOrg)),7] } pathway &lt;- dbConnect(sqlite,gmtFiles[ix],flags=SQLITE_RO) sqlQuery = paste( &quot; select distinct gene,pathwayID from pathway where gene IN (&#39;&quot;, paste(querySet,collapse=&quot;&#39;, &#39;&quot;),&quot;&#39;)&quot; ,sep=&quot;&quot;) #cat(paste0(&quot;HH&quot;,GO,&quot;HH&quot;) ) if( GO != &quot;All&quot;) sqlQuery = paste0(sqlQuery, &quot; AND category =&#39;&quot;,GO,&quot;&#39;&quot;) result &lt;- dbGetQuery( pathway, sqlQuery ) if( dim(result)[1] ==0) {return(as.data.frame(&quot;No matching species or gene ID file!&quot; )) } # given a pathway id, it finds the overlapped genes, symbol preferred sharedGenesPrefered &lt;- function(pathwayID) { tem &lt;- result[which(result[,2]== pathwayID ),1] ix = match(tem, converted$conversionTable$ensembl_gene_id) # convert back to original tem2 &lt;- unique( converted$conversionTable$User_input[ix] ) if(length(unique(gInfo$symbol) )/dim(gInfo)[1] &gt;.7 ) # if 70% genes has symbol in geneInfo { ix = match(tem, gInfo$ensembl_gene_id); tem2 &lt;- unique( gInfo$symbol[ix] ) } return( paste( tem2 ,collapse=&quot; &quot;,sep=&quot;&quot;) )} x0 = table(result$pathwayID) x0 = as.data.frame( x0[which(x0&gt;=Min_overlap)] )# remove low overlaps if(dim(x0)[1] &lt;= 5 ) return(idNotRecognized) # no data colnames(x0)=c(&quot;pathwayID&quot;,&quot;overlap&quot;) pathwayInfo &lt;- dbGetQuery( pathway, paste( &quot; select distinct id,n,Description from pathwayInfo where id IN (&#39;&quot;, paste(x0$pathwayID,collapse=&quot;&#39;, &#39;&quot;), &quot;&#39;) &quot;,sep=&quot;&quot;) ) x = merge(x0,pathwayInfo, by.x=&#39;pathwayID&#39;, by.y=&#39;id&#39;) x$Pval=phyper(x$overlap-1,length(querySet),totalGenes - length(querySet),as.numeric(x$n), lower.tail=FALSE ); x$FDR = p.adjust(x$Pval,method=&quot;fdr&quot;) x &lt;- x[ order( x$FDR) ,] # sort according to FDR if(dim(x)[1] &gt; maxTerms ) x = x[1:maxTerms,] if(min(x$FDR) &gt; minFDR) x=as.data.frame(&quot;No significant enrichment found!&quot;) else { x &lt;- x[which(x$FDR &lt; minFDR),] x= cbind(x,sapply( x$pathwayID, sharedGenesPrefered ) ) colnames(x)[7]= &quot;Genes&quot; x &lt;- subset(x,select = c(FDR,overlap,n,description,Genes) ) colnames(x) = c(&quot;Corrected P value (FDR)&quot;, &quot;Genes in list&quot;, &quot;Total genes in category&quot;,&quot;Functional Category&quot;,&quot;Genes&quot; ) # remove redudant gene sets if(reduced != FALSE ){ # reduced=FALSE no filtering, reduced = 0.9 filter sets overlap with 90% n= nrow(x) tem=rep(TRUE,n ) geneLists = lapply(x$Genes, function(y) unlist( strsplit(as.character(y),&quot; &quot; ) ) ) for( i in 2:n) for( j in 1:(i-1) ) { if(tem[j]) { # skip if this one is already removed commonGenes = length(intersect(geneLists[i] ,geneLists[j] ) ) if( commonGenes/ length(geneLists[j] ) &gt; reduced ) tem[i] = FALSE } } x &lt;- x[which(tem),] } } dbDisconnect(pathway) return(x ) } # Given a gene set, finds significant overlaps with a gene set database object findOverlapGMT &lt;- function ( query, geneSet, minFDR=.2 ,minSize=2,maxSize=10000 ){ #geneSets &lt;- readGMT(&quot;exampleData/MousePath_TF_gmt.gmt&quot;) #query &lt;- geneSets[[&#39;TF_MM_FRIARD_C-REL&#39;]] #query &lt;- query[1:60] total_elements = 30000 Min_overlap &lt;- 1 maxTerms =10 # max number of enriched terms noSig &lt;- as.data.frame(&quot;No significant enrichment found!&quot;) query &lt;- cleanGeneSet(query) # convert to upper case, unique() if(length(query) &lt;=2) return(noSig) if(length(geneSet) &lt;1) return(noSig) geneSet &lt;- geneSet[which(sapply(geneSet,length) &gt; minSize)] # gene sets smaller than 1 is ignored!!! geneSet &lt;- geneSet[which(sapply(geneSet,length) &lt; maxSize)] # gene sets smaller than 1 is ignored!!! result &lt;- unlist( lapply(geneSet, function(x) length( intersect (query, x) ) ) ) result &lt;- cbind(unlist( lapply(geneSet, length) ), result ) result &lt;- result[ which(result[,2]&gt;Min_overlap), ,drop=F] if(dim(result)[1] == 0) return( noSig) xx &lt;- result[,2] mm &lt;- length(query) nn &lt;- total_elements - mm kk &lt;- result[,1] Pval_enrich=phyper(xx-1,mm,nn,kk, lower.tail=FALSE ); FDR &lt;- p.adjust(Pval_enrich,method=&quot;fdr&quot;,n=length(geneSet) ) result &lt;- as.data.frame(cbind(FDR,result)) result &lt;- result[,c(1,3,2)] result$pathway = rownames(result) result$Genes = &quot;&quot; # place holder just colnames(result)= c(&quot;Corrected P value (FDR)&quot;, &quot;Genes in list&quot;, &quot;Total genes in category&quot;,&quot;Functional Category&quot;,&quot;Genes&quot; ) result &lt;- result[ which( result[,1] &lt; minFDR),,drop=F] if( dim( result)[1] == 0) return(noSig) if(min(FDR) &gt; minFDR) return(noSig) result &lt;- result[order(result[,1] ),] if(dim(result)[1] &gt; maxTerms ) result &lt;- result[1:maxTerms,] return( result) } KmeansGO &lt;- function() { pp=0 minFDR = 0.01 for( i in 1:input_nClusters) { query = rownames(Kmeans.out$x)[which(Kmeans.out$bar == i)] result &lt;- findOverlapGMT( query, GeneSets.out,1) if( dim(result)[2] ==1) next; # result could be NULL result$Genes = toupper(letters)[i] if (pp==0 ) { results &lt;- result; pp &lt;- 1; } else { results &lt;- rbind(results,result) } } if(pp == 0) return( as.data.frame(&quot;No enrichment found.&quot;)) results= results[,c(5,1,2,4)] colnames(results)= c(&quot;Cluster&quot;,&quot;FDR&quot;,&quot;Genes&quot;,&quot;Pathways&quot;) if(min(results$FDR) &gt; minFDR ) results = as.data.frame(&quot;No signficant enrichment found.&quot;) else results = results[which(results$FDR &lt; minFDR),] if( is.null(results) ) return ( as.matrix(&quot;No significant enrichment.&quot;) ) if( class(results) != &quot;data.frame&quot;) return ( as.matrix(&quot;No significant enrichment.&quot;) ) if( dim(results)[2] ==1) return ( as.matrix(&quot;No significant enrichment.&quot;) ) colnames(results)[2] = &quot;adj.Pval&quot; results$Genes &lt;- as.character(results$Genes) results$Cluster[which( duplicated(results$Cluster) ) ] &lt;- &quot;&quot; results } 6.8 Differential expression ################################################################ # Differential expression ################################################################ # Differential expression using LIMMA DEG.limma &lt;- function (x, maxP_limma=.1, minFC_limma=2, rawCounts,countsDEGMethods,priorCounts, dataFormat, selectedComparisons=NULL, sampleInfo = NULL,modelFactors=NULL, blockFactor = NULL){ library(limma,verbose=FALSE) # Differential expression library(statmod,verbose=FALSE) # many different situations: 1. just use sample names 2. just one factor 3. two factors no interaction # 4. two factors with interaction 5. block factor topGenes = list(); limmaTrend = FALSE if( dataFormat == 2) { # if normalized data eset = new(&quot;ExpressionSet&quot;, exprs=as.matrix(x)) } else { # counts data if (countsDEGMethods == 1 ) { # limma-trend method selected for counts data #dge &lt;- DGEList(counts=rawCounts); #dge &lt;- calcNormFactors(dge, method = &quot;TMM&quot;) #eset &lt;- cpm(dge, log=TRUE, prior.count=priorCounts) eset = new(&quot;ExpressionSet&quot;, exprs=as.matrix(x)) # use transformed data for limma limmaTrend = TRUE } } groups = colnames(x) groups = detectGroups( groups) g = unique(groups) # check for replicates, removes samples without replicates reps = as.matrix(table(groups)) # number of replicates per biological sample if ( sum( reps[,1] &gt;= 2) &lt;2 ) # if less than 2 samples with replicates return( list(results= NULL, comparisons = NULL, Exp.type=&quot;Failed to parse sample names to define groups. Cannot perform DEGs and pathway analysis. Please double check column names! Use WT_Rep1, WT_Rep2 etc. &quot;, topGenes=NULL)) # remove samples without replicates g &lt;- rownames(reps)[which(reps[,1] &gt;1)] ix &lt;- which( groups %in% g) groups &lt;- groups[ix] x&lt;- x[,ix]; rawCounts &lt;- rawCounts[,ix] if(length(g) ==2 ) { g= unique(groups) comparisons &lt;- paste(g[2],&quot;-&quot;,g[1],sep=&quot;&quot;) # &quot;Mutant-WT&quot; # no sample file, but user selected comparisons using column names if( is.null(modelFactors) &amp; length( selectedComparisons) &gt;0 ) comparisons = selectedComparisons design &lt;- model.matrix(~0+groups) colnames(design) &lt;- g if( !is.null(rawCounts) &amp;&amp; countsDEGMethods == 2) { # voom dge &lt;- DGEList(counts=rawCounts); dge &lt;- calcNormFactors(dge, method = &quot;TMM&quot;) # normalization v &lt;- voom(dge, design); fit &lt;- lmFit(v, design) } else fit &lt;- lmFit(eset, design) # regular limma cont.matrix &lt;- makeContrasts(contrasts=comparisons, levels=design) fit2 &lt;- contrasts.fit(fit, cont.matrix) fit2 &lt;- eBayes(fit2, trend=limmaTrend) # calls differential gene expression 1 for up, -1 for down results &lt;- decideTests(fit2, p.value=maxP_limma, lfc=log2(minFC_limma) ) #vennDiagram(results,circle.col=rainbow(5)) topGenes1 =topTable(fit2, number = 1e12,sort.by=&quot;M&quot; ) if (dim(topGenes1)[1] != 0) { topGenes1 = topGenes1[,c(&#39;logFC&#39;,&#39;adj.P.Val&#39;)] # topGenes1[,1] &lt;- -1* topGenes1[,1] # reverse direction topGenes[[1]] &lt;- topGenes1 } # log fold change is actually substract of means. So if the data is natral log transformed, it shoudl be natral log. Exp.type = &quot;2 sample groups.&quot; } if(length(g) &gt; 2 ) { # more than two sample groups design &lt;- model.matrix(~ 0+factor(groups)) colnames(design) &lt;- gsub(&quot;.*)&quot;,&quot;&quot;,colnames(design)) if( !is.null(rawCounts) &amp;&amp; countsDEGMethods == 2) { # voom v &lt;- voom(rawCounts, design); fit &lt;- lmFit(v, design) } else fit &lt;- lmFit(eset, design) fit &lt;- eBayes(fit, trend=limmaTrend) comparisons = &quot;&quot; for( i in 1:(length(g)-1) ) for (j in (i+1):length(g)) comparisons = c(comparisons,paste(g[j],&quot;-&quot;,g[i],sep=&quot;&quot; ) ) comparisons &lt;- comparisons[-1] # no sample file, but user selected comparisons using column names if( is.null(modelFactors) &amp; length( selectedComparisons) &gt;0 ) comparisons = selectedComparisons contrast1 &lt;- makeContrasts(contrasts=comparisons[1], levels=design) if(length(comparisons)&gt;1 ) for( kk in 2:length(comparisons) ) contrast1&lt;- cbind(contrast1,makeContrasts(contrasts=comparisons[kk], levels=design) ) Exp.type = paste(length(g),&quot; sample groups detected.&quot;) # if factorial design 2x2, 2x3, 3x5 etc. # all samples must be something like WT_control_rep1 if ( sum(sapply(strsplit(g,&quot;_&quot;),length) == 2 ) == length(g) ) { #comparisons comparisons = &quot;&quot; for( i in 1:(length(g)-1) ) for (j in (i+1):length(g)) if( strsplit(g[i],&quot;_&quot;)[[1]][1] == strsplit(g[j],&quot;_&quot;)[[1]][1]| strsplit(g[i],&quot;_&quot;)[[1]][2] == strsplit(g[j],&quot;_&quot;)[[1]][2]) # only compare WT_control vs. WT_treatment comparisons = c(comparisons,paste(g[j],&quot;-&quot;,g[i],sep=&quot;&quot; ) ) comparisons &lt;- comparisons[-1] #factors genotype treatment levels extract_treatment &lt;- function (x) paste( gsub( &quot;.*_&quot;,&quot;&quot;,unlist( strsplit(x,&quot;-&quot;)) ), collapse=&quot;-&quot;) extract_genotype &lt;- function (x) gsub( &quot;_.*&quot;,&quot;&quot;,unlist( strsplit(x,&quot;-&quot;)) )[1] extract_treatment_counting &lt;- unique( gsub( &quot;.*_&quot;,&quot;&quot;,unlist( strsplit(g,&quot;-&quot;)) )) treatments = sapply(comparisons, extract_treatment) genotypes = sapply(comparisons, extract_genotype) Exp.type = paste( Exp.type, &quot;\\nFactorial design:&quot;,length(unique(genotypes)),&quot;X&quot;, length( extract_treatment_counting ), sep=&quot;&quot; ) # pairwise contrasts contrast1 &lt;- makeContrasts(contrasts=comparisons[1], levels=design) for( kk in 2:length(comparisons) ) contrast1&lt;- cbind(contrast1,makeContrasts(contrasts=comparisons[kk], levels=design) ) contrast.names = colnames(contrast1) # interaction contrasts for ( kk in 1:(length(comparisons)-1) ) { for( kp in (kk+1):length(comparisons)) if( treatments[kp]== treatments[kk] ) { contrast1 = cbind(contrast1, contrast1[,kp]- contrast1[,kk] ) contrast.names = c(contrast.names, paste(&quot;I:&quot;, genotypes[kp], &quot;-&quot;, genotypes[kk],&quot;(&quot;,gsub(&quot;-&quot;,&quot;.vs.&quot;,treatments[kp]),&quot;)&quot;,sep=&quot;&quot; ) ) } } colnames(contrast1)=contrast.names comparisons = contrast.names } # if interaction terms # if sample information is uploaded and user selected factors and comparisons if( !is.null(modelFactors) &amp; length( selectedComparisons) &gt;0 ) { Exp.type = paste(&quot;Model: ~&quot;, paste(modelFactors,collapse=&quot; + &quot;) ) interactionTerm = FALSE # default value to be re-write if needed # model factors that does not contain interaction terms # modelFactors &quot;genotype&quot;, &quot;condition&quot;, &quot;genotype:condition&quot; keyModelFactors = modelFactors[ !grepl(&quot;:&quot;,modelFactors) ] # &quot;genotype: control vs. mutant&quot; factorsVector= gsub(&quot;:.*&quot;,&quot;&quot;,selectedComparisons) # corresponding factors for each comparison # remove factors not used in comparison, these are batch effects/pairs/blocks, # keyModelFactors = keyModelFactors[ !is.na(match(keyModelFactors, factorsVector)) ] # if a factor is selected both in block and main factors, then use it as block factor keyModelFactors = keyModelFactors[ is.na(match(keyModelFactors, blockFactor)) ] #------Design matrix sampleInfo2 = sampleInfo[,keyModelFactors,drop=F] # remove factors not used. groups = apply(sampleInfo2,1, function(x) paste(x,collapse=&quot;_&quot;) ) g = unique(groups) design &lt;- model.matrix(~ 0+factor(groups)) colnames(design) &lt;- gsub(&quot;.*)&quot;,&quot;&quot;,colnames(design)) if( !is.null(rawCounts) &amp;&amp; countsDEGMethods == 2) { # voom v &lt;- voom(rawCounts, design); fit &lt;- lmFit(v, design) } else fit &lt;- lmFit(eset, design) fit &lt;- eBayes(fit, trend=limmaTrend) #-----------Making comaprisons if( length(keyModelFactors) != 2 | length(blockFactor) &gt;1 ) { # if only one factor, or more than two then use all pairwise comparisons comparisons = gsub(&quot;.*: &quot;,&quot;&quot;,selectedComparisons) comparisons = gsub(&quot; vs\\\\. &quot;,&quot;-&quot;,comparisons) } else if( length(keyModelFactors) == 2 ){ # two key factors if( sum(grepl(&quot;:&quot;,modelFactors) &gt;0) ) { # interaction? interactionTerm =TRUE # all pairwise comparisons comparisons = &quot;&quot; for( i in 1:(length(g)-1) ) for (j in (i+1):length(g)) if( strsplit(g[i],&quot;_&quot;)[[1]][1] == strsplit(g[j],&quot;_&quot;)[[1]][1]| strsplit(g[i],&quot;_&quot;)[[1]][2] == strsplit(g[j],&quot;_&quot;)[[1]][2]) # only compare WT_control vs. WT_treatment comparisons = c(comparisons,paste(g[j],&quot;-&quot;,g[i],sep=&quot;&quot; ) ) comparisons &lt;- comparisons[-1] # pairwise contrasts contrast1 &lt;- makeContrasts(contrasts=comparisons[1], levels=design) if(length(comparisons)&gt;1 ) for( kk in 2:length(comparisons) ) contrast1&lt;- cbind(contrast1,makeContrasts(contrasts=comparisons[kk], levels=design) ) contrast.names = colnames(contrast1) # all possible interactions # interaction contrasts contrast2 = NULL contrast.names =&quot;&quot; for ( kk in 1:(dim(contrast1)[2]-1) ) { for( kp in (kk+1):dim(contrast1)[2]) #if( treatments[kp]== treatments[kk] ) { if(is.null(contrast2)) contrast2 = contrast1[,kp]- contrast1[,kk] else contrast2 = cbind(contrast2, contrast1[,kp]- contrast1[,kk] ) contrast.names = c(contrast.names, paste0(&quot;I:&quot;, colnames(contrast1)[kp], &quot;.vs.&quot;, colnames(contrast1)[kk] ) ) } } colnames(contrast2)=contrast.names[-1] # remove nonsense contrasts from interactions contrast2 = contrast2[,which(apply(abs(contrast2),2,max)==1),drop=F] contrast2 = contrast2[,which(apply(abs(contrast2),2,sum)==4),drop=F] contrast2 = t( unique(t(contrast2)) ) # remove duplicate columns # remove unwanted contrasts involving more than three levels in either factor keep= c() for( i in 1:dim(contrast2)[2]) { tem = rownames(contrast2)[ contrast2[ ,i ] != 0 ] tem1 = unique ( unlist(gsub(&quot;_.*&quot;,&quot;&quot;, tem) ) ) tem2 = unique ( unlist(gsub(&quot;.*_&quot;,&quot;&quot;, tem) ) ) if( length(tem1) == 2 &amp; length(tem2) ==2 ) keep = c(keep, colnames(contrast2) [i] ) } contrast2 = contrast2[,keep,drop=F] comparisons2 = colnames(contrast2) } # &quot;stage: MN vs. EN&quot; --&gt; c(&quot;MN_AB-EN_AB&quot;, &quot;EN_Nodule-EN_AB&quot;) # comparisons in all levels of the other factor transformComparisons &lt;- function (comparison1){ tem = gsub(&quot;.*: &quot;,&quot;&quot;,comparison1) tem = unlist(strsplit(tem, &quot; vs\\\\. &quot;) ) # control mutant factor1= gsub(&quot;:.*&quot;,&quot;&quot;,comparison1) ix = match(factor1, keyModelFactors) # 1: first factor, 2: 2nd factor otherFactor = keyModelFactors[3-ix] # 3-1 = 2; 3-1=1 otherFactorLevels = unique( sampleInfo2[,otherFactor] ) comparisons = c( ) for (factorLevels in otherFactorLevels) { if( ix == 1){ comparisons = c( comparisons, paste(paste0( tem, &quot;_&quot;,factorLevels),collapse=&quot;-&quot;) ) } else { comparisons = c( comparisons, paste(paste0(factorLevels, &quot;_&quot;, tem),collapse=&quot;-&quot;) ) } } return(comparisons) } comparisons = unlist( sapply(selectedComparisons, transformComparisons )) comparisons = as.vector(comparisons) } # two factors # make contrasts contrast1 &lt;- makeContrasts(contrasts=comparisons[1], levels=design) if(length(comparisons) &gt;1 ) for( kk in 2:length(comparisons) ) contrast1&lt;- cbind(contrast1,makeContrasts(contrasts=comparisons[kk], levels=design) ) if( interactionTerm ) { # if interaction terms contrast1 = cbind(contrast1,contrast2) contrast.names = c(colnames(contrast1), colnames(contrast2) ) comparisons = c(comparisons,comparisons2) } # block design to remove batch effect or paired samples # corfit &lt;- duplicateCorrelation(eset,design,block=targets$Subject) # corfit$consensus #Then this inter-subject correlation is input into the linear model fit: # fit &lt;- lmFit(eset,design,block=targets$Subject,correlation=corfit$consensus) if(length(blockFactor) &gt;= 1 ) { # if a factor is selected as block if(length(blockFactor) &gt;= 1 ) blockFactor = blockFactor[1] # if multiple use the first one block = sampleInfo[, blockFactor] # the column not used if( !is.null(rawCounts) &amp;&amp; countsDEGMethods == 2) { # voom v &lt;- voom(rawCounts, design); corfit &lt;- duplicateCorrelation(v,design,block= block) fit &lt;- lmFit(v, design,block=block,correlation=corfit$consensus) } else { corfit &lt;- duplicateCorrelation(eset,design,block= block) fit &lt;- lmFit(eset, design,block=block,correlation=corfit$consensus) } fit &lt;- eBayes(fit, trend=limmaTrend) } # block factors } # use selected factors fit2 &lt;- contrasts.fit(fit, contrast1) fit2 &lt;- eBayes(fit2, trend=limmaTrend) #topTable(fit2, coef=1, adjust=&quot;BH&quot;) results &lt;- decideTests(fit2, p.value=maxP_limma, lfc= log2(minFC_limma )) #vennDiagram(results[,1:5],circle.col=rainbow(5)) #colnames(results) = unlist(sapply( colnames(results), changeNames ) ) #comparisons3 &lt;- unlist(sapply( comparisons, changeNames ) ) # extract fold change for each comparison # there is issues with direction of foldchange. Sometimes opposite top &lt;- function (comp) { tem &lt;- topTable(fit2, number = 1e12,coef=comp,sort.by=&quot;M&quot; ) if(dim(tem)[1] == 0) { return (1) } else { # compute fold change for the first gene (ranked by absolute value) tem2 = as.numeric( x[ which(rownames(x)== rownames(tem)[1]) , ] ) names(tem2) = colnames(x) return( tem[,c(1,5)]) } } # no significant gene returns 1, otherwise a data frame topGenes &lt;- lapply(comparisons, top) topGenes &lt;- setNames(topGenes, comparisons ) ix &lt;- which( unlist( lapply(topGenes, class) ) == &quot;numeric&quot;) if( length(ix)&gt;0) topGenes &lt;- topGenes[ - ix ] # if (length(topGenes) == 0) topGenes = NULL; } #cat(&quot;\\n&quot;, names(topGenes) ) #cat(&quot;\\n&quot;, colnames(results)) #cat(&quot;\\n&quot;, comparisons3) #comparisons &lt;- comparisons3 # it does not make any sense! comparisons can not be changed! #comparisons =comparisons3 #cat(&quot;\\n&quot;, comparisons) return( list(results= results, comparisons=comparisons, Exp.type=Exp.type, topGenes=topGenes)) } # Differential expression using DESeq2 DEG.DESeq2 &lt;- function ( rawCounts,maxP_limma=.05, minFC_limma=2, selectedComparisons=NULL, sampleInfo = NULL,modelFactors=NULL, blockFactor = NULL, referenceLevels=NULL){ library(DESeq2,verbose=FALSE) # count data analysis groups = as.character ( detectGroups( colnames( rawCounts ) ) ) g = unique(groups)# order is reversed # check for replicates, removes samples without replicates reps = as.matrix(table(groups)) # number of replicates per biological sample if ( sum( reps[,1] &gt;= 2) &lt;2 ) # if less than 2 samples with replicates return( list(results= NULL, comparisons = NULL, Exp.type=&quot;Failed to parse sample names to define groups. Cannot perform DEGs and pathway analysis. Please double check column names! Use WT_Rep1, WT_Rep2 etc. &quot;, topGenes=NULL)) # remove samples without replicates g &lt;- rownames(reps)[which(reps[,1] &gt;1)] ix &lt;- which( groups %in% g) groups &lt;- groups[ix] rawCounts &lt;- rawCounts[,ix] Exp.type = paste(length(g),&quot; sample groups detected.&quot;) comparisons = &quot;&quot; for( i in 1:(length(g)-1) ) for (j in (i+1):length(g)) comparisons = c(comparisons,paste(g[j],&quot;-&quot;,g[i],sep=&quot;&quot; ) ) comparisons &lt;- comparisons[-1] colData = cbind(colnames(rawCounts), groups ) # no sample file, but user selected comparisons using column names if( is.null(modelFactors) &amp; length( selectedComparisons) &gt;0 ) comparisons = selectedComparisons comparisons2 = comparisons # this is for showing comparison names, which might be different from internally # Set up the DESeqDataSet Object and run the DESeq pipeline dds = DESeqDataSetFromMatrix(countData=rawCounts, colData=colData, design=~groups) if( is.null(modelFactors) ) dds = DESeq(dds) else { # using selected factors and comparisons # build model modelFactors = c(modelFactors,blockFactor) # block factor is just added in. factors = modelFactors # selected factors and interactions: c( &quot;strain&quot;, &quot;treatment&quot;, &quot;strain:treatment&quot;) factors = factors[ !grepl(&quot;:&quot;,factors )] # non-interaction terms # interaction terms like strain:treatment Interactions = modelFactors[ grepl(&quot;:&quot;,modelFactors )] colData = sampleInfo factorsCoded = toupper(letters )[1: dim(colData)[2] ] # Factors are encoded as &quot;A&quot;, &quot;B&quot;, &quot;C&quot;; this avoid illigal letters names(factorsCoded) = colnames(colData) # this is for look up; each column of sampleInfo colnames(colData) = factorsCoded # all columns named A B C D colData = as.data.frame(colData) # set reference levels for factors if(! is.null( referenceLevels) ) { # c(&quot;genotype:wt&quot;, &quot;treatment:control&quot; ) # first factor for ( refs in referenceLevels) if(! is.null( refs) ) { ix = match(gsub(&quot;:.*&quot;,&quot;&quot;,refs), colnames(sampleInfo) ) # corresponding column id for factor colData[,ix] = as.factor( colData[,ix] ) colData[,ix] = relevel(colData[,ix],gsub(&quot;.*:&quot;,&quot;&quot;,refs) ) } } # base model DESeq2.Object= paste(&quot;dds = DESeqDataSetFromMatrix(countData=rawCounts, colData=colData, design=~ &quot;, paste( factorsCoded[factors],collapse=&quot;+&quot;)) # only use selected factors Exp.type = paste(&quot;Model: ~&quot;, paste(modelFactors,collapse=&quot; + &quot;) ) # create model if( length(Interactions)&gt;0 ) { # if there is interaction for( interactionTerms in Interactions) { interactingFactors = unlist(strsplit(interactionTerms,&quot;:&quot; ) ) # split strain:treatment as &quot;strain&quot; and &quot;mutant&quot; tem = paste(factorsCoded [ interactingFactors ],collapse=&quot;:&quot;) # convert &quot;strain:mutant&quot; to &quot;A:B&quot; DESeq2.Object = paste(DESeq2.Object, &quot; + &quot;,tem) } } DESeq2.Object= paste( DESeq2.Object, &quot;)&quot;) # ends the model eval(parse(text = DESeq2.Object) ) dds = DESeq(dds) # main function # comparisons # &quot;group: control vs. mutant&quot; comparisons = gsub(&quot;.*: &quot;,&quot;&quot;,selectedComparisons) comparisons = gsub(&quot; vs\\\\. &quot;,&quot;-&quot;,comparisons) factorsVector= gsub(&quot;:.*&quot;,&quot;&quot;,selectedComparisons) # corresponding factors for each comparison # comparison2 holds names for display with real factor names # comparison is used in calculation it is A, B, C for factors comparisons2 = comparisons #comparisons2 = gsub(&quot; vs\\\\. &quot;,&quot;-&quot;,selectedComparisons) #comparisons2 = gsub(&quot;:&quot;,&quot;_&quot;,comparisons2) # Note that with interaction terms, not all meaningful comparisons is listed for selection. # this is complex. Only under reference level. # comparisons due to interaction terms if( length(Interactions)&gt;0 ) { # if there is interaction interactionComparisons = resultsNames(dds) interactionComparisons = interactionComparisons[ grepl(&quot;\\\\.&quot;,interactionComparisons ) ] comparisons = c(comparisons,interactionComparisons ) # translate comparisons generated in interaction terms back to real factor names interactionComparisons2 = interactionComparisons for ( i in 1:length(interactionComparisons2 ) ) { tem = unlist(strsplit(interactionComparisons2[i],&quot;\\\\.&quot; ) ) tem_factors = substr(tem,1,1) tem_factors[1] = names(factorsCoded)[factorsCoded == tem_factors[1]] # get the first letter and translate into real factor names tem_factors[2] = names(factorsCoded)[factorsCoded == tem_factors[2]] # get the 2nd letters and translate into real factor names interactionComparisons2[i] &lt;- paste0( &quot;I:&quot;,tem_factors[1], &quot;_&quot;,substr(tem[1],2,nchar(tem[1]) ),&quot;.&quot;, tem_factors[2], &quot;_&quot;,substr(tem[2],2,nchar(tem[2]) ) ) } comparisons2 = c(comparisons2,interactionComparisons2 ) } } # if selected factors # extract contrasts according to comprisons defined above result1 = NULL; allCalls = NULL; topGenes = list(); pk = 1 # counter pp=0 # first results? for( kk in 1:length(comparisons) ) { tem = unlist( strsplit(comparisons[kk],&quot;-&quot;) ) if(is.null(modelFactors)) # if just group comparison using sample names selected = results(dds, contrast=c(&quot;groups&quot;, tem[1], tem[2]) ) else { if(!grepl(&quot;\\\\.&quot;, comparisons[kk] ) ) # if not interaction term: they contain . interaction term selected = results(dds, contrast=c( factorsCoded[ factorsVector[kk] ],tem[1], tem[2]) ) else # either A, B, C ... selected = results(dds, name=comparisons[kk] ) # interaction term } selected$calls =0 selected$calls [which( selected$log2FoldChange &gt; log2(minFC_limma) &amp; selected$padj &lt; maxP_limma ) ] &lt;- 1 selected$calls [ which( selected$log2FoldChange &lt; -log2(minFC_limma) &amp; selected$padj &lt; maxP_limma ) ] &lt;- -1 colnames(selected)= paste( as.character(comparisons2[kk]), &quot;___&quot;,colnames(selected),sep=&quot;&quot; ) selected = as.data.frame(selected) if (pp==0){ # if first one with significant genes, collect gene list and Pval+ fold result1 = selected; pp = 1; # selected[,2] &lt;- -1 * selected[,2] # reverse fold change direction topGenes[[1]] = selected[,c(2,6)]; names(topGenes)[1] = comparisons2[kk]; } else { result1 = merge(result1,selected,by=&quot;row.names&quot;); rownames(result1) = result1[,1]; result1 &lt;- result1[,-1] pk= pk+1; # selected[,2] &lt;- -1 * selected[,2] # reverse fold change direction topGenes[[pk]] = selected[,c(2,6)]; names(topGenes)[pk] = comparisons2[kk]; # assign name to comprison } } Interactions = c() if( !is.null(modelFactors) ) Interactions = modelFactors[ grepl(&quot;:&quot;,modelFactors )] #--- add comprisons for non-reference levels. It adds to the results1 object. if( length(Interactions)&gt;0 ) { # if there is interaction factorLookup=c() # a factor whose values are factors and names are factor and level combination conditionTreated, genotypeWT levelLookup = c() for( i in 1:dim(sampleInfo)[2]) { sampleInfo2 = unique(sampleInfo) tem = rep(toupper(letters)[i],dim(sampleInfo2)[1] ) names(tem) = paste0(toupper(letters)[i],sampleInfo2[,i]) factorLookup = c(factorLookup,tem) tem = as.character( sampleInfo2[,i] ) names(tem) = paste0(toupper(letters)[i],sampleInfo2[,i]) levelLookup = c(levelLookup, tem) } # split genotypeI.conditionTrt --&gt; c(&quot;genotype&quot;,&quot;I&quot;,&quot;conditoin&quot;,&quot;Trt&quot;) splitInteractionTerms &lt;- function (term) { if(!grepl(&quot;\\\\.&quot;,term) ) return(NULL) terms2 = unlist(strsplit(term,&quot;\\\\.&quot;) ) # factor1, level1, factor2, level2 return(c(factorLookup[terms2[1]], levelLookup[terms2[1]],factorLookup[terms2[2]], levelLookup[terms2[2]] ) ) } # none interaction terms NoneInterTerms = resultsNames(dds)[ !grepl( &quot;\\\\.&quot;, resultsNames(dds)) ] NoneInterTerms=NoneInterTerms[-1] allInteractionTerms = resultsNames(dds)[ grepl( &quot;\\\\.&quot;, resultsNames(dds)) ] for( kk in 1:length(NoneInterTerms) ) { # for each none interaction term if(!is.null(modelFactors) ) {# if not just group comparison using sample names #current factor cFactor = gsub(&quot;_.*&quot;,&quot;&quot;,NoneInterTerms[kk] ) for(interactionTerm in allInteractionTerms ) { splited = splitInteractionTerms (interactionTerm) # 4 components if (cFactor != splited[1] &amp; cFactor != splited[3] ) next; selected = results(dds, list(c( NoneInterTerms[kk],interactionTerm ) ) ) comparisonName = paste0( NoneInterTerms[kk],&quot;__&quot;, gsub(&quot;\\\\.&quot;,&quot;&quot;,interactionTerm) ) if( cFactor == splited[1] ) otherLevel = splited[4] else otherLevel = splited[2] comparisonName = paste0(#names(factorsCoded)[which(factorsCoded==cFactor)], # real factor name gsub(&quot;_vs_&quot;,&quot;-&quot;, substr(NoneInterTerms[kk], 3, nchar(NoneInterTerms[kk] ) )), # the comparison &quot;_for_&quot;,otherLevel) comparisons2 = c(comparisons2, comparisonName) selected$calls =0 selected$calls [which( selected$log2FoldChange &gt; log2(minFC_limma) &amp; selected$padj &lt; maxP_limma ) ] &lt;- 1 selected$calls [ which( selected$log2FoldChange &lt; -log2(minFC_limma) &amp; selected$padj &lt; maxP_limma ) ] &lt;- -1 colnames(selected)= paste( comparisonName, &quot;___&quot;,colnames(selected),sep=&quot;&quot; ) selected = as.data.frame(selected) if (pp==0){ # if first one with significant genes, collect gene list and Pval+ fold result1 = selected; pp = 1; # selected[,2] &lt;- -1 * selected[,2] # reverse fold change direction topGenes[[1]] = selected[,c(2,6)]; names(topGenes)[1] = comparisonName; } else { result1 = merge(result1,selected,by=&quot;row.names&quot;); rownames(result1) = result1[,1]; result1 &lt;- result1[,-1] pk= pk+1; # selected[,2] &lt;- -1 * selected[,2] # reverse fold change direction topGenes[[pk]] = selected[,c(2,6)]; names(topGenes)[pk] = comparisonName; # assign name to comprison } } #for } #if } #for } #if #--- #if( length(comparisons) == 1) topGenes &lt;- topGenes[[1]] # if only one comparison, topGenes is not a list, just a data frame itself. if(! is.null(result1)) { # note that when you only select 1 column from a data frame it automatically converts to a vector. drop =FALSE prevents that. allCalls = as.matrix( result1[,grep(&quot;calls&quot;,colnames(result1)), drop = FALSE ] ) colnames(allCalls)= gsub(&quot;___.*&quot;,&quot;&quot;, colnames(allCalls)) colnames(allCalls)= gsub(&quot;\\\\.&quot;,&quot;-&quot;, colnames(allCalls)) # note that samples names should have no &quot;.&quot; colnames(allCalls)= gsub(&quot;^I-&quot;,&quot;I:&quot;, colnames(allCalls)) } return( list(results= allCalls, comparisons = comparisons2, Exp.type=Exp.type, topGenes=topGenes)) } # main function limma &lt;- function() { if(input_dataFileFormat == 1 ) { # if count data if(input_CountsDEGMethod == 3 ) { # if DESeq2 method # rawCounts = read.csv(&quot;exampleData/airway_GSE52778.csv&quot;, row.names=1) # res =DEG.DESeq2(rawCounts, .05, 2) # res1 =DEG.limma(rawCounts, .1, 1.5,rawCounts, 2,3) return( DEG.DESeq2( convertedCounts.out,input_limmaPval, input_limmaFC, input_selectModelComprions, readSampleInfo.out, c(input_selectFactorsModel,input_selectInteractions), input_selectBlockFactorsModel, factorReferenceLevels.out ) ) } if(input_CountsDEGMethod &lt; 3 ) # voom or limma-trend return( DEG.limma(convertedData.out, input_limmaPval, input_limmaFC, convertedCounts.out, input_CountsDEGMethod, priorCounts=input_countsLogStart,input_dataFileFormat, input_selectModelComprions, readSampleInfo.out, c(input_selectFactorsModel,input_selectInteractions), input_selectBlockFactorsModel) ) } else if (input_dataFileFormat == 2 ){ # normalized data return( DEG.limma(convertedData.out, input_limmaPval, input_limmaFC, convertedCounts.out, input_CountsDEGMethod, priorCounts=input_countsLogStart,input_dataFileFormat, input_selectModelComprions, readSampleInfo.out, c(input_selectFactorsModel,input_selectInteractions), input_selectBlockFactorsModel) ) } else { # dataFileFormat == 3 user just uploaded fold change matrix x = convertedData.out pvals = convertedPvals.out if(!is.null(pvals) ) { ix = match(rownames(x), rownames(pvals)) pvals = pvals[ix,] } # looks like ratio data, take log2 if( sum(round(apply(x,2, median) + .2) == 1 ) == dim(x)[2] &amp; min(x) &gt; 0) x = log2(x) Exp.type = &quot;None standard data without replicates.&quot; all.Calls = x # fake calls for( i in 1: dim(all.Calls)[2]) { tem &lt;- all.Calls[,i] all.Calls[which( tem &lt;= log2(input_limmaFC) &amp; tem &gt;= -log2(input_limmaFC) ) ,i] = 0 all.Calls[which( tem &gt; log2(input_limmaFC) ) ,i] = 1 all.Calls[which( tem &lt; -log2(input_limmaFC) ) ,i] = -1 if(!is.null(pvals) ) all.Calls[ which( pvals[,i] &gt; input_limmaPval),i] = 0 } comparisons = colnames(all.Calls) extractColumn &lt;- function (i) { topGenes = as.data.frame( convertedData.out[,i,drop=FALSE]) if(is.null(pvals) ) topGenes$FDR = 0 else topGenes$FDR = pvals[,i]# fake fdr colnames(topGenes) = c(&quot;Fold&quot;,&quot;FDR&quot;) return(topGenes) } topGenes = lapply( 1:dim( x )[2], extractColumn ) topGenes &lt;- setNames(topGenes, colnames(x ) ) return( list(results= all.Calls, comparisons = colnames(x ), Exp.type=Exp.type, topGenes=topGenes) ) } } DEG.data &lt;- function() { genes = limma.out$results genes = as.data.frame( genes[which( rowSums( abs (genes) ) != 0 ),] ) colnames(genes) = colnames( limma.out$results ) genes = merge(genes,convertedData.out, by=&#39;row.names&#39;) colnames(genes)[1] = &quot;1: upregulation, -1: downregulation&quot; # add gene symbol ix = match( genes[,1], allGeneInfo.out[,1]) genes &lt;- cbind(as.character( allGeneInfo.out$symbol)[ix],genes) colnames(genes)[1] = &quot;Symbol&quot; genes &lt;- genes[,c(2,1,3:dim(genes)[2]) ] return(genes) } vennPlot &lt;- function() { results = limma.out$results # split by up or down regulation if(input_UpDownRegulated) { resultUp = results; resultUp[resultUp &lt; 0 ] &lt;- 0; colnames(resultUp) = paste0(&quot;Up_&quot;, colnames(resultUp)) resultDown = results; resultDown[resultDown &gt; 0] &lt;- 0; colnames(resultDown) = paste0(&quot;Down_&quot;, colnames(resultDown)) results &lt;- cbind(resultUp, resultDown) } ixa = c() for (comps in input_selectComparisonsVenn) { if(!grepl(&quot;^I:|^I-|^Up_I:|^Up_I-|^Down_I:|^Down_I-&quot;, comps) ) { # if not interaction term ix = match(comps, colnames(results)) } else { #mismatch in comparison names for interaction terms for DESeq2 #I:water_Wet.genetic_Hy in the selected Contrast #Diff-water_Wet-genetic_Hy in column names tem = gsub(&quot;^I-&quot;,&quot;I:&quot; ,colnames(results)) tem = gsub(&quot;-&quot;,&quot;\\\\.&quot;,tem) ix = match(comps, tem) if(is.na(ix) ) # this is for limma package ix = match(comps, colnames(results)) } ixa = c(ixa,ix) } results = results[,ixa,drop=FALSE] # only use selected comparisons if(dim(results)[2] &gt;5) results &lt;- results[,1:5] colnames(results) = gsub(&quot;^I-&quot;,&quot;I:&quot; ,colnames(results)) vennDiagram(results,circle.col=rainbow(5), cex=c(1.,1, 0.7) ) # part of limma package } sigGeneStats &lt;- function( ){ results = limma.out$results library(reshape2) Up = apply(results, 2, function(x) sum(x == 1) ) Down = apply(results, 2, function(x) sum(x == -1) ) stats = rbind(Up, Down) gg &lt;- melt(stats) colnames(gg) = c(&quot;Regulation&quot;,&quot;Comparisons&quot;,&quot;Genes&quot;) p= ggplot(gg, aes(x=Comparisons, y=Genes, fill= Regulation ) )+ geom_bar(position=&quot;dodge&quot;, stat=&quot;identity&quot;) + coord_flip() + theme(legend.position = &quot;top&quot;) + scale_fill_manual(values=c(&quot;red&quot;, &quot;blue&quot;)) + ylab(&quot;Number of differntially expressed genes&quot;) + theme(axis.title.y=element_blank(), axis.text=element_text(size=14)) p } sigGeneStatsTable &lt;- function( ) { results = limma.out$results Up = apply(results, 2, function(x) sum(x == 1) ) Down = apply(results, 2, function(x) sum(x == -1) ) stats = rbind(Up, Down) stats = t(stats) stats=cbind(rownames(stats), stats) colnames(stats)[1]=&quot;Comparisons&quot; return(as.data.frame(stats)) } selectedHeatmap.data &lt;- function() { genes &lt;- limma.out$results if( is.null(genes) ) return(NULL) if(!grepl(&quot;I:&quot;, input_selectContrast) ) { # if not interaction term ix = match(input_selectContrast, colnames(genes)) } else { #mismatch in comparison names for interaction terms for DESeq2 #I:water_Wet.genetic_Hy in the selected Contrast #Diff-water_Wet-genetic_Hy in column names tem = gsub(&quot;I-&quot;,&quot;I:&quot; ,colnames(genes)) tem = gsub(&quot;-&quot;,&quot;\\\\.&quot;,tem) ix = match(input_selectContrast, tem) if(is.na(ix) ) # this is for limma package ix = match(input_selectContrast, colnames(genes)) } if(is.null(ix)) return(NULL) if(is.na(ix)) return(NULL) if( sum(abs(genes[,ix] ) ) &lt;= 1 ) return(NULL) # no significant genes for this comparison if(dim(genes)[2] &lt; ix ) return(NULL) query = rownames(genes)[which(genes[,ix] != 0)] if(length(query) == 0) return(NULL) iy = match(query, rownames(convertedData.out ) ) iz = findContrastSamples( input_selectContrast, colnames(convertedData.out), readSampleInfo.out, input_selectFactorsModel, input_selectModelComprions, factorReferenceLevels.out, input_CountsDEGMethod, input_dataFileFormat ) # color bar bar = genes[,ix] bar = bar[bar!=0] # retreive related data genes = convertedData.out[iy,iz,drop=FALSE] genes = genes[order(bar),,drop=FALSE] # needs to be sorted because myheatmap2 does not reorder genes bar = sort(bar) return(list(genes=genes, bar=bar )) } # find sample index for selected comparisons findContrastSamples &lt;- function(selectContrast, allSampleNames,sampleInfo=NULL, selectFactorsModel=NULL,selectModelComprions =NULL , referenceLevels=NULL, countsDEGMethod=NULL, dataFileFormat=NULL ){ iz= match( detectGroups(allSampleNames), unlist(strsplit( selectContrast, &quot;-&quot;)) ) iz = which(!is.na(iz)) if ( !is.null(sampleInfo) &amp; !is.null(selectFactorsModel) &amp; length(selectModelComprions)&gt;0 ) { comparisons = gsub(&quot;.*: &quot;,&quot;&quot;,selectModelComprions) # strings like: &quot;groups: mutant vs. control&quot; comparisons = gsub(&quot; vs\\\\. &quot;,&quot;-&quot;,comparisons) factorsVector= gsub(&quot;:.*&quot;,&quot;&quot;,selectModelComprions) # corresponding factors # if read counts data and DESeq2 if(dataFileFormat==1 &amp; countsDEGMethod == 3) { # if DESeq2 contrast = gsub(&quot;_for_.*&quot;,&quot;&quot;,selectContrast) # could be &quot;wt-mu&quot; or &quot;wt-mu_for_conditionB&quot; ik = match( contrast, comparisons ) # selected contrast lookes like: &quot;mutant-control&quot; otherFactorLevel = gsub(&quot;.*_for_&quot;,&quot;&quot;,selectContrast) # find the corresponding factor for the other factor otherFactor=&quot; &quot; if(nchar( otherFactorLevel ) &gt;0){ for( eachFactor in colnames(sampleInfo) ) if ( otherFactorLevel %in% sampleInfo[,eachFactor ] ) otherFactor = eachFactor } if (is.na(ik)) iz=1:(length(allSampleNames)) else { # interaction term, use all samples selectedfactor= factorsVector[ ik ] # corresponding factors iz = which(sampleInfo[,selectedfactor] %in% unlist(strsplit( contrast, &quot;-&quot;)) ) #filter by other factors: reference level if(! is.null( referenceLevels) ) { # c(&quot;genotype:wt&quot;, &quot;treatment:control&quot; ) for ( refs in referenceLevels) if(! is.null( refs) &amp; gsub(&quot;:.*&quot;,&quot;&quot;,refs) != selectedfactor ) { currentFactor = gsub(&quot;:.*&quot;,&quot;&quot;,refs) if(nchar( otherFactorLevel ) &gt;0 &amp; currentFactor == otherFactor ) { # if not reference level iz = intersect( iz, which(sampleInfo[,currentFactor] == otherFactorLevel ) ) } else iz = intersect( iz, which(sampleInfo[,currentFactor] == gsub(&quot;.*:&quot;,&quot;&quot;,refs) ) ) } } iz = iz[which(!is.na(iz))] # switching from limma to DESeq2 causes problem, as reference level is not defined. } } else { # not DESeq2 # given level find corresponding sample ids findIDsFromLevel &lt;- function (aLevel){ # find factor currentFactor=&quot;&quot; for( eachFactor in colnames(sampleInfo) ) if ( aLevel %in% sampleInfo[,eachFactor ] ) currentFactor = eachFactor if(nchar(currentFactor) &gt;0 ) return( which(sampleInfo[,currentFactor ] %in% aLevel ) ) else return(NULL) } if( !grepl(&quot;.*_.*-.*_.*&quot;,selectContrast )) iz = c.out levels4 = unlist( strsplit( unlist( strsplit(selectContrast,&quot;-&quot;) ), &quot;_&quot;) ) #double split! if(length(levels4)!=4) { iz = c.out } else { iz = intersect( findIDsFromLevel(levels4[1]), findIDsFromLevel(levels4[2]) ) # first sample iz = c(iz, intersect( findIDsFromLevel(levels4[3]), findIDsFromLevel(levels4[4]) ) ) # 2nd sample } } #else } if (grepl(&quot;I:&quot;,selectContrast)) iz=1:length(allSampleNames) # if it is factor design use all samples if( is.na(iz)[1] | length(iz)&lt;=1 ) iz=1:length(allSampleNames) return(iz) } selectedHeatmap &lt;- function() { bar = selectedHeatmap.data.out$bar +2; bar[bar==3] =2 myheatmap2( selectedHeatmap.data.out$genes,bar,200,mycolor=input_heatColors1,c(&quot;Down&quot;,&quot;Up&quot;) ) } selectedHeatmap.data &lt;- function(){ genes &lt;- limma.out$results if( is.null(genes) ) return(NULL) if(!grepl(&quot;I:&quot;, input_selectContrast) ) { # if not interaction term ix = match(input_selectContrast, colnames(genes)) } else { #mismatch in comparison names for interaction terms for DESeq2 #I:water_Wet.genetic_Hy in the selected Contrast #Diff-water_Wet-genetic_Hy in column names tem = gsub(&quot;I-&quot;,&quot;I:&quot; ,colnames(genes)) tem = gsub(&quot;-&quot;,&quot;\\\\.&quot;,tem) ix = match(input_selectContrast, tem) if(is.na(ix) ) # this is for limma package ix = match(input_selectContrast, colnames(genes)) } if(is.null(ix)) return(NULL) if(is.na(ix)) return(NULL) if( sum(abs(genes[,ix] ) ) &lt;= 1 ) return(NULL) # no significant genes for this comparison if(dim(genes)[2] &lt; ix ) return(NULL) query = rownames(genes)[which(genes[,ix] != 0)] if(length(query) == 0) return(NULL) iy = match(query, rownames(convertedData.out ) ) iz = findContrastSamples( input_selectContrast, colnames(convertedData.out), readSampleInfo.out, input_selectFactorsModel, input_selectModelComprions, factorReferenceLevels.out, input_CountsDEGMethod, input_dataFileFormat ) # color bar bar = genes[,ix] bar = bar[bar!=0] # retreive related data genes = convertedData()[iy,iz,drop=FALSE] genes = genes[order(bar),,drop=FALSE] # needs to be sorted because myheatmap2 does not reorder genes bar = sort(bar) return(list(genes=genes, bar=bar )) } DEG.data &lt;- function(){ genes = limma.out$results genes = as.data.frame( genes[which( rowSums(genes) != 0 ),] ) colnames(genes) = colnames( limma.out$results ) genes = merge(genes,convertedData.out, by=&#39;row.names&#39;) colnames(genes)[1] = &quot;1: upregulation, -1: downregulation&quot; # add gene symbol ix = match( genes[,1], allGeneInfo.out[,1]) genes &lt;- cbind(as.character( allGeneInfo.out$symbol)[ix],genes) colnames(genes)[1] = &quot;Symbol&quot; genes &lt;- genes[,c(2,1,3:dim(genes)[2]) ] return(genes) } AllGeneListsGMT &lt;- function() { results = limma.out$results results2 = cbind(results, results) colnames(results2)= c( paste0(&quot;UP_&quot;, colnames(results)),paste0(&quot;Down_&quot;, colnames(results)) ) for(i in 1:dim(results)[2] ) { results2[,i*2-1] = results[,i] results2[ which(results2[,i*2-1] &lt; 0 ) , i*2-1] = 0 results2[,i*2] = results[,i] results2[ which(results2[,i*2] &gt; 0 ) , i*2] = 0 } geneList1 &lt;- function (i) { ix = which(results2[,i] !=0 ) return(paste0(colnames(results2)[i],&quot;\\t&quot;, length(ix),&quot;\\t&quot;, paste(rownames(results2 )[ix], collapse=&quot;\\t&quot; ) ) ) } tem = sapply(1:dim(results2)[2],geneList1 ) return( paste(tem, collapse=&quot;\\n&quot;) ) } geneListData &lt;- function( ) { noSig = as.data.frame(&quot;No significant genes find!&quot;) if( is.null(input_selectContrast) ) return(NULL) if( is.null( limma.out$comparisons ) ) return(NULL) # if no significant genes found if( length(limma.out$topGenes) == 0 ) return(noSig) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast, names(top)) if( is.na(ix)) return (noSig) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (noSig) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) #top1 = merge(top1,convertedData(), by=&#39;row.names&#39;) #colnames(top1)[1] = &quot;Genes&quot; top1 = top1[order(-abs(top1$Fold)) ,] if ( length( which( top1$FDR &lt;= input_limmaPval &amp; abs(top1$Fold) &gt;= log2(input_limmaFC) ) ) == 0 ) return( noSig) top1 &lt;- top1[which(top1$FDR &lt;= input_limmaPval ) ,] top1 &lt;- top1[which(abs(top1$Fold) &gt;= log2( input_limmaFC)) ,] top1$Top_Genes &lt;- rownames(top1) top1 &lt;- top1[,c(3,1,2)] # if new species if( input_selectGO2 == &quot;ID not recognized!&quot; | input_selectOrg == &quot;NEW&quot;) return (top1); #convertedID = convertID(top1[,1],input_selectOrg, &quot;GOBP&quot; );#&quot;gmax_eg_gene&quot; # tem &lt;- geneInfo(convertedID,input_selectOrg) #input_selectOrg ) ; # tem &lt;- geneInfo(converted(),input_selectOrg) top1 &lt;- merge(top1, allGeneInfo.out, by.x =&quot;Top_Genes&quot;, by.y=&quot;ensembl_gene_id&quot;,all.x=T ) if ( sum( is.na(top1$band)) == dim(top1)[1] ) top1$chr = top1$chromosome_name else top1$chr = paste( top1$chromosome_name, top1$band,sep=&quot;&quot;) top1 &lt;- top1[,c(&#39;Top_Genes&#39;,&#39;Fold&#39;,&#39;FDR&#39;,&#39;symbol&#39;,&#39;chr&#39;,&#39;gene_biotype&#39;)] # ix = match(top1[,1], tem$ensembl_gene_id) # if( sum(is.na( tem$Symbol[ix]) ) != length(ix) ) # { top1 &lt;- cbind(top1, tem$Symbol[ix]); colnames(top1)[4]= &quot;Symbol&quot; } top1 = top1[order(-abs(as.numeric( top1$Fold))) ,] top1$FDR &lt;- sprintf(&quot;%-3.2e&quot;,top1$FDR ) colnames(top1) &lt;- c(&quot;Ensembl ID&quot;, &quot;log2 Fold Change&quot;, &quot;Adj.Pval&quot;, &quot;Symbol&quot;,&quot;Chr&quot;,&quot;Type&quot;) if ( sum( is.na(top1$Symbol)) == dim(top1)[1] ) top1 &lt;- top1[,-4] return(top1) } volcanoPlot &lt;- function( ) { if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast, names(top)) if( is.na(ix)) return (NULL) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (NULL) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) top1 &lt;- as.data.frame(top1) # convert to data frame top1 &lt;- top1[which(!(is.na(top1$Fold)|is.na(top1$FDR) )),] # remove NA&#39;s top1$upOrDown &lt;- 1 #write.csv(top1,&quot;tem.csv&quot;) top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval&amp; top1$Fold &gt;= log2( input_limmaFC)) ] &lt;- 2 top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval &amp; top1$Fold &lt;= -log2( input_limmaFC)) ] &lt;- 3 par(mar=c(5,5,1,1)) plot(top1$Fold,-log10(top1$FDR),col = c(&quot;grey30&quot;, &quot;red&quot;,&quot;blue&quot;)[top1$upOrDown], pch =16, cex = .3, xlab= &quot;log2 fold change&quot;, ylab = &quot;- log10 (FDR)&quot;, cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2 ) legend(&quot;bottomright&quot;,c(&quot;Upregulated&quot;,&quot;Downregulated&quot;),fill = c(&quot;red&quot;,&quot;blue&quot;),cex=1.1 ) } scatterPlot &lt;- function( ){ if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast, names(top)) if( is.na(ix)) return (NULL) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (NULL) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) top1 &lt;- as.data.frame(top1) # convert to data frame top1 &lt;- top1[which(!(is.na(top1$Fold)|is.na(top1$FDR) )),] # remove NA&#39;s top1$upOrDown &lt;- 1 #write.csv(top1,&quot;tem.csv&quot;) top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval&amp; top1$Fold &gt;= log2( input_limmaFC)) ] &lt;- 2 top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval &amp; top1$Fold &lt;= -log2( input_limmaFC)) ] &lt;- 3 iz = findContrastSamples( input_selectContrast, colnames(convertedData.out), readSampleInfo.out, input_selectFactorsModel, input_selectModelComprions, factorReferenceLevels.out, input_CountsDEGMethod, input_dataFileFormat ) genes &lt;- convertedData.out[,iz] g = detectGroups(colnames(genes)) if(length(unique(g)) &gt; 2) { plot.new(); text(0.5,0.5, &quot;Not available.&quot;) } else{ average1 &lt;- apply( genes[, which( g == unique(g)[1] ) ],1,mean) average2 &lt;- apply( genes[, which( g == unique(g)[2] ) ],1,mean) genes2 &lt;- cbind(average1,average2) rownames(genes2) = rownames(genes) genes2 &lt;- merge(genes2,top1,by=&quot;row.names&quot;) par(mar=c(5,5,1,1)) plot(genes2$average2,genes2$average1,col = c(&quot;grey45&quot;,&quot;red&quot;,&quot;blue&quot;)[genes2$upOrDown], pch =16, cex = .3, xlab= paste(&quot;Average expression in&quot;, unique(g)[2] ), ylab = paste(&quot;Average expression in&quot;, unique(g)[1] ), cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2 ) legend(&quot;bottomright&quot;,c(&quot;Upregulated&quot;,&quot;Downregulated&quot;),fill = c(&quot;red&quot;,&quot;blue&quot;),cex=1.3 ) } } MAplot &lt;- function ( ) { if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast, names(top)) if( is.na(ix)) return (NULL) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (NULL) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) top1 &lt;- as.data.frame(top1) # convert to data frame top1 &lt;- top1[which(!(is.na(top1$Fold)|is.na(top1$FDR) )),] # remove NA&#39;s top1$upOrDown &lt;- 1 #write.csv(top1,&quot;tem.csv&quot;) top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval&amp; top1$Fold &gt;= log2( input_limmaFC)) ] &lt;- 2 top1$upOrDown[ which(top1$FDR &lt;= input_limmaPval &amp; top1$Fold &lt;= -log2( input_limmaFC)) ] &lt;- 3 iz = findContrastSamples( input_selectContrast, colnames(convertedData.out), readSampleInfo.out, input_selectFactorsModel, input_selectModelComprions, factorReferenceLevels.out, input_CountsDEGMethod, input_dataFileFormat ) average1 &lt;- as.data.frame( apply( convertedData()[,iz],1,mean) ) colnames(average1) = &quot;Average&quot; rownames(average1) = rownames(convertedData.out) genes2 &lt;- merge(average1,top1,by=&quot;row.names&quot;) par(mar=c(5,5,1,1)) plot(genes2$Average,genes2$Fold,col = c(&quot;grey45&quot;,&quot;red&quot;,&quot;blue&quot;)[genes2$upOrDown], pch =16, cex = .3, xlab= &quot;Average expression&quot;, ylab = &quot;Log2 fold change&quot;, cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2 ) abline(h=0) legend(&quot;bottomright&quot;,c(&quot;Upregulated&quot;,&quot;Downregulated&quot;),fill = c(&quot;red&quot;,&quot;blue&quot;),cex=1.3 ) } geneListGOTable &lt;- function() { NoSig=NULL # using expression data genes &lt;- selectedHeatmap.data.out$genes if(is.null(genes) ) return(NULL) if(dim(genes)[1] &lt;= minGenesEnrichment ) return(NoSig) # if has only few genes fc = selectedHeatmap.data.out$bar # GO results1 &lt;- NULL; result &lt;- NULL pp &lt;- 0 for( i in c(1,-1) ) { if( length(which(fc*i&lt;0)) &lt;= minGenesEnrichment) next; query = rownames(genes)[which(fc*i&lt;0)] if( length(query) &lt;= minGenesEnrichment) next; result &lt;- findOverlapGMT( query, GeneSets.out,1) if( dim(result)[2] ==1) next; # result could be NULL if(i == -1) result$direction = &quot;Up regulated&quot; else result$direction = &quot;Down regulated&quot; # changed if (pp==0 ) { results1 &lt;- result; pp = 1;} else results1 = rbind(results1,result) } if ( pp == 0 ) return (NoSig) if ( is.null( results1) ) return (NoSig) if( dim(results1)[2] == 1 ) return(NoSig) # Returns a data frame: &quot;No significant results found!&quot; results1= results1[,c(6,1,2,4,5)] # changed colnames(results1)= c(&quot;List&quot;,&quot;FDR&quot;,&quot;nGenes&quot;,&quot;GO terms or pathways&quot;,&quot;Genes&quot;) # changed minFDR = 0.01 if(min(results1$FDR) &gt; minFDR ) results1 = as.data.frame(&quot;No signficant enrichment found.&quot;) else results1 = results1[which(results1$FDR &lt; minFDR),] if(dim(results1)[2] != 5) return(NoSig) # changed colnames(results1)= c(&quot;Direction&quot;,&quot;adj.Pval&quot;,&quot;nGenes&quot;,&quot;Pathways&quot;, &quot;Genes&quot;) # changed results1 } geneListGO &lt;- function() { results1 = geneListGOTable.out tem = input_removeRedudantSets if(dim(results1)[2] ==1) return(results1) else { results1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(results1$adj.Pval) ) results1[,1] &lt;- as.character(results1[,1]) results1[ duplicated (results1[,1] ),1 ] &lt;- &quot;&quot; return( results1[,-5] ) } } # a program for ploting enrichment results by highlighting the similarities among terms # must have columns: Direction, adj.Pval Pathways Genes # Direction adj.Pval nGenes Pathways Genes #Down regulated 3.58E-59 131 Ribonucleoprotein complex biogenesis 36 Nsun5 Nhp2 Rrp15 #Down regulated 2.55E-57 135 NcRNA metabolic process 23 Nsun5 Nhp2 Rrp15 Emg1 Ddx56 Rsl1d1 enrichmentPlot &lt;- function( enrichedTerms){ # Up or down regulation is color-coded # gene set size if represented by the size of marker enrichmentPlot &lt;- function( enrichedTerms, rightMargin=33) { if(class(enrichedTerms) != &quot;data.frame&quot;) return(NULL) library(dendextend) # customizing tree geneLists = lapply(enrichedTerms$Genes, function(x) unlist( strsplit(as.character(x),&quot; &quot; ) ) ) names(geneLists)= enrichedTerms$Pathways # compute overlaps percentage-------------------- n = length(geneLists) w &lt;- matrix(NA, nrow = n, ncol = n) # compute overlaps among all gene lists for (i in 1:n) { for (j in i:n) { u &lt;- unlist(geneLists[i]) v &lt;- unlist(geneLists[j]) w[i, j] = length(intersect(u, v))/length(unique(c(u,v))) } } # the lower half of the matrix filled in based on symmetry for (i in 1:n) for (j in 1:(i-1)) w[i, j] = w[j,i] Terms = paste( sprintf(&quot;%-1.0e&quot;,as.numeric(enrichedTerms$adj.Pval)), names(geneLists)) rownames(w) = Terms colnames(w) = Terms par(mar=c(0,0,1,rightMargin)) # a large margin for showing dend &lt;- as.dist(1-w) %&gt;% hclust (method=&quot;average&quot;) ix = dend$order # permutated order of leaves leafType= as.factor( gsub(&quot; .*&quot;,&quot;&quot;, enrichedTerms$Direction[ix] ) ) if(length(unique(enrichedTerms$Direction) ) ==2 ) leafColors = c(&quot;green&quot;,&quot;red&quot;) else # mycolors leafColors = mycolors #leafSize = unlist( lapply(geneLists,length) ) # leaf size represent number of genes #leafSize = sqrt( leafSize[ix] ) leafSize = -log10(as.numeric( enrichedTerms$adj.Pval[ix] ) ) # leaf size represent P values leafSize = 1.5*leafSize/max( leafSize ) + .2 dend %&gt;% as.dendrogram(hang=-1) %&gt;% set(&quot;leaves_pch&quot;, 19) %&gt;% # type of marker set(&quot;leaves_cex&quot;, leafSize) %&gt;% #Size set(&quot;leaves_col&quot;, leafColors[leafType]) %&gt;% # up or down genes plot(horiz=TRUE) #legend(&quot;top&quot;,pch=19, col=leafColors[1:2],legend=levels(leafType),bty = &quot;n&quot;,horiz =T ) # add legend using a second layer par(lend = 1) # square line ends for the color legend add_legend(&quot;top&quot;,pch=19, col=leafColors[1:2],legend=levels(leafType),bty = &quot;n&quot;,horiz =T ) } # numChar=100 maximum number of characters # n=200 maximum number of nodes # degree.cutoff = 0 Remove node if less connected #from PPInfer enrich.net2 &lt;- function (x, gene.set, node.id, node.name = node.id, pvalue, n = 50, numChar = NULL, pvalue.cutoff = 0.05, edge.cutoff = 0.05, degree.cutoff = 0, edge.width = function(x) { 5 * x^2 }, node.size = function(x) { 2.5 * log10(x) }, group = FALSE, group.color = c(&quot;green&quot;,&quot;red&quot; ), group.shape = c(&quot;circle&quot;, &quot;square&quot;), legend.parameter = list(&quot;topright&quot;), show.legend = TRUE, plotting=TRUE, ...) { library(igraph) x &lt;- data.frame(x, group) colnames(x)[length(colnames(x))] &lt;- &quot;Group&quot; x &lt;- x[as.numeric( x[, pvalue]) &lt; pvalue.cutoff, ] x &lt;- x[order(x[, pvalue]), ] n &lt;- min(nrow(x), n) if (n == 0) { stop(&quot;no enriched term found...&quot;) } x &lt;- x[1:n, ] index &lt;- match(x[, node.id], names(gene.set)) geneSets &lt;- list() for (i in 1:n) { geneSets[[i]] &lt;- gene.set[[index[i]]] } names(geneSets) &lt;- x[, node.name] if (is.null(numChar)) { numChar &lt;- max(nchar(as.character(x[, node.name]))) } else { if (length(unique(substr(x[, node.name], 1, numChar))) &lt; nrow(x)) { numChar &lt;- max(nchar(as.character(x[, node.name]))) message(&quot;Note : numChar is too small.&quot;, &quot;\\n&quot;) } } x[, node.name] &lt;- paste(substr(x[, node.name], 1, numChar), ifelse(nchar(as.character(x[, node.name])) &gt; numChar, &quot;...&quot;, &quot;&quot;), sep = &quot;&quot;) w &lt;- matrix(NA, nrow = n, ncol = n) for (i in 1:n) { for (j in i:n) { u &lt;- unlist(geneSets[i]) v &lt;- unlist(geneSets[j]) w[i, j] = length(intersect(u, v))/length(unique(c(u, v))) } } list.edges &lt;- stack(data.frame(w)) list.edges &lt;- cbind(list.edges[, 1], rep(x[, node.name], n), rep(x[, node.name], each = n)) list.edges &lt;- list.edges[list.edges[, 2] != list.edges[,3], ] list.edges &lt;- list.edges[!is.na(list.edges[, 1]), ] g &lt;- graph.data.frame(list.edges[, -1], directed = FALSE) E(g)$width = edge.width(as.numeric(list.edges[, 1])) V(g)$size &lt;- node.size(lengths(geneSets)) g &lt;- delete.edges(g, E(g)[as.numeric(list.edges[, 1]) &lt; edge.cutoff]) index.deg &lt;- igraph::degree(g) &gt;= degree.cutoff g &lt;- delete.vertices(g, V(g)[!index.deg]) x &lt;- x[index.deg, ] index &lt;- index[index.deg] if (length(V(g)) == 0) { stop(&quot;no categories greater than degree.cutoff...&quot;) } n &lt;- min(nrow(x), n) x &lt;- x[1:n, ] group.level &lt;- sort(unique(group)) pvalues &lt;- x[, pvalue] for (i in 1:length(group.level)) { index &lt;- x[, &quot;Group&quot;] == group.level[i] V(g)$shape[index] &lt;- group.shape[i] group.pvalues &lt;- pvalues[index] if (length(group.pvalues) &gt; 0) { if (max(group.pvalues) == min(group.pvalues)) { V(g)$color[index] &lt;- adjustcolor(group.color[i], alpha.f = 0.5) } else { V(g)$color[index] &lt;- sapply(1 - (group.pvalues - min(group.pvalues))/(max(group.pvalues) - min(group.pvalues)), function(x) { adjustcolor(group.color[i], alpha.f = x) }) } } } if(plotting) { plot(g,, vertex.label.dist=1, ...) if (show.legend) { legend.parameter$legend &lt;- group.level legend.parameter$text.col &lt;- group.color legend.parameter$bty &lt;- &quot;n&quot; do.call(legend, legend.parameter) }} return(g) } enrichmentNetwork &lt;- function(enrichedTerms){ geneLists = lapply(enrichedTerms$Genes, function(x) unlist( strsplit(as.character(x),&quot; &quot; ) ) ) names(geneLists)= enrichedTerms$Pathways enrichedTerms$Direction = gsub(&quot; .*&quot;,&quot;&quot;,enrichedTerms$Direction ) g &lt;- enrich.net2(enrichedTerms, geneLists, node.id = &quot;Pathways&quot;, numChar = 100, pvalue = &quot;adj.Pval&quot;, edge.cutoff = 0.2, pvalue.cutoff = 1, degree.cutoff = 0, n = 200, group = enrichedTerms$Direction, vertex.label.cex = 1, vertex.label.color = &quot;black&quot;) } enrichmentNetworkPlotly &lt;- function(enrichedTerms){ geneLists = lapply(enrichedTerms$Genes, function(x) unlist( strsplit(as.character(x),&quot; &quot; ) ) ) names(geneLists)= enrichedTerms$Pathways g &lt;- enrich.net2(enrichedTerms, geneLists, node.id = &quot;Pathways&quot;, numChar = 100, pvalue = &quot;adj.Pval&quot;, edge.cutoff = 0.2, pvalue.cutoff = 1, degree.cutoff = 0, n = 200, group = enrichedTerms$Direction, vertex.label.cex = 0.8, vertex.label.color = &quot;black&quot; ,plotting=TRUE) vs &lt;- V(g) es &lt;- as.data.frame(get.edgelist(g)) Nv &lt;- length(vs) Ne &lt;- length(es[1]$V1) # create nodes L &lt;- layout.kamada.kawai(g) Xn &lt;- L[,1] Yn &lt;- L[,2] inc = (max(Yn)-min(Yn))/50 # for shifting #group &lt;- ifelse(V(g)$shape == &quot;circle&quot;, &quot;GO&quot;, &quot;KEGG&quot;) group &lt;- as.character(enrichedTerms$Direction) network &lt;- plot_ly(x = ~Xn, y = ~Yn, type = &quot;scatter&quot;, mode = &quot;markers&quot;, marker = list(color = V(g)$color, size = V(g)$size*2, symbol= ~V(g)$shape, line = list(color = &quot;gray&quot;, width = 2)), hoverinfo = &quot;text&quot;, text = ~paste(&quot;&lt;/br&gt;&quot;, group, &quot;&lt;/br&gt;&quot;, names(vs))) %&gt;% add_annotations( x = ~Xn, y = ~Yn+inc, text = names(vs), showarrow = FALSE, font = list(color = &quot;#030303&quot;, size = 12)) # create edges edge_shapes &lt;- list() for(i in 1:Ne) { v0 &lt;- es[i,]$V1 v1 &lt;- es[i,]$V2 index0 &lt;- match(v0, names(V(g))) index1 &lt;- match(v1, names(V(g))) edge_shape &lt;- list(type = &quot;line&quot;, line = list(color = &quot;gray&quot; , width = E(g)$width[i]/2), x0 = Xn[index0], y0 = Yn[index0], x1 = Xn[index1], y1 = Yn[index1]) edge_shapes[[i]] &lt;- edge_shape } # create network axis &lt;- list(title = &quot;&quot;, showgrid = FALSE, showticklabels = FALSE, zeroline = FALSE) h &lt;- layout(network, title = &quot;Enrichment Network&quot;, shapes = edge_shapes, xaxis = axis, yaxis = axis) config(h, showLink = TRUE) } #Homo sapies --&gt; hsapiens shortSpeciesNames &lt;- function(tem){ tem2 = strsplit(as.character(tem),&quot; &quot; ) return( tolower( paste0(substr(tem2[[1]][1],1,1), tem2[[1]][2] ) ) ) } findTaxonomyID &lt;- function( speciesName = &quot;mmusculus&quot;) { if(!is.null(input_speciesName) ) { # if species name is entered ix = match(input_speciesName, STRING10_species$official_name) } else if( input_selectGO2 != &quot;ID not recognized!&quot; ) { # if no species is entered, try to resolve species using existing info codedNames = sapply(STRING10_species$compact_name,shortSpeciesNames ) ix = match(speciesName , codedNames) if(input_selectOrg != speciesChoice[[1]]) { # if species is entered selectedSpecies = findSpeciesById(input_selectOrg)[1,1] ix = match( gsub(&quot;_.*&quot;,&quot;&quot;, selectedSpecies ), codedNames) } } else return(NULL) if(length(ix) == 0 | is.na(ix) ) return(NULL) return(STRING10_species$species_id[ix]) } STRINGdb_geneList &lt;- function() { library(STRINGdb,verbose=FALSE) taxonomyID = findTaxonomyID.out if(is.null( taxonomyID ) ) return(NULL) #Intialization string_db &lt;- STRINGdb$new( version=&quot;10&quot;, species=taxonomyID, score_threshold=0, input_directory=&quot;&quot; ) # using expression data genes &lt;- geneListData.out colnames(genes)[1:2]=c(&quot;gene&quot;,&quot;lfc&quot;) mapped &lt;- string_db$map(genes,&quot;gene&quot;, removeUnmappedRows = TRUE ) up= subset(mapped, lfc&gt;0, select=&quot;STRING_id&quot;, drop=TRUE ) down= subset(mapped, lfc&lt;0, select=&quot;STRING_id&quot;, drop=TRUE ) mappingRatio = nrow(mapped)/ nrow(genes) if(nrow(mapped) == 0) return(NULL) else return( list(up=up, down=down, ratio=mappingRatio, geneTable=mapped ) ) } STRINGDB_mapping_stat &lt;- function( ) { if( is.null(STRINGdb_geneList.out ) ) return(&quot;No genes mapped by STRINGdb. Please enter or double-check species name above.&quot;) if(! is.null(STRINGdb_geneList.out ) ) { tem=paste0( 100*round(STRINGdb_geneList()$ratio,3), &quot;% genes mapped by STRING web server.&quot;) if(STRINGdb_geneList()$ratio &lt;0.3 ) tem = paste(tem, &quot;Warning!!! Very few gene mapped. Double check if the correct species is selected.&quot;) return( tem ) } } stringDB_GO_enrichmentData &lt;- function() { library(STRINGdb,verbose=FALSE) tem = input_STRINGdbGO taxonomyID = findTaxonomyID.out if(is.null( taxonomyID ) ) return(NULL) NoSig = as.data.frame(&quot;No significant enrichment found.&quot;) #################################### #Intialization string_db &lt;- STRINGdb$new( version=&quot;10&quot;, species=taxonomyID, score_threshold=0, input_directory=&quot;&quot; ) # using expression data genes &lt;- selectedHeatmap.data.out$genes if(is.null(genes) ) return(NULL) if(dim(genes)[1] &lt;= minGenesEnrichment ) return(NoSig) # if has only few genes fc = selectedHeatmap.data.out$bar # GO results1 &lt;- NULL; result &lt;- NULL pp &lt;- 0 for( i in c(1:2) ) { if( length(which(fc*i&lt;0)) &lt;= minGenesEnrichment) next; query = rownames(genes)[which(fc*i&lt;0)] if( length(query) &lt;= minGenesEnrichment) next; ids = STRINGdb_geneList.out[[i]] result &lt;- string_db$get_enrichment( ids, category = input_STRINGdbGO, methodMT = &quot;fdr&quot;, iea = TRUE ) if(nrow(result) == 0 ) next; if(nrow(result) &gt; 15) result &lt;- result[1:15,] if( dim(result)[2] ==1) next; # result could be NULL if(i == 1) result$direction = &quot;Up regulated&quot; else result$direction = &quot;Down regulated&quot; if (pp==0 ) { results1 &lt;- result; pp = 1;} else results1 = rbind(results1,result) } if ( pp == 0 ) return (NoSig) if ( is.null( results1) ) return (NoSig) if( dim(results1)[2] == 1 ) return(NoSig) # Returns a data frame: &quot;No significant results found!&quot; results1= results1[,c(7,5,3, 6)] colnames(results1)= c(&quot;List&quot;,&quot;FDR&quot;,&quot;nGenes&quot;,&quot;GO terms or pathways&quot;) minFDR = 0.01 if(min(results1$FDR) &gt; minFDR ) results1 = as.data.frame(&quot;No signficant enrichment found.&quot;) else results1 = results1[which(results1$FDR &lt; minFDR),] if(dim(results1)[2] != 4) return(NoSig) colnames(results1)= c(&quot;Direction&quot;,&quot;adj.Pval&quot;,&quot;nGenes&quot;,&quot;Pathways&quot;) results1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(results1$adj.Pval) ) rownames(results1)=1:nrow(results1) results1[ duplicated (results1[,1] ),1 ] &lt;- &quot;&quot; return( results1 ) } stringDB_network1 &lt;- function( geneLists = 1 ) { # geneLists =2 for both up and down library(STRINGdb) tem = input_nGenesPPI taxonomyID = findTaxonomyID.out if(is.null( taxonomyID ) ) return(NULL) #################################### NoSig = as.data.frame(&quot;No significant enrichment found.&quot;) if(is.null(STRINGdb_geneList.out ) ) return(NULL) #Intialization string_db &lt;- STRINGdb$new( version=&quot;10&quot;, species=taxonomyID, score_threshold=0, input_directory=&quot;&quot; ) # only up regulated is ploted for( i in c(1:geneLists) ) { ids = STRINGdb_geneList.out[[i]] if(length(ids)&gt; input_nGenesPPI ) # n of genes cannot be more than 400 ids &lt;- ids[1:input_nGenesPPI] string_db$plot_network( ids,add_link=FALSE) } } # generates a html file containing results and also links to STRING-db stringDB_network_link &lt;- function(){ library(STRINGdb,verbose=FALSE) taxonomyID = findTaxonomyID.out if(is.null( taxonomyID ) ) return(NULL) NoSig = as.data.frame(&quot;No significant enrichment found.&quot;) if(is.null(STRINGdb_geneList.out ) ) return(NULL) #Intialization string_db &lt;- STRINGdb$new( version=&quot;10&quot;, species=taxonomyID, score_threshold=0, input_directory=&quot;&quot; ) # upregulated ids = STRINGdb_geneList.out[[1]] if(length(ids)&gt; input_nGenesPPI ) # n of genes cannot be more than 400 ids &lt;- ids[1:input_nGenesPPI] link1 = string_db$get_link( ids) Pval1 = string_db$get_ppi_enrichment( ids) tem = &quot;&lt;h5&gt; Interactive and annotated PPI networks among DEGs: &lt;br/&gt; &quot; tem = paste(tem, &quot;&lt;a href=\\&quot;&quot;, link1, &quot;\\&quot; target=\\&quot;_blank\\&quot;&gt; Up-regulated; &lt;/a&gt;&quot; ) # downregulated ids = STRINGdb_geneList()[[2]] if(length(ids)&gt; input_nGenesPPI ) ids &lt;- ids[1:input_nGenesPPI] link2 = string_db$get_link( ids) Pval2 = string_db$get_ppi_enrichment( ids) tem = paste(tem, &quot; &amp;nbsp &lt;a href=\\&quot;&quot;, link2, &quot;\\&quot;target=\\&quot;_blank\\&quot;&gt; Down-regulated; &lt;/a&gt;&quot; ) # both up and down with color code geneTable = STRINGdb_geneList.out$geneTable if(nrow(geneTable)&gt; input_nGenesPPI ) geneTable &lt;- geneTable[1:input_nGenesPPI,] geneTable = string_db$add_diff_exp_color( geneTable, logFcColStr=&quot;lfc&quot; ) payload_id &lt;- string_db$post_payload( geneTable$STRING_id,colors=geneTable$color ) link3 = string_db$get_link(geneTable$STRING_id, payload_id = payload_id) tem = paste(tem, &quot; &amp;nbsp &lt;a href=\\&quot;&quot;, link3, &quot;\\&quot;target=\\&quot;_blank\\&quot;&gt; Both with fold-changes color coded.&lt;/a&gt;&lt;/h5&gt;&quot; ) tem2 = paste(&quot;&lt;h5&gt; PPI enrichment P values: &quot;) tem2 = paste0(tem2,&quot;Up-regulated: &quot;, sprintf(&quot;%-3.2e&quot;,Pval1[1]), &quot; &amp;nbsp Down-regulated: &quot;, sprintf(&quot;%-3.2e&quot;,Pval2[1]),&quot;.&quot;) tem2 = paste(tem2, &quot; Small P values indicate more PPIs among DEGs than background. &lt;/h5&gt;&quot; ) tem = paste(tem2,tem ) return(tem) } 6.9 Pathway analysis ################################################################ # Pathway analysis ################################################################ gagePathwayData &lt;- function( ){ library(gage,verbose=FALSE) # pathway analysis #################################### myrange = c(input_minSetSize, input_maxSetSize) noSig = as.data.frame(&quot;No significant pathway found.&quot;) if( length(limma.out$topGenes) == 0 ) return(noSig) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast1, names(top)) if( is.na(ix)) return (noSig) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (noSig) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) top1 = top1[which(top1$FDR &lt;input_GenePvalCutoff) , ] gmt = GeneSets.out if(length( GeneSets.out ) == 0) { return(as.data.frame(&quot;No gene set found!&quot;))} #converted = convertID(rownames(top1),input_selectOrg) # #gmt = readGeneSets(converted, top1, input_selectGO, input_selectOrg, myrange ) # cat(&quot;Sets&quot;,length(gmt)) fold = top1[,1]; names(fold) &lt;- rownames(top1) if(input_absoluteFold) fold &lt;- abs(fold) paths &lt;- gage(fold, gsets = gmt, ref = NULL, samp = NULL) paths &lt;- rbind(paths$greater,paths$less) # write.csv(paths,&quot;tem.csv&quot;) # cat( dim(paths) ) if(dim(paths)[1] &lt; 1 | dim(paths)[2]&lt; 6 ) return( noSig ) top1 &lt;- paths[,c(&#39;stat.mean&#39;,&#39;set.size&#39;,&#39;q.val&#39;)] colnames(top1)= c(&quot;statistic&quot;,&quot;Genes&quot;,&quot;adj.Pval&quot;) top1 &lt;- top1[order(top1[,3]) ,] if ( length( which( top1[,3] &lt;= input_pathwayPvalCutoff ) ) == 0 ) return( noSig) top1 &lt;- top1[which(top1[,3] &lt;= input_pathwayPvalCutoff ) ,,drop=FALSE] if(dim(top1)[1] &gt; input_nPathwayShow ) top1 &lt;- top1[1:input_nPathwayShow, ,drop=FALSE] top1 &lt;- as.data.frame(top1) top1 &lt;- cbind(rep( input_selectContrast1, dim(top1)[1]),row.names(top1), top1); top1$statistic &lt;- as.character( round(as.numeric(top1$statistic),4)); top1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(top1$adj.Pval) ) top1[,2] &lt;- as.character(top1[,2]);top1[,1] &lt;- as.character(top1[,1]) colnames(top1)[1] &lt;- &quot;Direction&quot; p.m &lt;- &quot;GAGE&quot; colnames(top1)[2] &lt;- paste(p.m,&quot; analysis:&quot;, gsub(&quot;-&quot;,&quot; vs &quot;,input_selectContrast1 ) ) top1[ which( top1[,3] &gt;0),1 ] &lt;- &quot;Up&quot; #gsub(&quot;-&quot;,&quot; &gt; &quot;,input_selectContrast1 ) top1[ which( top1[,3] &lt;0),1 ] &lt;- &quot;Down&quot; # gsub(&quot;-&quot;,&quot; &lt; &quot;,input_selectContrast1 ) top1 &lt;- top1[order( top1[,1], -abs(as.numeric( top1[,3]) ) ) ,] top1[ duplicated (top1[,1] ),1 ] &lt;- &quot;&quot; return( top1) } fgseaPathwayData &lt;- function() { library(fgsea,verbose=FALSE) # fast GSEA noSig = as.data.frame(&quot;No significant pathway found.&quot;) if( length(limma.out$topGenes) == 0 ) return(noSig) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast1, names(top)) if( is.na(ix)) return (noSig) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (noSig) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) # remove some genes top1 = top1[which(top1$FDR &lt;input_GenePvalCutoff) , ] gmt = GeneSets.out if(length( GeneSets.out ) == 0) { return(as.data.frame(&quot;No gene set found!&quot;))} #converted = convertID(rownames(top1),input_selectOrg) # #gmt = readGeneSets(converted, top1, input_selectGO, input_selectOrg, myrange ) # cat(&quot;Sets&quot;,length(gmt)) fold = top1[,1]; names(fold) &lt;- rownames(top1) if(input_absoluteFold) fold &lt;- abs(fold) # use absolute value of fold change, disregard direction paths &lt;- fgsea(pathways = gmt, stats = fold, minSize=input_minSetSize, maxSize=input_maxSetSize, nperm=10000) # paths &lt;- rbind(paths$greater,paths$less) if(dim(paths)[1] &lt; 1 ) return( noSig ) paths &lt;- as.data.frame(paths) paths &lt;- paths[order(-abs( paths[,5])) ,] # sort by NES # paths &lt;- paths[order( paths[,3]) ,] # sort by FDR top1 &lt;- paths[,c(1,5,7,3)] # rownames(top1) &lt;- paths[,1] #paste(1:dim(paths)[1],&quot;: &quot;,paths[,1],sep=&quot;&quot; ) colnames(top1)= c(&quot;Pathway&quot;, &quot;NES&quot;,&quot;Genes&quot;,&quot;adj.Pval&quot;) if ( length( which( top1[,4] &lt;= input_pathwayPvalCutoff ) ) == 0 ) return( noSig) top1 &lt;- top1[which(top1[,4] &lt;= input_pathwayPvalCutoff ) , ,drop=FALSE] if(dim(top1)[1] &gt; input_nPathwayShow ) top1 &lt;- top1[1:input_nPathwayShow,,drop=FALSE] #top1 &lt;- cbind(row.names(top1), top1); colnames(top1)[1] &lt;-input_selectContrast1 top1 &lt;- as.data.frame(top1) top1 &lt;- cbind(rep( input_selectContrast1, dim(top1)[1]), top1); top1[,4] = as.character( round(as.numeric(top1[,4]),4)); top1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(top1$adj.Pval) ) top1[,1] &lt;- as.character(top1[,1]) colnames(top1)[1] &lt;- &quot;Direction&quot; p.m &lt;- &quot;GSEA&quot; colnames(top1)[2] &lt;- paste(p.m,&quot; analysis:&quot;, gsub(&quot;-&quot;,&quot; vs &quot;,input_selectContrast1 ) ) top1[ which( as.numeric( top1[,3]) &gt;0),1 ] &lt;- &quot;Up&quot; #gsub(&quot;-&quot;,&quot; &gt; &quot;,input_selectContrast1 ) top1[ which( as.numeric( top1[,3]) &lt;0),1 ] &lt;- &quot;Down&quot; #gsub(&quot;-&quot;,&quot; &lt; &quot;,input_selectContrast1 ) top1 &lt;- top1[order( top1[,1], -abs(as.numeric( top1[,3]) ) ) ,] top1[ duplicated (top1[,1] ),1 ] &lt;- &quot;&quot; top1[,3] = as.character( round(as.numeric(top1[,3]),4)); return( top1) } extract1 &lt;- function (x) { words &lt;- unlist ( strsplit(x,&quot;_&quot;)) if(length( words ) &lt;=4 ) return(gsub(&quot;_&quot;,&quot; &quot;,x)) else { words &lt;- words[-c(1:4)] return( proper(paste(words,collapse = &quot; &quot;) ) )} } PGSEApathway &lt;- function (converted,convertedData, selectOrg,GO,gmt, myrange,Pval_pathway,top){ subtype = detectGroups(colnames(convertedData)) library(PGSEA,verbose=FALSE) Pvalue = 0.01 # cut off to report in PGSEA. Otherwise NA #Pval_pathway = 0.2 # cut off for P value of ANOVA test to writ to file # top = 30 # number of pathways to show if(length(gmt) ==0 ) return( list(pg3 = NULL, best = 1 ) ) # centering by mean #pg = myPGSEA (convertedData - rowMeans(convertedData), # cl=gmt,range=myrange,p.value=TRUE, weighted=FALSE,nPermutation=100) #if( class(convertedData) != &quot;data.frame&quot; | class(convertedData) != &quot;matarix&quot;) return( list(pg3 = NULL, best = 1 ) ) #if( dim(convertedData)[2] &lt;2 ) return( list(pg3 = NULL, best = 1 ) ) pg = PGSEA (convertedData - rowMeans(convertedData),cl=gmt,range=myrange,p.value=TRUE, weighted=FALSE) pg2 = pg$results; pg2 = pg2[rowSums(is.na(pg2))&lt;ncol(pg2) ,] # remove se/wrts with all missing(non-signficant) if (dim(pg2)[1] &lt; 2 ) return.out best = max(abs(pg2)) if(length(subtype) &lt; 4 || length(unique(subtype)) &lt;2 ||length(unique(subtype)) == dim(convertedData)[2] ) { pg2 = pg2[order(-apply(pg2,1,sd) ) ,] return( list(pg3 = pg2[1:top,], best = best ) ) } cat(&quot;\\nComputing P values using ANOVA\\n&quot;); pathPvalue &lt;- function ( k){ return( summary(aov(pg2[k,]~subtype) )[[1]][[&quot;Pr(&gt;F)&quot;]][1] ) } Pvalues = sapply(1:dim(pg2)[1], pathPvalue) Pvalues = p.adjust(Pvalues, &quot;fdr&quot;) #if(min(Pvalues) &gt; Pval_pathway ) return( list(pg3 = NULL, best = best ) ) else { if(sort(Pvalues)[2] &gt; Pval_pathway ) return( list(pg3 = NULL, best = best ) ) else { NsigT = rowSums(pg$p.results&lt;Pvalue) result=cbind( as.matrix(Pvalues),NsigT,pg2); result = result[ order(result[,1]) ,] result = result[which(result[,1] &lt; Pval_pathway),,drop=F] #result = result[which(result[,2] &gt;2) ,] pg2 = result[,-2] # when there is only 1 left in the matrix pg2 becomes a vector if(sum( Pvalues&lt;Pval_pathway) == 1) { pg3 = t( as.matrix(pg2));pg3 = rbind(pg3,pg3);} else { if(dim(pg2)[1] &gt; top ) { pg3 = pg2[1:top,]; } else { pg3 = pg2; } } rownames(pg3) = sapply(rownames(pg3) , extract1) a=sprintf(&quot;%-3.2e&quot;,pg3[,1]) rownames(pg3) = paste(a,rownames(pg3),sep=&quot; &quot;) pg3 =pg3[,-1] pg3 &lt;- pg3[order( -apply(pg3,1,sd) ),] # sort by SD return( list(pg3 = pg3, best = best ) ) } } PGSEAplot &lt;- function(){ library(PGSEA,verbose=FALSE) if(input_selectGO == &quot;ID not recognized!&quot; ) return( NULL) myrange = c(input_minSetSize, input_maxSetSize) genes = convertedData.out if (is.null(input_selectContrast1 ) ) return(NULL) gmt = GeneSets.out # find related samples iz = findContrastSamples(input_selectContrast1, colnames(convertedData.out),readSampleInfo.out, input_selectFactorsModel,input_selectModelComprions, factorReferenceLevels.out,input_CountsDEGMethod, input_dataFileFormat ) genes = genes[,iz] subtype = detectGroups(colnames(genes )) if(length( GeneSets.out ) == 0) { plot.new(); text(0.5,0.5, &quot;No gene sets!&quot;)} else { result = PGSEApathway(converted.out,genes, input_selectOrg,input_selectGO, GeneSets.out, myrange, input_pathwayPvalCutoff, input_nPathwayShow ) if( is.null(result$pg3) ) { plot.new(); text(0.5,1, &quot;No significant pathway found!&quot;)} else smcPlot(result$pg3,factor(subtype),scale = c(-max(result$pg3), max(result$pg3)), show.grid = T, margins = c(3,1, 13,28), col = .rwb,cex.lab=0.5, main=&quot;Pathway Analysis:PGSEA&quot;) } } convertEnsembl2Entrez &lt;- function (query,Species) { querySet &lt;- cleanGeneSet( unlist( strsplit( toupper(names( query)),&#39;\\t| |\\n|\\\\,&#39; ) ) ) speciesID &lt;- orgInfo$id[ which(orgInfo$ensembl_dataset == Species)] # note uses species Identifying # idType 6 for entrez gene ID result &lt;- dbGetQuery( convert, paste( &quot; select id,ens,species from mapping where ens IN (&#39;&quot;, paste(querySet,collapse=&quot;&#39;, &#39;&quot;), &quot;&#39;) AND idType =&#39;&quot;,idType_Entrez,&quot;&#39;&quot;,sep=&quot;&quot;) ) # slow if( dim(result)[1] == 0 ) return(NULL) result &lt;- subset(result, species==speciesID, select = -species) ix = match(result$ens,names(query) ) tem &lt;- query[ix]; names(tem) = result$id return(tem) } ReactomePAPathwayData &lt;- function( ){ library(ReactomePA,verbose=FALSE) # pathway analysis ensemblSpecies &lt;- c(&quot;hsapiens_gene_ensembl&quot;,&quot;rnorvegicus_gene_ensembl&quot;, &quot;mmusculus_gene_ensembl&quot;, &quot;celegans_gene_ensembl&quot;,&quot;scerevisiae_gene_ensembl&quot;, &quot;drerio_gene_ensembl&quot;, &quot;dmelanogaster_gene_ensembl&quot;) ReactomePASpecies= c(&quot;human&quot;, &quot;rat&quot;, &quot;mouse&quot;, &quot;celegans&quot;, &quot;yeast&quot;, &quot;zebrafish&quot;, &quot;fly&quot; ) # cbind(ensemblSpecies,ReactomePASpecies) # double check mapping myrange = c(input_minSetSize, input_maxSetSize) noSig = as.data.frame(&quot;No significant pathway found.&quot;) if( length(limma.out$topGenes) == 0 ) return(noSig) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast1, names(top)) if( is.na(ix)) return (noSig) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (noSig) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) # remove some genes top1 = top1[which(top1$FDR &lt;input_GenePvalCutoff) , ] fold = top1[,1]; names(fold) &lt;- rownames(top1) if(input_absoluteFold) fold &lt;- abs(fold) # use absolute value of fold change, disregard direction Species &lt;- converted.out$species ix &lt;- match( Species,ensemblSpecies ) if(is.na(ix) ) return(as.data.frame(&quot;Species not coverted by ReactomePA package!&quot;)) fold &lt;- convertEnsembl2Entrez (fold, Species) fold &lt;- sort(fold,decreasing =T) paths &lt;- gsePathway(fold, nPerm=5000, organism = ReactomePASpecies[ix], minGSSize= input_minSetSize, maxGSSize= input_maxSetSize, pvalueCutoff=0.5, pAdjustMethod=&quot;BH&quot;, verbose=FALSE) paths &lt;- as.data.frame(paths) if(is.null(paths) ) return( noSig) if(dim(paths)[1] ==0 ) return( noSig) # paths &lt;- rbind(paths$greater,paths$less) if(dim(paths)[1] &lt; 1 ) return( noSig ) paths &lt;- as.data.frame(paths) paths &lt;- paths[order(-abs( paths[,5])) ,] # sort by NES # paths &lt;- paths[order( paths[,3]) ,] # sort by FDR top1 &lt;- paths[,c(2,5,3,7)] # rownames(top1) &lt;- paths[,1] #paste(1:dim(paths)[1],&quot;: &quot;,paths[,1],sep=&quot;&quot; ) colnames(top1)= c(&quot;Pathway&quot;, &quot;NES&quot;,&quot;Genes&quot;,&quot;adj.Pval&quot;) if ( length( which( top1[,4] &lt;= input_pathwayPvalCutoff ) ) == 0 ) return( noSig) top1 &lt;- top1[which(top1[,4] &lt;= input_pathwayPvalCutoff ) ,,drop=FALSE] if(dim(top1)[1] &gt; input_nPathwayShow ) top1 &lt;- top1[1:input_nPathwayShow,,drop=FALSE] #top1 &lt;- cbind(row.names(top1), top1); colnames(top1)[1] &lt;-input_selectContrast1 top1 &lt;- as.data.frame(top1) top1 &lt;- cbind(rep( input_selectContrast1, dim(top1)[1]), top1); top1[,4] = as.character( round(as.numeric(top1[,4]),4)); top1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(top1$adj.Pval) ) top1[,1] &lt;- as.character(top1[,1]) colnames(top1)[1] &lt;- &quot;Direction&quot; if(input_pathwayMethod == 1 ) p.m &lt;- &quot;GAGE&quot; else if(input_pathwayMethod == 2 ) p.m &lt;- &quot;PGSEA&quot; else if(input_pathwayMethod == 3 ) p.m &lt;- &quot;GSEA&quot; else if(input_pathwayMethod == 4 ) p.m &lt;- &quot;PGSEA_All&quot; else if(input_pathwayMethod == 5 ) p.m &lt;- &quot;ReactomePA&quot; colnames(top1)[2] &lt;- paste(p.m,&quot; analysis:&quot;, gsub(&quot;-&quot;,&quot; vs &quot;,input_selectContrast1 ) ) top1[ which( as.numeric( top1[,3]) &gt;0),1 ] &lt;- &quot;Up&quot; #gsub(&quot;-&quot;,&quot; &gt; &quot;,input_selectContrast1 ) top1[ which( as.numeric( top1[,3]) &lt;0),1 ] &lt;- &quot;Down&quot; #gsub(&quot;-&quot;,&quot; &lt; &quot;,input_selectContrast1 ) top1 &lt;- top1[order( top1[,1], -abs(as.numeric( top1[,3]) ) ) ,] top1[ duplicated (top1[,1] ),1 ] &lt;- &quot;&quot; top1[,3] = as.character( round(as.numeric(top1[,3]),4)); return( top1) } selectedPathwayData &lt;- function( ){ if(input_sigPathways == &quot;All&quot;) return (NULL) ix &lt;- which(names(GeneSets.out ) == input_sigPathways ) # find the gene set if(length(ix) == 0 ) return(NULL) genes &lt;- GeneSets.out[[ix]] # retrieve genes # find related samples iz = findContrastSamples(input_selectContrast1, colnames(convertedData.out),readSampleInfo.out, input_selectFactorsModel,input_selectModelComprions, factorReferenceLevels.out,input_CountsDEGMethod , input_dataFileFormat ) x &lt;- convertedData.out[which(rownames(convertedData.out) %in% genes), iz ] if( input_selectOrg != &quot;NEW&quot;) { ix = match( rownames(x), allGeneInfo.out[,1]) if( sum( is.na(allGeneInfo.out$symbol )) != dim(allGeneInfo.out )[1] ) # symbol really exists? rownames(x) &lt;- paste(rownames(x),&quot;:&quot;, as.character( allGeneInfo.out$symbol)[ix]) } return( x ) } selectedPathwayHeatmap &lt;- function() { x = selectedPathwayData.out if(dim(x)[1]&lt;=2 | dim(x)[2]&lt;=2 ) return(NULL) groups = detectGroups(colnames(x)) # this will cutoff very large values, which could skew the color x=as.matrix(x)-apply(as.matrix(x),1,mean) cutoff = median(unlist(x)) + 3*sd (unlist(x)) x[x&gt;cutoff] &lt;- cutoff cutoff = median(unlist(x)) - 3*sd (unlist(x)) x[x&lt; cutoff] &lt;- cutoff # sometimes, a gene can be all zero in selected samples. x &lt;- x[which(apply(x,1,sd)&gt;0) ,] lmat = rbind(c(5,4),c(0,1),c(3,2)) lwid = c(1.5,6) lhei = c(.5,.2,8) if( dim(x)[1]&gt;200) heatmap.2(x, distfun = dist2,hclustfun=hclust2, col=heatColors[as.integer(input_heatColors1),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.5 ,key=T, symkey=F ,dendrogram = &quot;row&quot; ,ColSideColors=mycolors[ groups] ,labRow=&quot;&quot; ,margins=c(10,15) ,srtCol=45 ,lmat = lmat, lwid = lwid, lhei = lhei #,main =&quot;Title&quot; ) if( dim(x)[1]&lt;=200) heatmap.2(x, distfun = dist2,hclustfun=hclust2, col=heatColors[as.integer(input_heatColors1),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.5 ,key=T, symkey=F, dendrogram = &quot;row&quot;, ,labRow=gsub(&quot;.*:&quot;,&quot;&quot;,rownames(x)) ,ColSideColors=mycolors[ groups] ,margins=c(10,15) ,cexRow=1.2 ,srtCol=45 ,lmat = lmat, lwid = lwid, lhei = lhei #,main =&quot;Title&quot; ) } convertEnsembl2KEGG &lt;- function (query,Species) { # not working querySet &lt;- cleanGeneSet( unlist( strsplit( toupper(names( query)),&#39;\\t| |\\n|\\\\,&#39; ) ) ) speciesID &lt;- orgInfo$id[ which(orgInfo$ensembl_dataset == Species)] # note uses species Identifying # idType 6 for entrez gene ID result &lt;- dbGetQuery( convert, paste( &quot; select id,ens,species from mapping where ens IN (&#39;&quot;, paste(querySet,collapse=&quot;&#39;, &#39;&quot;), &quot;&#39;) AND idType =&#39;&quot;,idType_KEGG,&quot;&#39;&quot;,sep=&quot;&quot;) ) # slow if( dim(result)[1] == 0 ) return(NULL) result &lt;- subset(result, species==speciesID, select = -species) ix = match(result$ens,names(query) ) tem &lt;- query[ix]; names(tem) = result$id return(tem) } keggPathwayID &lt;- function (pathwayDescription, Species, GO,selectOrg) { ix = grep(Species,gmtFiles) if (length(ix) == 0 ) {return(NULL)} # If selected species is not the default &quot;bestMatch&quot;, use that species directly if(selectOrg != speciesChoice[[1]]) { ix = grep(findSpeciesById(selectOrg)[1,1], gmtFiles ) if (length(ix) == 0 ) {return(NULL )} totalGenes &lt;- orgInfo[which(orgInfo$id == as.numeric(selectOrg)),7] } pathway &lt;- dbConnect(sqlite,gmtFiles[ix],flags=SQLITE_RO) # change Parkinson&#39;s disease to Parkinson\\&#39;s disease otherwise SQL pathwayDescription &lt;- gsub(&quot;\\&#39;&quot;,&quot;\\&#39;\\&#39;&quot;,pathwayDescription) pathwayInfo &lt;- dbGetQuery( pathway, paste( &quot; select * from pathwayInfo where description = &#39;&quot;, pathwayDescription, &quot;&#39; AND name LIKE &#39;&quot;,GO,&quot;%&#39;&quot;,sep=&quot;&quot;) ) pathwayInfo &lt;- dbGetQuery( pathway, paste( &quot; select * from pathwayInfo where description = &#39;&quot;, pathwayDescription, &quot;&#39;&quot;,sep=&quot;&quot;) ) dbDisconnect(pathway); if(dim(pathwayInfo)[1] != 1 ) {return(NULL) } tem = gsub(&quot;.*:&quot;,&quot;&quot;,pathwayInfo[1,2]) return( gsub(&quot;_.*&quot;,&quot;&quot;,tem) ) } KeggImage &lt;- function(){ # First generate a blank image. Otherwise return(NULL) gives us errors. outfile &lt;- tempfile(fileext=&#39;.png&#39;) png(outfile, width=400, height=300) frame() dev.off() blank &lt;- list(src = outfile, contentType = &#39;image/png&#39;, width = 400, height = 300, alt = &quot; &quot;) if(is.null( input_selectGO ) ) return(outfile) if(input_selectGO != &quot;KEGG&quot;) return(outfile) if(is.null(gagePathwayData.out ) ) return(outfile) if(is.null( input_sigPathways)) return (outfile) # if( is.null(selectedPathwayData()) ) return(blank) library(pathview) if (is.null(input_selectContrast1 ) ) return(outfile) if(input_sigPathways == &quot;All&quot;) return (outfile) if( length(limma.out$topGenes) == 0 ) return(outfile) # get fold change if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast1, names(top)) if( is.na(ix)) return (outfile) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (outfile) # cat(&quot;here5&quot;) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) Species &lt;- converted.out$species fold = top1[,1]; names(fold) &lt;- rownames(top1) fold &lt;- convertEnsembl2Entrez(fold,Species) keggSpecies &lt;- as.character( keggSpeciesID[which(keggSpeciesID[,1] == Species),3] ) if(nchar( keggSpecies) &lt;=2 ) return(outfile) # not in KEGG # kegg pathway id pathID = keggPathwayID(input_sigPathways, Species, &quot;KEGG&quot;,input_selectOrg) #cat(&quot;\\nhere5 &quot;,keggSpecies, &quot; &quot;,Species,&quot; &quot;,input_sigPathways, &quot;pathID:&quot;,pathID,&quot;End&quot;, fold[1:5],names(fold)[1:5],&quot;\\n&quot;) #cat(&quot;\\npathway:&quot;,is.na(input_sigPathways)) #cat(&quot;\\n&quot;,fold[1:5],&quot;\\n&quot;,keggSpecies,&quot;\\n&quot;,pathID) if(is.null(pathID) ) return(blank) # kegg pathway id not found. if(nchar(pathID)&lt;3 ) return(blank) randomString &lt;- gsub(&quot;.*file&quot;,&quot;&quot;,tempfile()) outfile &lt;- paste(pathID,&quot;.&quot;,randomString,&quot;.png&quot;,sep=&quot;&quot;) try( pv.out &lt;- pathview(gene.data = fold, pathway.id = pathID, out.suffix = randomString, species = keggSpecies, kegg.native=TRUE) ) return( outfile ) } # list of pathways with details pathwayListData &lt;- function(){ pathways = NULL if( input_pathwayMethod == 1) if(!is.null(gagePathwayData.out)) if(dim(gagePathwayData.out)[2] &gt;1) { pathways &lt;- gagePathwayData.out colnames(pathways)[2] =&quot;Pathways&quot;; colnames(pathways)[4] =&quot;nGenes&quot;; } if( input_pathwayMethod == 3) if(!is.null(fgseaPathwayData.out)) if(dim(fgseaPathwayData.out)[2] &gt;1) { pathways &lt;- fgseaPathwayData.out colnames(pathways)[2] =&quot;Pathways&quot;; colnames(pathways)[4] =&quot;nGenes&quot;; } if( input_pathwayMethod == 2) if(!is.null(PGSEAplot.data.out)) if(dim(PGSEAplot.data.out)[2] &gt;1) { pathways &lt;- as.data.frame( PGSEAplot.data.out) pathways$Pathways = substr(rownames(pathways),10, nchar( rownames(pathways)) ) pathways$adj.Pval = gsub(&quot; .*&quot;,&quot;&quot;, rownames(pathways)) pathways$Direction =&quot;Diff&quot; } if( input_pathwayMethod == 4) if(!is.null(PGSEAplotAllSamples.data.out)) if(dim(PGSEAplotAllSamples.data.out)[2] &gt;1) { pathways &lt;- as.data.frame( PGSEAplotAllSamples.data.out) pathways$Pathways = substr(rownames(pathways),10, nchar( rownames(pathways)) ) pathways$adj.Pval = gsub(&quot; .*&quot;,&quot;&quot;, rownames(pathways)) pathways$Direction =&quot;Diff&quot; } if( is.null( pathways) ) return(NULL) # if no gene set data, return pathway list if(is.null(GeneSets.out ) ) return(pathways) pathways$adj.Pval = as.numeric(pathways$adj.Pval) if(nrow(pathways)&gt;1) for( i in 2:nrow(pathways) ) if(nchar(pathways$Direction[i]) &lt;=1) pathways$Direction[i] = pathways$Direction[i-1] # gene symbol matching symbols probeToGene = NULL if( input_selectGO != &quot;ID not recognized!&quot; &amp; input_selectOrg != &quot;NEW&quot;) if(sum(is.na( allGeneInfo.out$symbol ) )/ dim( allGeneInfo.out )[1] &lt;.5 ) { # if more than 50% genes has symbol probeToGene = allGeneInfo.out[,c(&quot;ensembl_gene_id&quot;,&quot;symbol&quot;)] probeToGene$symbol = gsub(&quot; &quot;,&quot;&quot;,probeToGene$symbol) ix = which( is.na(probeToGene$symbol) | nchar(probeToGene$symbol)&lt;2 | toupper(probeToGene$symbol)==&quot;NA&quot; | toupper(probeToGene$symbol)==&quot;0&quot; ) probeToGene[ix,2] = probeToGene[ix,1] # use gene ID } pathways$Genes =&quot;&quot; # looking up genes for each pathway for(i in 1:nrow(pathways) ){ ix &lt;- which(names(GeneSets.out ) == pathways$Pathways[i] ) # find the gene set if(length(ix) != 0 ) { genes &lt;- GeneSets.out[[ix]] # retrieve genes if(!is.null(probeToGene) ) { iy = match(genes,probeToGene[,1]) genes = probeToGene[iy,2] } pathways$Genes[i] = paste(genes, collapse=&quot; &quot;) } } return(pathways) } 6.10 Genome-wide view ################################################################ # Genome-wide view ################################################################ genomePlotly &lt;- function( ){ # default plot fake = data.frame(a=1:3,b=1:3) p &lt;- ggplot(fake, aes(x = a, y = b)) + geom_blank() + ggtitle(&quot;No genes with position info.&quot;) + theme(axis.title.x=element_blank(),axis.title.y=element_blank()) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast2, names(top)) if( is.na(ix)) return (ggplotly(p)) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (ggplotly(p)) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) # write.csv(merge(top1,allGeneInfo(), by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ),&quot;tem.csv&quot; ) x &lt;- merge(top1,allGeneInfo.out, by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ) # if no chromosomes found. For example if user do not convert gene IDs. if( dim(x)[1] &gt;5 ) { x &lt;- x[order(x$chromosome_name,x$start_position),] tem = sort( table( x$chromosome_name), decreasing=T) chromosomes &lt;- names( tem[tem &gt;= 5 ] ) # chromosomes with less than 100 genes are excluded if(length(chromosomes) &gt; 50) chromosomes &lt;- chromosomes[1:50] # at most 50 chromosomes chromosomes &lt;- chromosomes[ nchar(chromosomes)&lt;=12] # chr. name less than 10 characters chromosomes = chromosomes[order(as.numeric(chromosomes) ) ] # chromosomes = chromosomes[!is.na(as.numeric(chromosomes) ) ] chromosomesNumbers = as.numeric(chromosomes) # convert chr.x to numbers j = max( chromosomesNumbers,na.rm=T) for( i in 1:length( chromosomes)) { if ( is.na(chromosomesNumbers[i]) ) { chromosomesNumbers[i] &lt;- j+1; j &lt;- j+1; } } x &lt;- x[which(x$chromosome_name %in% chromosomes ),] x &lt;- droplevels(x) # find the number coding for chromosome getChrNumber &lt;- function (chrName){ return( chromosomesNumbers[ which( chromosomes == chrName)] ) } x$chrNum = 1 # numeric coding x$chrNum &lt;- unlist( lapply( x$chromosome_name, getChrNumber) ) x$Row.names &lt;- as.character( x$Row.names) # if symbol is missing use Ensembl id x$symbol = as.character(x$symbol) ix = which(is.na(x$symbol)) ix2 = which(nchar(as.character(x$symbol))&lt;= 2 ) ix3 = which( duplicated(x$symbol)) ix = unique( c(ix,ix2,ix3)) x$symbol[ix] &lt;- x$Row.names[ix] ################################## # plotting # x = read.csv(&quot;tem_genome.csv&quot;) x = x[!is.na(x$chromosome_name),] x = x[!is.na(x$start_position),] # only keep significant genes #x = x[which(x$FDR&lt;input_limmaPval),] # x = x[which(abs(x$Fold) &gt; log2( input_limmaFC)),] ix = which( (x$FDR&lt; as.numeric(input_limmaPvalViz)) &amp; (abs(x$Fold) &gt; as.numeric(input_limmaFCViz) ) ) if (length(ix) &gt; 5) { x = x[ix,] x$start_position = x$start_position/1000000 # Mbp chrD = 20 # distance between chrs. foldCutoff = 3 # max log2 fold x$Fold = x$Fold / sd(x$Fold) # standardize fold change x$Fold[which(x$Fold &gt; foldCutoff )] = foldCutoff # log2fold within -5 to 5 x$Fold[which(x$Fold &lt; -1*foldCutoff )] = -1*foldCutoff x$Fold = 4* x$Fold x$y = x$chrNum*chrD + x$Fold chrLengthTable = aggregate(start_position~chrNum, data=x,max ) chrTotal = dim(chrLengthTable)[1] x$R = as.factor(sign(x$Fold)) colnames(x)[ which(colnames(x) == &quot;start_position&quot;)] = &quot;x&quot; p= ggplot(x, aes(x = x, y = y, colour = R, text = symbol ) ) + geom_point(shape = 20, size = .2) #label y with chr names p &lt;- p + scale_y_continuous(labels = paste(&quot;chr&quot;,chromosomes[chrLengthTable$chrNum],sep=&quot;&quot;), breaks = chrD* (1:chrTotal), limits = c(0, chrD*chrTotal + 5) ) # draw horizontal lines for each chr. for( i in 1:dim(chrLengthTable)[1] ) p = p+ annotate( &quot;segment&quot;,x = 0, xend = chrLengthTable$start_position[i], y = chrLengthTable$chrNum[i]*chrD, yend = chrLengthTable$chrNum[i]*chrD) # change legend http://ggplot2.tidyverse.org/reference/scale_manual.html p=p+scale_colour_manual(name=&quot;&quot;, # customize legend text values=c(&quot;blue&quot;, &quot;red&quot;), breaks=c(&quot;1&quot;,&quot;-1&quot;), labels=c(&quot;Up&quot;, &quot;Dn&quot;)) p = p + xlab(&quot;Position on chrs. (Mbp)&quot;) + theme(axis.title.y=element_blank()) p= p + theme(legend.position=&quot;none&quot;) # p &lt;- ggplot(mtcars, aes(x=hp, y=mpg)) + geom_point(shape=20, size=17) # p=p+ geom_smooth(method = &quot;lm&quot;,se=FALSE) #p+ geom_line(aes(y=rollmean(y,7, na.pad=TRUE))) # Customize hover text https://cran.r-project.org/web/packages/plotly/plotly.pdf # style(ggplotly(p),hoverinfo=&quot;text&quot;) # not working } # if no genes else } ggplotly(p) } # results from PREDA genomePlotData &lt;- function( ){ if (is.null(input_selectContrast2 ) ) return(NULL) if( length(limma.out$topGenes) == 0 ) return(NULL) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast2, names(top)) if( is.na(ix)) return (NULL) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (NULL) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) # write.csv(merge(top1,allGeneInfo(), by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ),&quot;tem.csv&quot; ) x &lt;- merge(top1,allGeneInfo.out, by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ) x &lt;- x[order(x$chromosome_name,x$start_position),] tem = sort( table( x$chromosome_name), decreasing=T) chromosomes &lt;- names( tem[tem &gt; 100 ] ) # chromosomes with less than 100 genes are excluded if(length(chromosomes) &gt; 50) chromosomes &lt;- chromosomes[1:50] # at most 50 chromosomes chromosomes = chromosomes[order(as.numeric(chromosomes) ) ] # chromosomes = chromosomes[!is.na(as.numeric(chromosomes) ) ] chromosomesNumbers = as.numeric(chromosomes) # convert chr.x to numbers j = max( chromosomesNumbers,na.rm=T) for( i in 1:length( chromosomes)) { if ( is.na(chromosomesNumbers[i]) ) { chromosomesNumbers[i] &lt;- j+1; j &lt;- j+1; } } x &lt;- x[which(x$chromosome_name %in% chromosomes ),] x &lt;- droplevels(x) # find the number coding for chromosome getChrNumber &lt;- function (chrName){ return( chromosomesNumbers[ which( chromosomes == chrName)] ) } x$chrNum = 1 # numeric coding x$chrNum &lt;- unlist( lapply( x$chromosome_name, getChrNumber) ) x$Row.names &lt;- as.character( x$Row.names) fold = x$Fold; names(fold) = x$Row.names # write.csv(x,&quot;tem.csv&quot;) x &lt;- x[!duplicated(x$Row.names),] #rownames(x) = x$Row.names GEanalysisResults &lt;- genomePlotDataPre.out; genomic_regions_UP&lt;-PREDAResults2GenomicRegions(GEanalysisResults, qval.threshold=input_RegionsPvalCutoff, smoothStatistic.tail=&quot;upper&quot;, smoothStatistic.threshold= input_StatisticCutoff) genomic_regions_DOWN&lt;-PREDAResults2GenomicRegions(GEanalysisResults, qval.threshold=input_RegionsPvalCutoff, smoothStatistic.tail=&quot;lower&quot;, smoothStatistic.threshold= -1 *input_StatisticCutoff) if( is.null(genomic_regions_UP$Test) &amp;&amp; is.null(genomic_regions_UP$Test) ) return(-1) # no significant regions regions &lt;- 0 if( !is.null(genomic_regions_UP$Test)) { dataframe_UPregions&lt;-GenomicRegions2dataframe(genomic_regions_UP[[1]]) dataframe_UPregions$Regulation &lt;- &quot;Up&quot; regions = dataframe_UPregions } if( !is.null(genomic_regions_DOWN$Test) ){ dataframe_DOWNregions&lt;-GenomicRegions2dataframe(genomic_regions_DOWN[[1]]) dataframe_DOWNregions$Regulation &lt;- &quot;Down&quot; if ( class(regions) != &quot;data.frame&quot; ) regions &lt;- dataframe_DOWNregions else # if UP regions is NULL regions = rbind(regions,dataframe_DOWNregions ) } if( class(regions) != &quot;data.frame&quot;) return(-1) Regions &lt;- regions[,c(4,1:3)] Regions &lt;- Regions[which(Regions$end != Regions$start),] Regions$size = round((Regions$end - Regions$start )/1000000,3) Regions$chr &lt;- chromosomes[ Regions$chr ] # convert from chr. number to names # find the gene indices in the up or down regulated regions regulatedGenes &lt;- function (i) { ix = which( Regions$chr == x$chromosome_name[i] &amp; Regions$start &lt; x$start_position[i] #&amp;(Regions$end &gt; x$start_position[i] + x$genomeSpan[i]) &amp;(Regions$end &gt; x$start_position[i] )) # if the start position is within the region if( length(ix) == 0 | length(ix) &gt;1 ) return(NA) else return( ix ) } regionID = unlist( lapply(1:dim(x)[1], regulatedGenes) ) x1 = x[which(!is.na(regionID)),] regionID = regionID[!is.na(regionID)] x1 = cbind(regionID,Regions[regionID, ], x1[,c(&#39;symbol&#39;, &#39;Row.names&#39;, &#39;Fold&#39;,&#39;FDR&#39;, &#39;band&#39;,&#39;start_position&#39;)]) x1 = x1[order(x1$regionID,x1$start_position ), ] colnames(x1)[8] = &quot;Ensembl&quot;; colnames(x1)[4] = &quot;Region.Start&quot;;colnames(x1)[5] = &quot;Region.End&quot;; colnames(x1)[12] = &quot;Gene.Start&quot; # number of genes tem = table(x1$regionID) Regions$Ngenes = 0 Regions$Ngenes[as.integer(names(tem) ) ] &lt;- tem # cytoband per region tem = unique(x1[,c(&#39;regionID&#39;,&#39;band&#39;)]) tem$band = gsub(&quot;\\\\..*&quot;,&quot;&quot;,tem$band) tem = unique(tem) Regions$band =&quot;&quot; Regions$ID &lt;- 1:dim(Regions)[1] for ( i in 1:dim(Regions)[1] ) Regions$band[i] &lt;- paste( tem[ which( tem[,1] == Regions$ID[i]),2], collapse=&quot;;&quot; ) # Genes Regions$Genes &lt;- &quot;&quot; for ( i in 1:dim(Regions)[1] ) Regions$Genes[i] &lt;- paste( x1$symbol[ which( x1[,1] == Regions$ID[i])], collapse=&quot; &quot; ) return( list(mainResult = GEanalysisResults, Regions = Regions, Genes = x1,legend.x=max(x$start_position)*.6, legend.y=max(chromosomesNumbers)-3 ) ) } genomePlot &lt;- function(){ library(PREDA,verbose=FALSE) # showing expression on genome library(PREDAsampledata,verbose=FALSE) library(hgu133plus2.db,verbose=FALSE) if( class(genomePlotData.out) != &quot;list&quot; ) { plot.new(); text(0.2,1, &quot;No significant regions found!&quot;)} else { GEanalysisResults &lt;- genomePlotData.out$mainResult; if( is.null( GEanalysisResults ) ) return(NULL) genomic_regions_UP&lt;-PREDAResults2GenomicRegions(GEanalysisResults, qval.threshold=input_RegionsPvalCutoff, smoothStatistic.tail=&quot;upper&quot;, smoothStatistic.threshold= -1 *input_StatisticCutoff) genomic_regions_DOWN&lt;-PREDAResults2GenomicRegions(GEanalysisResults, qval.threshold=input_RegionsPvalCutoff, smoothStatistic.tail=&quot;lower&quot;, smoothStatistic.threshold= -1 *input_StatisticCutoff) checkplot&lt;-genomePlot(GEanalysisResults, genomicRegions=c(genomic_regions_UP, genomic_regions_DOWN), grouping=c(1, 1), scale.positions=&quot;Mb&quot;, region.colors=c(&quot;red&quot;,&quot;blue&quot;)) legend(x=genomePlotData.out$legend.x, y=genomePlotData.out$legend.y , legend=c(&quot;UP&quot;, &quot;DOWN&quot;), fill=c(&quot;red&quot;,&quot;blue&quot;)) } #if else } # pre-calculating PREDA, so that changing FDR cutoffs does not trigger entire calculation genomePlotDataPre &lt;- function( ){ library(PREDA,verbose=FALSE) # showing expression on genome library(PREDAsampledata,verbose=FALSE) library(hgu133plus2.db,verbose=FALSE) if (is.null(input_selectContrast2 ) ) return(NULL) if( length(limma.out$topGenes) == 0 ) return(NULL) if(length( limma.out$comparisons) ==1 ) { top1=limma.out$topGenes[[1]] } else { top = limma.out$topGenes ix = match(input_selectContrast2, names(top)) if( is.na(ix)) return (NULL) top1 &lt;- top[[ix]]; } if(dim(top1)[1] == 0 ) return (NULL) colnames(top1)= c(&quot;Fold&quot;,&quot;FDR&quot;) # write.csv(merge(top1,allGeneInfo(), by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ),&quot;tem.csv&quot; ) x &lt;- merge(top1,allGeneInfo.out, by.x=&quot;row.names&quot;,by.y=&quot;ensembl_gene_id&quot; ) #hist(top1[,1]) ########## PREDA infofile &lt;- system.file(&quot;sampledata&quot;, &quot;GeneExpression&quot;, &quot;sampleinfoGE_PREDA.txt&quot;, package = &quot;PREDAsampledata&quot;) sampleinfo&lt;-read.table(infofile, sep=&quot;\\t&quot;, header=TRUE) head(sampleinfo) data(ExpressionSetRCC) GEstatisticsForPREDA&lt;-statisticsForPREDAfromEset(ExpressionSetRCC, statisticType=&quot;tstatistic&quot;, referenceGroupLabel=&quot;normal&quot;, classVector=sampleinfo[,&quot;Class&quot;]) analysesNames(GEstatisticsForPREDA) GEGenomicAnnotations&lt;-eset2GenomicAnnotations(ExpressionSetRCC, retain.chrs=1:22) # needs hgu133plus2.db package GEGenomicAnnotationsForPREDA&lt;-GenomicAnnotations2GenomicAnnotationsForPREDA(GEGenomicAnnotations, reference_position_type=&quot;median&quot;) GEDataForPREDA&lt;-MergeStatisticAnnotations2DataForPREDA(GEstatisticsForPREDA, GEGenomicAnnotationsForPREDA, sortAndCleanNA=TRUE) #x = read.csv(&quot;PREDA_test.csv&quot;) #x &lt;- x[,-1] # remove the row index, not needed in Shiny x &lt;- x[order(x$chromosome_name,x$start_position),] tem = sort( table( x$chromosome_name), decreasing=T) chromosomes &lt;- names( tem[tem &gt; 100 ] ) # chromosomes with less than 100 genes are excluded if(length(chromosomes) &gt; 50) chromosomes &lt;- chromosomes[1:50] # at most 50 chromosomes chromosomes = chromosomes[order(as.numeric(chromosomes) ) ] # chromosomes = chromosomes[!is.na(as.numeric(chromosomes) ) ] chromosomesNumbers = as.numeric(chromosomes) # convert chr.x to numbers j = max( chromosomesNumbers,na.rm=T) for( i in 1:length( chromosomes)) { if ( is.na(chromosomesNumbers[i]) ) { chromosomesNumbers[i] &lt;- j+1; j &lt;- j+1; } } x &lt;- x[which(x$chromosome_name %in% chromosomes ),] x &lt;- droplevels(x) # find the number coding for chromosome getChrNumber &lt;- function (chrName){ return( chromosomesNumbers[ which( chromosomes == chrName)] ) } x$chrNum = 1 # numeric coding x$chrNum &lt;- unlist( lapply( x$chromosome_name, getChrNumber) ) x$Row.names &lt;- as.character( x$Row.names) fold = x$Fold; names(fold) = x$Row.names # write.csv(x,&quot;tem.csv&quot;) x &lt;- x[!duplicated(x$Row.names),] #rownames(x) = x$Row.names myData &lt;- GEDataForPREDA myData@position &lt;- as.integer( x$start_position+ x$genomeSpan/2 ) myData@ids &lt;- as.character( x$Row.names) myData@chr &lt;- as.integer( x$chrNum ) myData@start &lt;- x$start_position myData@end &lt;- x$start_position + x$genomeSpan myData@strand &lt;- rep(1,dim(x)[1]) myData@chromosomesLabels &lt;- chromosomes myData@chromosomesNumbers &lt;- as.integer( chromosomesNumbers ) myData@statistic &lt;- as.matrix( x[,2,drop=FALSE] ) myData@analysesNames &lt;- &quot;Test&quot; myData@testedTail &lt;- &quot;both&quot; myData@optionalAnnotations &lt;- as.matrix( x[,1:2,drop=FALSE] ) myData@optionalAnnotationsHeaders &lt;- c(&quot;a&quot;,&quot;b&quot;) set.seed(2) GEanalysisResults&lt;-PREDA_main(myData,nperms = PREDA_Permutations) return( GEanalysisResults ) } 6.11 Biclustering ################################################################ # Biclustering ################################################################ biclustering &lt;- function( ){ library(biclust,verbose=FALSE) if(input_biclustMethod == &quot;BCQU()&quot; ) library(QUBIC,verbose=FALSE) # have trouble installing on Linux if(input_biclustMethod == &quot;BCUnibic()&quot; ) library(runibic,verbose=FALSE) # x &lt;- convertedData.out n=input_nGenesBiclust if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data if(n&lt;10) n = 10 if(n&gt; 2000 ) n = 2000 x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) if( input_biclustMethod == &quot;BCXmotifs()&quot; ) x&lt;-discretize(x) #res &lt;- biclust::biclust(as.matrix( x), method = BCQU()) runR = paste( &quot;res &lt;- biclust::biclust(as.matrix( x), method =&quot;, input_biclustMethod ,&quot;)&quot; ) eval(parse(text = runR ) ) return(list( x=x, res=res) ) } biclustHeatmap &lt;- function ( ){ res = biclustering()$res if( res@Number == 0 ) { plot.new(); text(0.5,0.5, &quot;No cluster found!&quot;)} else { x = biclust::bicluster(biclustering.out$x, res, as.numeric( input_selectBicluster) )[[1]] par(mar = c(5, 4, 1.4, 0.2)) if( dim(x)[1] &lt;=30 ) heatmap.2(x, Rowv =T,Colv=F, dendrogram =&quot;none&quot;, col=heatColors[as.integer(input_heatColors1),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.2 ,key=F, #labRow = T, ,margins = c(8, 24) ,cexRow=1 #,srtCol=45 ,cexCol=1. # size of font for sample names ) else heatmap.2(x, Rowv =T,Colv=F, dendrogram =&quot;none&quot;, col=heatColors[as.integer(input_heatColors1),], density.info=&quot;none&quot;, trace=&quot;none&quot;, scale=&quot;none&quot;, keysize=.2 ,key=F, labRow = F, ,margins = c(8, 4) ,cexRow=1 #,srtCol=45 ,cexCol=1. # size of font for sample names ) } } geneListBclustGO &lt;- function( ){ res = biclustering.out$res if( res@Number == 0 ) return(as.data.frame(&quot;No clusters found!&quot;) ) x = biclust::bicluster(biclustering.out$x, res, as.numeric( input_selectBicluster) )[[1]] if( dim(x)[1] &lt;= minGenesEnrichment) return(NoSig) query = rownames(x) result &lt;- findOverlapGMT( query, GeneSets.out,1) result$Genes = &quot;Up regulated&quot; results1 = result if ( is.null( results1) ) return (NoSig) if( dim(results1)[2] &lt;5 ) return(NoSig) # Returns a data frame: &quot;No significant results found!&quot; results1= results1[,c(5,1,2,4)] colnames(results1)= c(&quot;List&quot;,&quot;FDR&quot;,&quot;Genes&quot;,&quot;GO terms or pathways&quot;) minFDR = 0.01 if(min(results1$FDR) &gt; minFDR ) results1 = as.data.frame(&quot;No signficant enrichment found.&quot;) else results1 = results1[which(results1$FDR &lt; minFDR),] if(dim(results1)[2] != 4) return(NoSig) colnames(results1)= c(&quot;Direction&quot;,&quot;adj.Pval&quot;,&quot;Genes&quot;,&quot;Pathways&quot;) results1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(results1$adj.Pval) ) results1[,1] &lt;- as.character(results1[,1]) tem &lt;- results1[,1] results1[ duplicated (results1[,1] ),1 ] &lt;- &quot;&quot; results1[,-1] } 6.12 Co-expression network ################################################################ # Co-expression network ################################################################ wgcna &lt;- function ( ){ #http://pklab.med.harvard.edu/scw2014/WGCNA.html library(WGCNA) x &lt;- convertedData.out n=input_nGenesNetwork if(n&gt;dim(x)[1]) n = dim(x)[1] # max as data if(n&lt;50) return(NULL) if(dim(x)[2] &lt;4) return(NULL) if(n&gt; maxGeneWGCNA ) n = maxGeneWGCNA #x=as.matrix(x[1:n,])-apply(x[1:n,],1,mean) datExpr=t(x[1:n,]) subGeneNames=colnames(datExpr) #Choosing a soft-threshold to fit a scale-free topology to the network powers = c(c(1:10), seq(from = 12, to=20, by=2)); sft=pickSoftThreshold(datExpr,dataIsExpr = TRUE,powerVector = powers,corFnc = cor,corOptions = list(use = &#39;p&#39;),networkType = &quot;unsigned&quot;) softPower = input_mySoftPower; #calclute the adjacency matrix adj= adjacency(datExpr,type = &quot;unsigned&quot;, power = softPower); #turn adjacency matrix into topological overlap to minimize the effects of noise and spurious associations TOM=TOMsimilarityFromExpr(datExpr,networkType = &quot;unsigned&quot;, TOMType = &quot;unsigned&quot;, power = softPower); colnames(TOM) =subGeneNames rownames(TOM) =subGeneNames ########################################## # module detection library(flashClust,verbose=FALSE) geneTree = flashClust(as.dist(1-TOM),method=&quot;average&quot;); # Set the minimum module size minModuleSize = input_minModuleSize; # Module identification using dynamic tree cut dynamicMods = cutreeDynamic(dendro = geneTree, method=&quot;tree&quot;, minClusterSize = minModuleSize); #dynamicMods = cutreeDynamic(dendro = geneTree, distM = dissTOM, method=&quot;hybrid&quot;, deepSplit = 2, pamRespectsDendro = FALSE, minClusterSize = minModuleSize); # table(dynamicMods) dynamicColors = labels2colors(dynamicMods) #table(dynamicColors) #discard the unassigned genes, and focus on the rest # this causes problems #restGenes= (dynamicColors != &quot;grey&quot;) #diss1=1-TOMsimilarityFromExpr(datExpr[,restGenes], power = softPower) #colnames(diss1) =rownames(diss1) =subGeneNames[restGenes] #colorCode = as.character(dynamicColors[restGenes]) moduleInfo = cbind( subGeneNames, dynamicColors, dynamicMods) moduleInfo = moduleInfo[which(moduleInfo[,2] != &quot;grey&quot;) ,] # remove genes not in any modules moduleInfo = moduleInfo[order(moduleInfo[,3]),] # sort n.modules = length(unique(dynamicColors) ) -1 ; nGenes = dim(moduleInfo)[1] return(list(x = t(datExpr),powers=powers,sft=sft, TOM = TOM, dynamicColors = dynamicColors, moduleInfo = moduleInfo,n.modules=n.modules, nGenes =nGenes) ) } softPower &lt;- function(){ #################################### sft = wgcna.out$sft; powers=wgcna.out$powers; # Plot the results #sizeGrWindow(9, 5) par(mfrow = c(1,2)); cex1 = 0.9; # Scale-free topology fit index as a function of the soft-thresholding power plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Scale Free Topology Model Fit, signed R^2&quot;,type=&quot;n&quot;, main = paste(&quot;Scale independence&quot;)); text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],labels=powers,cex=cex1,col=&quot;red&quot;); # Red line corresponds to using an R^2 cut-off abline(h=0.80,col=&quot;red&quot;) # Mean connectivity as a function of the soft-thresholding power plot(sft$fitIndices[,1], sft$fitIndices[,5],xlab=&quot;Soft Threshold (power)&quot;,ylab=&quot;Mean Connectivity&quot;, type=&quot;n&quot;,main = paste(&quot;Mean connectivity&quot;)) text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col=&quot;red&quot;) } modulePlot &lt;- function(){ diss1 = 1-wgcna.out$TOM; dynamicColors = wgcna.out$dynamicColors hier1=flashClust(as.dist(diss1), method=&quot;average&quot; ) #set the diagonal of the dissimilarity to NA diag(diss1) = NA; plotDendroAndColors(hier1, dynamicColors, &quot;Dynamic Tree Cut&quot;, dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05, main = &quot;Gene dendrogram and module colors&quot;) #Visualize the Tom plot. Raise the dissimilarity matrix to the power of 4 to bring out the module structure #TOMplot(diss1, hier1, colorCode) } listWGCNA.Modules &lt;- function(){ if (is.null(wgcna.out ) ){ # if sample info is uploaded and correctly parsed. return(NULL) } else { if( dim(wgcna.out$moduleInfo)[1] == 0 ) { # if no module return(NULL) } else { modules = unique(wgcna.out$moduleInfo[, c(&quot;dynamicMods&quot;,&quot;dynamicColors&quot;)] ) moduleList = apply(modules,1,paste,collapse=&quot;. &quot;) moduleList = paste0( moduleList, &quot; (&quot;, table(wgcna.out$moduleInfo[,&quot;dynamicMods&quot;] ),&quot; genes)&quot; ) moduleList = c(moduleList,&quot;Entire network&quot;) return(moduleList) } } } moduleNetwork &lt;- function(){ outfile &lt;- tempfile(fileext=&#39;.txt&#39;) #module = gsub(&quot;.* &quot;,&quot;&quot;,input_selectWGCNA.Module) module = unlist(strsplit(input_selectWGCNA.Module,&quot; &quot; ) )[2] moduleColors = wgcna.out$dynamicColors inModule = (moduleColors==module); if( input_selectWGCNA.Module == &quot;Entire network&quot;) inModule = rep(TRUE, length(inModule)) datExpr = t(wgcna.out$x ) probes = colnames(datExpr) modProbes = probes[inModule]; modTOM = wgcna.out$TOM[inModule, inModule]; dimnames(modTOM) = list(modProbes, modProbes) nTop = input_topGenesNetwork; if( nTop &gt; 1000) nTop = 1000; IMConn = softConnectivity(datExpr[, modProbes]); top = (rank(-IMConn) &lt;= nTop) # adding symbols probeToGene = NULL if( input_selectGO5 != &quot;ID not recognized!&quot; &amp; input_selectOrg != &quot;NEW&quot;) if(sum(is.na( allGeneInfo.out$symbol ) )/ dim( allGeneInfo.out )[1] &lt;.5 ) { # if more than 50% genes has symbol probeToGene = allGeneInfo.out[,c(&quot;ensembl_gene_id&quot;,&quot;symbol&quot;)] probeToGene$symbol = gsub(&quot; &quot;,&quot;&quot;,probeToGene$symbol) ix = which( is.na(probeToGene$symbol) | nchar(probeToGene$symbol)&lt;2 | toupper(probeToGene$symbol)==&quot;NA&quot; | toupper(probeToGene$symbol)==&quot;0&quot; ) probeToGene[ix,2] = probeToGene[ix,1] # use gene ID } net &lt;- modTOM[top,top] &gt;input_edgeThreshold for( i in 1:dim(net)[1]) # remove self connection net[i,i] = FALSE if(!is.null(probeToGene) &amp; !input_noIDConversion) { # if gene symbol exist ix = match( colnames(net), probeToGene[,1]) colnames(net) = probeToGene[ix,2] ix = match( rownames(net), probeToGene[,1]) rownames(net) = probeToGene[ix,2] } library(igraph,verbose=FALSE) #plot(graph_from_data_frame(d=data.frame(1:10,ncol=2) ,directed=F) ) # http://www.kateto.net/wp-content/uploads/2016/01/NetSciX_2016_Workshop.pdf plot( graph_from_adjacency_matrix( net, mod =&quot;undirected&quot; ), vertex.label.color=&quot;black&quot;, vertex.label.dist=3,vertex.size=7) } networkModuleGO &lt;- function(){ #module = gsub(&quot;.* &quot;,&quot;&quot;,input_selectWGCNA.Module) module = unlist(strsplit(input_selectWGCNA.Module,&quot; &quot; ) )[2] moduleColors = wgcna.out$dynamicColors inModule = (moduleColors==module); if( input_selectWGCNA.Module == &quot;Entire network&quot;) inModule = rep(TRUE, length(inModule)) probes = rownames(wgcna.out$x ) query = probes[inModule]; if( length(query) &lt;= minGenesEnrichment) return(NoSig) result &lt;- findOverlapGMT( query, GeneSets.out,1) result$Genes = &quot;Up regulated&quot; results1 = result if ( is.null( results1) ) return (NoSig) if( dim(results1)[2] &lt;5 ) return(NoSig) # Returns a data frame: &quot;No significant results found!&quot; results1= results1[,c(5,1,2,4)] colnames(results1)= c(&quot;List&quot;,&quot;FDR&quot;,&quot;Genes&quot;,&quot;GO terms or pathways&quot;) minFDR = 0.01 if(min(results1$FDR) &gt; minFDR ) results1 = as.data.frame(&quot;No signficant enrichment found.&quot;) else results1 = results1[which(results1$FDR &lt; minFDR),] if(dim(results1)[2] != 4) return(NoSig) colnames(results1)= c(&quot;Direction&quot;,&quot;adj.Pval&quot;,&quot;Genes&quot;,&quot;Pathways&quot;) results1$adj.Pval &lt;- sprintf(&quot;%-2.1e&quot;,as.numeric(results1$adj.Pval) ) results1[,1] &lt;- as.character(results1[,1]) tem &lt;- results1[,1] results1[ duplicated (results1[,1] ),1 ] &lt;- &quot;&quot; results1[,-1] } "],["wgcna-rna-seq-blog.html", "Chapter 7 WGCNA RNA-seq Blog 7.1 Introduction to the WGCNA Rpackage 7.2 RNA-seq Analisys with Kaku’s Data sample.", " Chapter 7 WGCNA RNA-seq Blog 7.1 Introduction to the WGCNA Rpackage 7.1.1 WGCNA Rpackage Installation procedure. Installing and re-installing new versions or R and Studio. In Terminal (or Rstudio &gt; Terminal). brew reinstall --cask r brew reinstall --cask rstudio Installing WGCNA: and R package for weighted correlation network analysis. To install the package, go to Tab: Packages &gt; Install …[]… -Repository: (CRAN); -Packages: WGCNA; *Install. In R code: install.packages(&quot;WGCNA&quot;) Installation (Failed). Unfortunately, it could not install correctly. Error was: install.packages(&quot;WGCNA&quot;) Warning in install.packages : dependencies ‘Biobase’, ‘impute’, ‘preprocessCore’, ‘GO.db’, ‘AnnotationDbi’ are not available Package which is only available in source form, and may need compilation of C/C++/Fortran: ‘WGCNA’ Do you want to attempt to install these from sources? (Yes/no/cancel) y Warning in install.packages : installation of package ‘WGCNA’ had non-zero exit status Dependencies are old and require special installation. From this page, installed several packages. (Failed). install.packages(c(&quot;dynamicTreeCut&quot;, &quot;cluster&quot;, &quot;flashClust&quot;, &quot;Hmisc&quot;, &quot;reshape&quot;, &quot;foreach&quot;, &quot;doParallel&quot;) ) source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;impute&quot;) install.packages(&quot;WGCNA&quot;) Install most of the packages, but not “impute,” result: could not install WGCNA. Tried to install dependencies independently from here: (Failed) You&#39;re using R-3.6.0, but trying to install Bioconductor version 3.8. Try using BiocManager::install(&quot;Biobase&quot;). If that works, then try BiocManager::install(&quot;GO.db&quot;). If you have success, make sure your installation is valid with BiocManager::valid(). BiocManager::install(&quot;Biobase&quot;) BiocManager::install(&quot;GO.db&quot;) BiocManager::valid() No resutl Decided to install the complete “BiocManager” pack. ** BiocManager: (OK); (WGCNA:(Failed)** &gt; install.packages(&quot;BiocManager&quot;) downloaded 315 KB &gt; install.packages(&quot;WGCNA&quot;) Warning in install.packages : dependencies ‘impute’, ‘preprocessCore’ are not available Search ‘preprocessCore,’ in this page. PreprocessCore:(OK); (WGCNA:(Failed) To install this package, start R (version “4.1”) and enter: if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;preprocessCore&quot;) For ‘impute,’ found install in this page. Impute:(OK); WGCNA:( OK) To install this package, start R (version “4.1”) enter: if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;impute&quot;) Then install WGCNA install.packages(&quot;WGCNA&quot;) 7.1.2 Final installation workflow: # Set working directory getwd() setwd(&quot;/Users/marcelorosales/Box Sync/Documents/R/Rmarkdown&quot;) getwd() # Load list of packages and install. load(&quot;Rpackages&quot;) for (p in setdiff(packages, installed.packages()[,&quot;Package&quot;])) install.packages(p) Check &lt;- installed.packages() BiocManager::install(&quot;Biobase&quot;) BiocManager::install(&quot;GO.db&quot;) BiocManager::valid() &gt; install.packages(&quot;BiocManager&quot;) if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;preprocessCore&quot;) BiocManager::install(&quot;WGCNA&quot;) install.packages(c(&quot;dynamicTreeCut&quot;, &quot;cluster&quot;, &quot;flashClust&quot;, &quot;Hmisc&quot;, &quot;reshape&quot;, &quot;foreach&quot;, &quot;doParallel&quot;) ) source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;impute&quot;) if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;impute&quot;) install.packages(&quot;WGCNA&quot;) Checking the packages for WGCNA installed previously for OS Catalina. Warning in install.packages : package ‘anRichment’ is not available for this version of R A version of this package for your version of R might be available elsewhere, see the ideas at https://cran.r-project.org/doc/manuals/r-patched/R-admin.htmlInstalling-packages Warning in install.packages : package ‘anRichment’ is not available for this version of R package ‘anRichmentMethods’ is not available for this version of R package ‘BiocFileCache’ is not available for this version of R package ‘BiocParallel’ is not available for this version of R package ‘biomaRt’ is not available for this version of R package ‘DelayedArray’ is not available for this version of R package ‘GenomicAlignments’ is not available for this version of R package ‘GenomicFeatures’ is not available for this version of R package ‘GenomicRanges’ is not available for this version of R package ‘inserttable’ is not available for this version of R package ‘lorem’ is not available for this version of R package ‘org.Hs.eg.db’ is not available for this version of R package ‘org.Mm.eg.db’ is not available for this version of R package ‘Rhtslib’ is not available for this version of R package ‘Rsamtools’ is not available for this version of R package ‘rtracklayer’ is not available for this version of R package ‘SummarizedExperiment’ is not available for this version of R package ‘TxDb.Hsapiens.UCSC.hg19.knownGene’ is not available for this version of R package ‘TxDb.Mmusculus.UCSC.mm10.knownGene’ is not available for this version of R A version of this package for your version of R might be available elsewhere, see the ideas at https://cran.r-project.org/doc/manuals/r-patched/R-admin.htmlInstalling-packages 7.1.3 WGCNA tutorial. This code has been adapted from the tutorials available at WGCNA website (this page does no longer exist). WGCNA: an R package for weighted correlation network analysis site. Tutorials for the WGCNA package. R tutorial Steps Required for this process are: 1. Data input and cleaning: PDF document, R script. 1. Network construction and module detection a. Automatic, one-step network construction and module detection: PDF document, R script b. Step-by-step network construction and module detection: PDF document, R script c. Dealing with large datasets: block-wise network construction and module detection: PDF document, R script 1. Relating modules to external clinical traits and identifying important genes: PDF document, R script 1. Interfacing network analysis with other data such as functional annotation and gene ontology PDF document, R script 1. Network visualization using WGCNA functions: PDF document, R script 1. Export of networks to external software: PDF document, R script 7.1.4 3.4 Gene expression analysis The level of gene expression is measured by read density, the higher the read density, the higher the level of gene expression. Gene expression calculation was performed with the formula below, which calculates FPKM (Fragments per kilo bases per million reads) based on read counts from HT-seq (V 0.6.1) (Mortazavi, 2008). The formula is: Figure 3.4.1 The ratio of (total exon fragments / mapped reads [millions]) is the read count mapped to the gene normalized to total read counts. The value is then normalized to gene length (exon length [KB]), so that the expression of genes with different sequencing depths and length are comparable. The numbers of genes with different expression levels are summarized in Table 3.7.1. In general, FPKM threshold for gene expression is set between 0.1-1, although there is no absolute standard and various thresholds have been used in the literature. 7.2 RNA-seq Analisys with Kaku’s Data sample. 2021/07/02 Copy Trial data from MK/土橋 to folder : The Report file. The Summary file Report ### Experimental Workflow. Transcriptome sequencing experiments include: * RNA extraction and QC (Quality Control?), * Library construction, * Purification, * Library QC and * Quantitation, as well as * Sequencing cluster generation and high through-put sequencing. Each step is important for data quality and quantity, which in turn affect the data analysis. To ensure the accuracy and reliability of the analysis results, every step is under strict monitoring and quality control. After mixing libraries based on their effective concentration and the required sequencing data volume, Illumina platform is used for high through-put sequencing. 7.2.1 Data Analysis. First Data must be in the right format. In the data received. “GeneName” “Chr” “Start” “End” “Strand” “Length” “mPDL_RNA14D_Ko1” “mPDL_RNA14D_Ko2” “mPDL_RNA14D_Ko3” “mPDL_RNA14D_Ko4” “mPDL_RNA14D_WT1” “mPDL_RNA14D_WT2” “mPDL_RNA14D_WT3” “mPDL_RNA14D_WT4” “mPDL_RNA7D_Ko1” “mPDL_RNA7D_Ko2” “mPDL_RNA7D_Ko3” “mPDL_RNA7D_Ko4” “mPDL_RNA7D_WT1” “mPDL_RNA7D_WT2” “mPDL_RNA7D_WT3” “mPDL_RNA7D_WT4” Use Markdown Table generator. 20210705 Problems with software* ** Regarding Rstudio Shortcut keys “not working” sometimes** SOME shortcuts will work if not on the corresponding file type. For example, MARKDOWN shortcuts will not work on R script files window or vice versa. Set working directory getwd() setwd(&quot;/Users/marcelorosales/Box Sync/Documents/R/Rmarkdown&quot;) &quot;/Users/marcelorosales/Box Sync/Documents/R/Rmarkdown&quot; # [1] &quot;/Users/marcelorosales/Box Sync/Niigata Uni Box/Experiments/Photoconvertible FP/Experiment Notebooks&quot; getwd() Load list of packages and install. load(&quot;Rpackages&quot;) for (p in setdiff(packages, installed.packages()[,&quot;Package&quot;])) install.packages(p) Check &lt;- installed.packages() BiocManager::install(&quot;Biobase&quot;) BiocManager::install(&quot;GO.db&quot;) BiocManager::valid() &gt; install.packages(&quot;BiocManager&quot;) if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;preprocessCore&quot;) BiocManager::install(&quot;WGCNA&quot;) install.packages(c(&quot;dynamicTreeCut&quot;, &quot;cluster&quot;, &quot;flashClust&quot;, &quot;Hmisc&quot;, &quot;reshape&quot;, &quot;foreach&quot;, &quot;doParallel&quot;) ) source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite(&quot;impute&quot;) install.packages(&quot;WGCNA&quot;) source(&quot;https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/GeneAnnotation/installAnRichment.R&quot;); installAnRichment(); install.packages(&quot;path/to/anRichmentMethods&quot;, repos = NULL, type = &quot;source&quot;); install.packages(&quot;path/to/anRichment&quot;, repos = NULL, type = &quot;source&quot;); source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(c(&quot;AnnotationDBI&quot;, &quot;GO.db&quot;, &quot;org.Hs.eg.db&quot;, &quot;org.Mm.eg.db&quot;, &quot;XML&quot;, &quot;WGCNA&quot;, &quot;TxDb.Hsapiens.UCSC.hg19.knownGene&quot;, &quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;)); install.packages(&quot;path/to/anRichmentMethods&quot;, repos = NULL, type = &quot;source&quot;); install.packages(&quot;path/to/anRichment&quot;, repos = NULL, type = &quot;source&quot;); BiocManager::install() source(&quot;https://bioconductor.org/biocLite.R&quot;); biocLite(c(&quot;AnnotationDBI&quot;, &quot;GO.db&quot;, &quot;org.Hs.eg.db&quot;, &quot;org.Mm.eg.db&quot;, &quot;XML&quot;, &quot;WGCNA&quot;, &quot;TxDb.Hsapiens.UCSC.hg19.knownGene&quot;, &quot;TxDb.Mmusculus.UCSC.mm10.knownGene&quot;)); if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;impute&quot;) str(all_fpkm) table(all_fpkm) names(all_fpkm) "],["youtube-references..html", "Chapter 8 Youtube references. 8.1 Anaconda set up, Robust Data Science Environment with Miniconda and Conda-Forge. 8.2 Quality control &amp; preprocessing of raw reads 8.3 Trimmomatic. 8.4 Building Genome Index and Aligning with STAR", " Chapter 8 Youtube references. 8.1 Anaconda set up, Robust Data Science Environment with Miniconda and Conda-Forge. Anaconda set up Bioinformatics - Downloading and Setting Up Conda Environments. 8.2 Quality control &amp; preprocessing of raw reads Bioinformatics - SRA Download, QC, and Trimming. RNA-seq course: Quality control &amp; preprocessing of raw reads Good explanation of the fastQC html plots. 8.3 Trimmomatic. RNA Sequencing 3: Trimmomatic Good explanation of the fastQC html plots. Topic: Metagenomics Lesson 2 Demo 2.2 - Trimmomatic 8.4 Building Genome Index and Aligning with STAR Bioinformatics - Building Genome Index and Aligning with STAR How to use the Cat command "],["external-ref.html", "Chapter 9 External Ref", " Chapter 9 External Ref We have finished a nice book. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
